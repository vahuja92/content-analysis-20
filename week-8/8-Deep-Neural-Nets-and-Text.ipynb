{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week - 8 - Deep Neural Nets and Text\n",
    "\n",
    "In this week we introduce the use of Deep Neural Networks to work with text. We have already seen some uses of neural networks for text in our classification HW, where we used a simple neural network--the one-layer perceptron--to classify text. It performed quite well, but comes up short in more sophisticated classification tasks, such as in predicting intent. We have also seen slightly deeper, 2-level neural nets in the form of word embeddings such as Word2Vec. While they work well, they have some drawbacks, such as representing words with multiple meanings in a singular space. \n",
    "\n",
    "BERT, which is a language model built using bidirectional encoders, allows us to take advantage of a powerful pre-trained model which we can then use to perform our own tasks based on data we analyze. \n",
    "\n",
    "In this notebook we use ```huggingface/transformers```, a python package that allows for easy interface to use pre-trained BERT models. It is built using Tensorflow and PyTorch, two computational graph packages which are built specifically for creating powerful neural networks. We will also be introducing Keras, which allows us to easily build Neural Networks in an abstracted way. Keras is a popular way to understand how we can stack layers to create such Neural Networks, but to reach state-of-the-art results we will stick with using BERT and similar models that can be tuned to extremely high performance on specific language understanding and generation tasks.\n",
    "\n",
    "To demonstrate this, we begin by using the [Corpus of Linguistic Acceptability](https://nyu-mll.github.io/CoLA/). We will also use BERT by learning how to extract embeddings from such a model and use it to semantically probe sentences. There are a number of new packages and methods we will be using so be sure to update lucem_illud_2020.\n",
    "\n",
    "## NOTE\n",
    "\n",
    "This notebook **requires** GPUs for training models in section 1 and section 3. To train models, please use this [Google Colab file](https://colab.research.google.com/drive/1_G6iGqiXb-zPBTurRxd7cgGrXyNaKGsA) to create the models. Note that I have only given you view access: please create your own colab file to train your models, using the code and instructions I have given in the Colab file. So while you have to do the homework on this notebook, the models which you will train should be done on Google Colab, which has GPU access. If you happen to have GPU access on your personal machines or some other way to train the models, you are welcome to do that too.\n",
    "\n",
    "Note that if you run the computationally intensive models on your local computer they will take a long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U git+git://github.com/Computational-Content-Analysis-2020/lucem_illud_2020.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # pip install torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig # pip install tranformers==2.4.1\n",
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lucem_illud_2020 # pip install -U git+git://github.com/Computational-Content-Analysis-2020/lucem_illud_2020.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/vedikaahuja/winter2020/Content-Analysis-2020/week-8'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoLA Dataset and pre-processing\n",
    "\n",
    "We start with loading our dataset and pre-processing it. The pre-processing follows similar steps as we have done in the past, but we will be using pre-written modules offered by the transformers package. These are some of the things we have to take care of when using this particular BERT model.\n",
    "\n",
    "    -special tokens to mark the beginning ([CLS]) and separation/end of sentences ([SEP])\n",
    "    -tokens that conforms with the fixed vocabulary used in BERT\n",
    "    -token IDs from BERTâ€™s tokenizer\n",
    "    -mask IDs to indicate which elements in the sequence are tokens and which are padding elements\n",
    "    -segment IDs used to distinguish different sentences\n",
    "    -positional embeddings used to show token position within the sequence\n",
    "\n",
    "\n",
    "We will be using parts of the code from [this notebook](https://colab.research.google.com/drive/1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO#scrollTo=BJR6t_gCQe_x) which walks us through the process of using a pre-trained BERT model. The interface to use these models comes from the package [huggingface/transformers](https://github.com/huggingface/transformers). \n",
    "\n",
    "We start by setting up our GPU if we can - this may not work on your machine, so it has been commented out.\n",
    "\n",
    "An aside: check out this tutorial too - https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if gpu:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['somebody', 'just', 'left', '-', 'guess', 'who', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2020, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2020, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that estimate a deep classification model with Keras (and LSTM) and also BERT in order to predict pre-established data labels relevant to your final project (as for week 3's homework). Which works better? Are the errors the same or different?\n",
    "\n",
    "<span style=\"color:red\">***Stretch***</span>: <span style=\"color:red\">Now alter the neural network by stacking network layers, adjusting the embedding dimension, compare its performance with your model above, and interpret why it might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 1 Write Up (Code below)*</span>\n",
    "\n",
    "\n",
    "My corpus doesn't have labels, so I used the documents already included in this notebook for this exercise.\n",
    "\n",
    "The BERT Model has a much higher accuarcy level than the LSTM model. Accuarcy is the number of correctly predicted labels. Both iterations of the The LSTM model using different parameters had accuarcy levels of 68%, while the BERT model has an accuarcy rate of 82%. This means the LSTM has more errors.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Deep Neural Nets\n",
    "\n",
    "A popular, simplified package for introducing deep neural networks is [Keras](https://keras.io). It is a high level package in that we don't bother with every detail or hyper-parameter associated with the neural network (e.g., regularizers), and can stack on layers directly. For a rapid tutorial on neural networks for text such as the LSTM or the Recurrent Neural Network, Colah's blog is a great start. [LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) is an article on LSTMs, and if you'd like to  learn about RNN, Andrej Karpathy does a great job in [this blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), in addition to our reading from the newest online verion of Jurafsky & Martin's review of deep learning methods in their book on speech and language processing, chapters [6,7,9,10](https://web.stanford.edu/~jurafsky/slp3/), and the [*Deep Learning*](https://www.deeplearningbook.org/) book by Goodfellow, Bengio & Courville.\n",
    "\n",
    "In the following cells we build a basic deep net that has an embedding layer and an LSTM to perform classification. This is to illustrate the process of using Keras, which is a very popular library for such work. It may not yield state of the art performance because it constrains the hyperparameters you can tune, but is nonetheless an useful tool and works well on some datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_in_size = tokenizer.vocab_size\n",
    "embedding_dim = 32\n",
    "unit = 100\n",
    "no_labels = len(np.unique(train_labels))\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 128, 32)           976704    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,030,106\n",
      "Trainable params: 1,030,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(vocab_in_size, embedding_dim, input_length=MAX_LEN))\n",
    "model_lstm.add(LSTM(unit))\n",
    "model_lstm.add(Dense(no_labels, activation='softmax'))\n",
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "464/464 [==============================] - 2s 4ms/step - loss: 0.6498 - accuracy: 0.6530\n",
      "Epoch 2/10\n",
      "464/464 [==============================] - 2s 3ms/step - loss: 0.6331 - accuracy: 0.6789\n",
      "Epoch 3/10\n",
      "464/464 [==============================] - 1s 3ms/step - loss: 0.6293 - accuracy: 0.6789\n",
      "Epoch 4/10\n",
      "464/464 [==============================] - 2s 3ms/step - loss: 0.6313 - accuracy: 0.6789\n",
      "Epoch 5/10\n",
      "464/464 [==============================] - 2s 3ms/step - loss: 0.6343 - accuracy: 0.6789\n",
      "Epoch 6/10\n",
      "464/464 [==============================] - 2s 4ms/step - loss: 0.6350 - accuracy: 0.6789\n",
      "Epoch 7/10\n",
      "464/464 [==============================] - 2s 4ms/step - loss: 0.6305 - accuracy: 0.6789\n",
      "Epoch 8/10\n",
      "464/464 [==============================] - 1s 3ms/step - loss: 0.6289 - accuracy: 0.6789\n",
      "Epoch 9/10\n",
      "464/464 [==============================] - 2s 3ms/step - loss: 0.6283 - accuracy: 0.6789\n",
      "Epoch 10/10\n",
      "464/464 [==============================] - 1s 3ms/step - loss: 0.6283 - accuracy: 0.6789\n"
     ]
    }
   ],
   "source": [
    "history_lstm = model_lstm.fit(train_inputs, train_labels, \n",
    "                              epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1aa07a2e50>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy of this model isn't terrible, but it still hovers around 70%. Below there is code for a slightly modified neural network - how does this one perform? Note that in this model, I have added another LSTM layer. You are encouraged to explore the [Keras documentaion](https://keras.io/layers/about-keras-layers/) to explore what kind of layers you can add and how they change performances for different tasks. Different kinds of losses, optimizers, activations and layers can change the flavour of your net dramatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm2 = Sequential()\n",
    "model_lstm2.add(Embedding(vocab_in_size, embedding_dim, input_length=MAX_LEN))\n",
    "model_lstm2.add(LSTM(unit))\n",
    "#model_lstm2.add(LSTM(unit))\n",
    "model_lstm2.add(Dense(1, activation='sigmoid'))\n",
    "model_lstm2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "464/464 [==============================] - 2s 4ms/step - loss: 0.6553 - accuracy: 0.6444\n",
      "Epoch 2/10\n",
      "464/464 [==============================] - 1s 3ms/step - loss: 0.6338 - accuracy: 0.6789\n",
      "Epoch 3/10\n",
      "464/464 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.6789\n",
      "Epoch 4/10\n",
      "464/464 [==============================] - 1s 3ms/step - loss: 0.6322 - accuracy: 0.6789\n",
      "Epoch 5/10\n",
      "464/464 [==============================] - 1s 3ms/step - loss: 0.6293 - accuracy: 0.6789\n",
      "Epoch 6/10\n",
      "464/464 [==============================] - 2s 4ms/step - loss: 0.6281 - accuracy: 0.6789\n",
      "Epoch 7/10\n",
      "464/464 [==============================] - 2s 3ms/step - loss: 0.6307 - accuracy: 0.6789\n",
      "Epoch 8/10\n",
      "464/464 [==============================] - 1s 3ms/step - loss: 0.6280 - accuracy: 0.6789\n",
      "Epoch 9/10\n",
      "464/464 [==============================] - 1s 3ms/step - loss: 0.6318 - accuracy: 0.6789\n",
      "Epoch 10/10\n",
      "464/464 [==============================] - 2s 4ms/step - loss: 0.6296 - accuracy: 0.6789\n"
     ]
    }
   ],
   "source": [
    "history_lstm2 = model_lstm2.fit(train_inputs, train_labels, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On with BERT!\n",
    "\n",
    "So while Neural Networks can do a good job with some kind of classification tasks, they don't perform too well on intent classification. Let us see how a bidirectional transformer embedding like BERT might do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1a49e9abd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our Models (Did this part in Google Colab)\n",
    "\n",
    "### Train Model\n",
    "Now that our input data is properly formatted, it's time to fine tune the BERT model.\n",
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until the entire model, end-to-end, is well-suited for our task. Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.\n",
    "We'll load BertForSequenceClassification. This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n",
    "\n",
    "### Structure of Fine-Tuning Model\n",
    "\n",
    "As we've showed beforehand, the first token of every sequence is the special classification token ([CLS]). Unlike the hidden state vector corresponding to a normal word token, the hidden state corresponding to this special token is designated by the authors of BERT as an aggregate representation of the whole sentence used for classification tasks. As such, when we feed in an input sentence to our model during training, the output is the length 768 hidden state vector corresponding to this token. The additional layer that we've added on top consists of untrained linear neurons of size [hidden_state, number_of_labels], so [768,2], meaning that the output of BERT plus our classification layer is a vector of two numbers representing the \"score\" for \"grammatical/non-grammatical\" that are then fed into cross-entropy loss.\n",
    "\n",
    "### The Fine-Tuning Process\n",
    "\n",
    "Because the pre-trained BERT layers already encode a lot of information about the language, training the classifier is relatively inexpensive. Rather than training every layer in a large model from scratch, it's as if we have already trained the bottom layers 95% of where they need to be, and only really need to train the top layer, with a bit of tweaking going on in the lower levels to accomodate our task.\n",
    "Sometimes practicioners will opt to \"freeze\" certain layers when fine-tuning, or to apply different learning rates, apply diminishing learning rates, etc. all in an effort to preserve the good quality weights in the network and speed up training (often considerably). In fact, recent research on BERT specifically has demonstrated that freezing the majority of the weights results in only minimal accuracy declines, but there are exceptions and broader rules of transfer learning that should also be considered. For example, if your task and fine-tuning dataset is very different from the dataset used to train the transfer learning model, freezing the weights may not be a good idea. OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "Credit to Michel Kana's [tutorial](https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03) and the [tutorial](https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=GuE5BqICAne2) by Chris McCormick and Nick Ryan who describe the workings of BERT and the way it is used by the ```transformers``` package. \n",
    "\n",
    "## WARNING: SHIFT TO A GPU ENABLED MACHINE (e.g., Google Colab)\n",
    "\n",
    "Note that you only want to run the following code if you have a GPU. Otherwise, rerun the **same** cells we just ran on the Colab file to train your model, download it to your local, and load it by running\n",
    "```model = BertForSequenceClassification.from_pretrained(\"my_model_directory\", num_labels=2)```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COME BACK TO THIS NOTEBOOK to load and work with your trained model\n",
    "\n",
    "Once you tune your model on Colab (or on your own machine if you decided to do that instead), you load it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"../data/model_save\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"../data/cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 516 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 354 of 516 (68.60%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-2.34643   ,  2.591998  ],\n",
       "        [-2.4428024 ,  2.700246  ],\n",
       "        [-2.339438  ,  2.7989264 ],\n",
       "        [-2.250794  ,  2.5029619 ],\n",
       "        [-1.6965761 ,  2.0191786 ],\n",
       "        [-2.567413  ,  2.859779  ],\n",
       "        [-0.25952053, -0.3571833 ],\n",
       "        [-2.1614861 ,  2.151256  ],\n",
       "        [-2.3983898 ,  2.7420828 ],\n",
       "        [-2.3672612 ,  2.7403853 ],\n",
       "        [-1.3809142 ,  1.7459767 ],\n",
       "        [ 1.4603266 , -1.6187049 ],\n",
       "        [-2.2324817 ,  2.7162743 ],\n",
       "        [-0.9985211 ,  0.6627108 ],\n",
       "        [-2.0497117 ,  2.1283667 ],\n",
       "        [-1.5071132 ,  1.6383497 ],\n",
       "        [-2.0219698 ,  1.8611529 ],\n",
       "        [ 1.5893661 , -2.0814195 ],\n",
       "        [-2.142292  ,  2.4949555 ],\n",
       "        [-1.8617957 ,  2.3376205 ],\n",
       "        [-2.142292  ,  2.4949555 ],\n",
       "        [-1.6129186 ,  1.9922585 ],\n",
       "        [-1.2618977 ,  1.6175938 ],\n",
       "        [-2.1850543 ,  2.393134  ],\n",
       "        [-1.5120282 ,  1.5098029 ],\n",
       "        [-2.2880998 ,  2.5041404 ],\n",
       "        [-1.795022  ,  2.0749717 ],\n",
       "        [-2.2815995 ,  2.2859082 ],\n",
       "        [-2.3815777 ,  2.4916816 ],\n",
       "        [-1.885067  ,  1.9434903 ],\n",
       "        [-2.1253016 ,  2.2289913 ],\n",
       "        [-1.4338169 ,  1.6713252 ]], dtype=float32),\n",
       " array([[-1.2061795 ,  1.1204327 ],\n",
       "        [-1.810865  ,  2.2910538 ],\n",
       "        [-1.3150325 ,  1.5372999 ],\n",
       "        [-2.4091158 ,  2.5299377 ],\n",
       "        [-2.087234  ,  2.3955297 ],\n",
       "        [-2.4511642 ,  2.85631   ],\n",
       "        [-1.9861623 ,  2.2652462 ],\n",
       "        [-2.476275  ,  2.6933255 ],\n",
       "        [-0.10668673, -0.39585093],\n",
       "        [-2.0338235 ,  2.2135396 ],\n",
       "        [-1.8379338 ,  2.2812867 ],\n",
       "        [ 1.0924287 , -1.1361381 ],\n",
       "        [-1.9300494 ,  2.376409  ],\n",
       "        [-1.5088031 ,  1.2098656 ],\n",
       "        [-1.0371373 ,  0.6604024 ],\n",
       "        [-0.96698284,  0.6019897 ],\n",
       "        [-1.599411  ,  1.8550351 ],\n",
       "        [-2.5383358 ,  2.637949  ],\n",
       "        [-1.9259225 ,  1.8718941 ],\n",
       "        [-1.5686566 ,  1.4360538 ],\n",
       "        [ 1.2334886 , -1.5384519 ],\n",
       "        [ 1.2722163 , -1.7290316 ],\n",
       "        [-2.2152324 ,  2.3386903 ],\n",
       "        [-2.2558222 ,  2.677115  ],\n",
       "        [-2.253696  ,  2.5869918 ],\n",
       "        [-2.253696  ,  2.5869918 ],\n",
       "        [-2.153143  ,  2.4034429 ],\n",
       "        [-1.686489  ,  2.058684  ],\n",
       "        [-2.1585915 ,  2.4015846 ],\n",
       "        [-2.3210657 ,  2.361669  ],\n",
       "        [-1.6864889 ,  2.058684  ],\n",
       "        [-2.4426525 ,  2.5671394 ]], dtype=float32),\n",
       " array([[-2.3977742,  2.5914316],\n",
       "        [-2.0597394,  2.4750352],\n",
       "        [-2.4197245,  2.5541558],\n",
       "        [-2.2734408,  2.4119585],\n",
       "        [-2.0719502,  2.3699107],\n",
       "        [-1.4911896,  1.8053733],\n",
       "        [ 1.0463355, -1.3787434],\n",
       "        [-1.0145454,  0.8485588],\n",
       "        [-2.4938433,  2.8927412],\n",
       "        [-2.345952 ,  2.4906719],\n",
       "        [-2.4951572,  2.9014902],\n",
       "        [-2.1466758,  2.134507 ],\n",
       "        [-1.5056282,  1.3288529],\n",
       "        [ 1.6596625, -2.059507 ],\n",
       "        [-1.4927888,  1.4921843],\n",
       "        [-2.1246276,  2.3188648],\n",
       "        [-1.6661918,  1.8405778],\n",
       "        [ 1.6755347, -2.13272  ],\n",
       "        [-2.222681 ,  2.812952 ],\n",
       "        [-2.5834234,  2.9811926],\n",
       "        [-1.9666386,  2.568191 ],\n",
       "        [-2.512051 ,  2.9642966],\n",
       "        [ 1.8944888, -2.3750446],\n",
       "        [ 1.8099778, -2.2448614],\n",
       "        [-2.3209143,  2.58753  ],\n",
       "        [-1.7243097,  1.9618818],\n",
       "        [-2.4780567,  2.8474727],\n",
       "        [ 1.7597938, -2.2148104],\n",
       "        [ 1.3990687, -1.7826877],\n",
       "        [ 1.8527364, -2.3603392],\n",
       "        [-1.9121323,  2.0407114],\n",
       "        [ 1.9203134, -2.411697 ]], dtype=float32),\n",
       " array([[-2.2748086 ,  2.5150654 ],\n",
       "        [ 1.8832014 , -2.3167167 ],\n",
       "        [ 1.8586595 , -2.3608396 ],\n",
       "        [-0.23219046, -0.0973806 ],\n",
       "        [-2.5133932 ,  3.034344  ],\n",
       "        [-2.582775  ,  2.8745856 ],\n",
       "        [-2.1310165 ,  2.6683884 ],\n",
       "        [ 0.9588676 , -1.3483051 ],\n",
       "        [-2.607483  ,  2.888382  ],\n",
       "        [-2.2674704 ,  2.3643012 ],\n",
       "        [-1.7903166 ,  1.9302796 ],\n",
       "        [-2.0144238 ,  2.4037995 ],\n",
       "        [-2.1422117 ,  2.644049  ],\n",
       "        [-1.5853031 ,  1.744725  ],\n",
       "        [-0.8932994 ,  0.7763328 ],\n",
       "        [-2.2246394 ,  2.5352569 ],\n",
       "        [-2.3507419 ,  2.5962722 ],\n",
       "        [-2.1020124 ,  2.249277  ],\n",
       "        [-2.3623953 ,  2.6874375 ],\n",
       "        [-2.3762245 ,  2.538712  ],\n",
       "        [-2.5024822 ,  2.7236185 ],\n",
       "        [ 0.37208435, -0.6854622 ],\n",
       "        [ 1.0054466 , -1.4339105 ],\n",
       "        [ 0.27379256, -0.2950553 ],\n",
       "        [-2.308911  ,  2.7688687 ],\n",
       "        [-2.4650953 ,  2.8028858 ],\n",
       "        [-2.4776344 ,  2.8173928 ],\n",
       "        [-1.6395407 ,  1.937172  ],\n",
       "        [ 1.1750987 , -1.6558716 ],\n",
       "        [ 0.9246322 , -1.3205663 ],\n",
       "        [-2.4617863 ,  2.631422  ],\n",
       "        [-1.4632208 ,  1.3697369 ]], dtype=float32),\n",
       " array([[-1.626971  ,  1.7132456 ],\n",
       "        [-1.2646596 ,  1.2431095 ],\n",
       "        [-2.2878156 ,  2.7576354 ],\n",
       "        [ 0.2754159 , -0.4407158 ],\n",
       "        [-2.1474519 ,  2.3425975 ],\n",
       "        [-1.9634806 ,  2.0457067 ],\n",
       "        [-0.7899735 ,  0.81934184],\n",
       "        [-2.500197  ,  2.8862047 ],\n",
       "        [-1.9782631 ,  2.2307956 ],\n",
       "        [-1.7540582 ,  2.2333038 ],\n",
       "        [-1.4022814 ,  1.4494742 ],\n",
       "        [-2.6506934 ,  2.956563  ],\n",
       "        [-2.2760081 ,  2.6713557 ],\n",
       "        [-2.223134  ,  2.654318  ],\n",
       "        [-1.8895155 ,  2.2252212 ],\n",
       "        [-2.0447593 ,  2.2244186 ],\n",
       "        [-1.5853248 ,  1.8376163 ],\n",
       "        [ 0.9941195 , -1.1325132 ],\n",
       "        [-1.5178888 ,  1.770246  ],\n",
       "        [-1.7151966 ,  2.154763  ],\n",
       "        [ 1.0303812 , -1.3019904 ],\n",
       "        [ 0.19962606, -0.41342282],\n",
       "        [-1.6620266 ,  2.000932  ],\n",
       "        [-1.1213043 ,  1.1926945 ],\n",
       "        [-2.3360293 ,  2.676083  ],\n",
       "        [-2.5140574 ,  3.0076199 ],\n",
       "        [-1.9340813 ,  2.609964  ],\n",
       "        [-2.5833082 ,  2.766841  ],\n",
       "        [-2.4080415 ,  2.6979966 ],\n",
       "        [-2.2525566 ,  2.3157701 ],\n",
       "        [ 1.6685793 , -2.168034  ],\n",
       "        [-2.3231754 ,  2.366732  ]], dtype=float32),\n",
       " array([[-2.0806136,  2.3612697],\n",
       "        [-1.9293194,  2.1509569],\n",
       "        [-2.0919232,  2.23616  ],\n",
       "        [-1.6996174,  1.9023707],\n",
       "        [-2.4552162,  2.708858 ],\n",
       "        [ 1.6486763, -2.098821 ],\n",
       "        [ 1.8366332, -2.3138735],\n",
       "        [ 1.5586251, -1.9085104],\n",
       "        [ 1.7472988, -2.1724348],\n",
       "        [ 1.4217492, -1.7167002],\n",
       "        [-2.38266  ,  2.672446 ],\n",
       "        [-1.6814066,  2.0333478],\n",
       "        [-1.4013581,  1.6863369],\n",
       "        [ 1.6113958, -2.0280242],\n",
       "        [-2.2135987,  2.7430513],\n",
       "        [ 1.0611959, -1.3266914],\n",
       "        [-2.3556757,  2.5463524],\n",
       "        [-1.7650075,  2.0802374],\n",
       "        [-2.4325018,  2.8639636],\n",
       "        [-2.5601566,  2.958826 ],\n",
       "        [ 1.9736347, -2.466242 ],\n",
       "        [ 1.8380297, -2.4238808],\n",
       "        [ 1.7714231, -2.339791 ],\n",
       "        [-2.172434 ,  2.4621253],\n",
       "        [-2.1929216,  2.6001143],\n",
       "        [-2.6587486,  3.011967 ],\n",
       "        [-2.3053432,  2.8068118],\n",
       "        [ 1.3202088, -1.6519817],\n",
       "        [-2.276572 ,  2.839528 ],\n",
       "        [-2.386942 ,  2.8072865],\n",
       "        [-2.3679972,  2.6813836],\n",
       "        [-1.4293729,  1.5107026]], dtype=float32),\n",
       " array([[-2.5867941 ,  2.918892  ],\n",
       "        [ 1.7448065 , -2.12888   ],\n",
       "        [-2.4304786 ,  2.7832432 ],\n",
       "        [-2.173211  ,  2.629909  ],\n",
       "        [-2.012831  ,  2.139105  ],\n",
       "        [-2.3600178 ,  2.5945249 ],\n",
       "        [-1.1959717 ,  0.8743123 ],\n",
       "        [-2.282644  ,  2.6329646 ],\n",
       "        [-2.2672982 ,  2.388097  ],\n",
       "        [-2.149234  ,  2.339432  ],\n",
       "        [-0.19077648, -0.12423919],\n",
       "        [-1.0662425 ,  0.82744765],\n",
       "        [-2.340626  ,  2.565276  ],\n",
       "        [-2.4342628 ,  2.8492174 ],\n",
       "        [ 1.1885078 , -1.7356808 ],\n",
       "        [-1.6992254 ,  1.5931164 ],\n",
       "        [-2.5102713 ,  2.9277544 ],\n",
       "        [-2.3549151 ,  2.71067   ],\n",
       "        [-2.4185395 ,  2.747932  ],\n",
       "        [-2.166633  ,  2.5950925 ],\n",
       "        [-2.5309067 ,  2.9488523 ],\n",
       "        [ 1.009684  , -1.229757  ],\n",
       "        [-0.9370175 ,  1.1796315 ],\n",
       "        [-2.030025  ,  2.5347674 ],\n",
       "        [-2.5092444 ,  2.6896172 ],\n",
       "        [-2.4126623 ,  2.6111789 ],\n",
       "        [-2.38537   ,  2.62493   ],\n",
       "        [-0.9939201 ,  0.83254963],\n",
       "        [-2.2130046 ,  2.7150884 ],\n",
       "        [-2.466955  ,  2.8624258 ],\n",
       "        [ 0.73101664, -1.0040889 ],\n",
       "        [-2.5856385 ,  2.9198647 ]], dtype=float32),\n",
       " array([[-0.48397624,  0.20382121],\n",
       "        [-2.304213  ,  2.8124304 ],\n",
       "        [-2.4649568 ,  2.9436095 ],\n",
       "        [-1.8201818 ,  2.372334  ],\n",
       "        [-1.5395701 ,  2.0849109 ],\n",
       "        [-1.9973034 ,  2.5301409 ],\n",
       "        [-0.31919876,  0.06808255],\n",
       "        [-2.0108027 ,  2.4951167 ],\n",
       "        [-1.8956966 ,  2.2821836 ],\n",
       "        [-2.5482454 ,  2.8930767 ],\n",
       "        [-2.601513  ,  3.0083642 ],\n",
       "        [-2.408788  ,  2.909691  ],\n",
       "        [-2.5067081 ,  2.800418  ],\n",
       "        [-2.008628  ,  2.534366  ],\n",
       "        [-2.3787186 ,  2.6729102 ],\n",
       "        [-2.4930978 ,  2.7166615 ],\n",
       "        [-2.3614764 ,  2.608131  ],\n",
       "        [-2.002047  ,  2.4758549 ],\n",
       "        [-2.4618611 ,  2.9065027 ],\n",
       "        [-2.5300868 ,  2.9289536 ],\n",
       "        [-2.4143083 ,  2.586397  ],\n",
       "        [-2.347917  ,  2.7501955 ],\n",
       "        [-2.1791372 ,  2.2186139 ],\n",
       "        [-2.448096  ,  2.8854163 ],\n",
       "        [-2.515945  ,  2.8805337 ],\n",
       "        [-2.188083  ,  2.8144019 ],\n",
       "        [-2.1902745 ,  2.5828416 ],\n",
       "        [-2.4921627 ,  2.9636192 ],\n",
       "        [-0.46029222,  0.31218213],\n",
       "        [-1.9233513 ,  2.1275532 ],\n",
       "        [-1.401355  ,  1.4895346 ],\n",
       "        [-2.1157224 ,  2.452818  ]], dtype=float32),\n",
       " array([[ 1.6426553 , -2.0997186 ],\n",
       "        [-2.39921   ,  2.6858823 ],\n",
       "        [ 0.5119543 , -0.9132447 ],\n",
       "        [-2.2854774 ,  2.7239575 ],\n",
       "        [ 0.5455109 , -0.62694144],\n",
       "        [-1.4402639 ,  1.6835514 ],\n",
       "        [-2.5547504 ,  2.963407  ],\n",
       "        [-2.5887504 ,  3.0163627 ],\n",
       "        [-2.455111  ,  2.8960059 ],\n",
       "        [-2.4799907 ,  2.9157276 ],\n",
       "        [-2.5291734 ,  2.921648  ],\n",
       "        [-2.527974  ,  2.8940425 ],\n",
       "        [-2.4926872 ,  2.8618262 ],\n",
       "        [-2.5961328 ,  2.9862845 ],\n",
       "        [-2.4970546 ,  2.924076  ],\n",
       "        [-2.4513984 ,  2.8996265 ],\n",
       "        [-2.5704477 ,  2.9276237 ],\n",
       "        [-2.543376  ,  2.8990579 ],\n",
       "        [-2.4584274 ,  2.885755  ],\n",
       "        [-2.4962225 ,  2.825417  ],\n",
       "        [-2.5166235 ,  2.8875568 ],\n",
       "        [-1.7443001 ,  2.1420064 ],\n",
       "        [-2.2965655 ,  2.7626562 ],\n",
       "        [-1.8687968 ,  2.2552752 ],\n",
       "        [ 0.8543316 , -1.0341389 ],\n",
       "        [-2.4417806 ,  2.9265354 ],\n",
       "        [ 1.9376248 , -2.3878624 ],\n",
       "        [ 1.713655  , -2.1794984 ],\n",
       "        [-2.4931989 ,  2.899822  ],\n",
       "        [ 1.4483235 , -1.7632242 ],\n",
       "        [ 0.24138731, -0.4138474 ],\n",
       "        [-2.229629  ,  2.7025566 ]], dtype=float32),\n",
       " array([[ 1.6213799 , -1.94322   ],\n",
       "        [-1.0972253 ,  1.2145424 ],\n",
       "        [-2.338409  ,  2.8044991 ],\n",
       "        [ 1.7725236 , -2.2176147 ],\n",
       "        [ 1.7166927 , -2.051649  ],\n",
       "        [-1.8629618 ,  1.8190794 ],\n",
       "        [-2.4114833 ,  2.7849345 ],\n",
       "        [-2.5813422 ,  2.924324  ],\n",
       "        [ 1.735807  , -2.1172497 ],\n",
       "        [-1.8159075 ,  1.9970903 ],\n",
       "        [-2.329543  ,  2.6603634 ],\n",
       "        [-2.3080847 ,  2.6641893 ],\n",
       "        [ 0.7009189 , -0.7805312 ],\n",
       "        [ 0.39319143, -0.6030117 ],\n",
       "        [ 0.23416273, -0.57702655],\n",
       "        [-2.5415907 ,  2.944628  ],\n",
       "        [-2.4880574 ,  2.9882343 ],\n",
       "        [ 1.1819179 , -1.3827336 ],\n",
       "        [-2.5117328 ,  2.960934  ],\n",
       "        [-2.5858803 ,  3.008182  ],\n",
       "        [-2.3299565 ,  2.5808234 ],\n",
       "        [ 1.5558941 , -1.8293829 ],\n",
       "        [-2.1923854 ,  2.7055476 ],\n",
       "        [-2.4852114 ,  2.8715057 ],\n",
       "        [ 1.4102058 , -1.9689655 ],\n",
       "        [ 1.5843002 , -2.020809  ],\n",
       "        [ 0.75512946, -1.1422007 ],\n",
       "        [-1.7001832 ,  2.1602192 ],\n",
       "        [-2.1031146 ,  2.6769152 ],\n",
       "        [-0.9714379 ,  0.92220694],\n",
       "        [ 0.22915997, -0.2898143 ],\n",
       "        [-2.396593  ,  2.8943448 ]], dtype=float32),\n",
       " array([[-2.4427762 ,  2.842723  ],\n",
       "        [ 1.7187482 , -2.166018  ],\n",
       "        [-2.5514708 ,  2.8221602 ],\n",
       "        [ 1.6587024 , -2.1470852 ],\n",
       "        [-2.6232765 ,  2.9082394 ],\n",
       "        [ 1.7219425 , -2.0382507 ],\n",
       "        [-2.2781346 ,  2.6711864 ],\n",
       "        [-2.507101  ,  2.931301  ],\n",
       "        [-2.5964808 ,  3.026702  ],\n",
       "        [-1.79041   ,  2.3013544 ],\n",
       "        [-1.0829268 ,  1.1406207 ],\n",
       "        [-2.0938234 ,  2.6439981 ],\n",
       "        [ 0.27727148, -0.6934514 ],\n",
       "        [-0.31957796,  0.49087748],\n",
       "        [-2.536168  ,  3.0122147 ],\n",
       "        [-2.2366729 ,  2.380578  ],\n",
       "        [-2.526219  ,  2.9294822 ],\n",
       "        [-1.860823  ,  2.3396304 ],\n",
       "        [-2.4140959 ,  2.6363025 ],\n",
       "        [-2.4081247 ,  2.6979337 ],\n",
       "        [-2.4535193 ,  2.8532932 ],\n",
       "        [ 1.283401  , -1.4085791 ],\n",
       "        [ 0.4361558 , -0.61735225],\n",
       "        [-0.6805616 ,  0.77950346],\n",
       "        [-2.4827955 ,  2.791777  ],\n",
       "        [-2.2258077 ,  2.7341547 ],\n",
       "        [-2.5281506 ,  2.7757695 ],\n",
       "        [-2.624805  ,  2.9216294 ],\n",
       "        [-2.5438077 ,  2.8349452 ],\n",
       "        [-2.435065  ,  2.8727393 ],\n",
       "        [-2.2368593 ,  2.3884919 ],\n",
       "        [-2.5122426 ,  2.932646  ]], dtype=float32),\n",
       " array([[-2.39614   ,  2.8120537 ],\n",
       "        [ 0.36417535, -0.50549227],\n",
       "        [-2.4336805 ,  2.7800136 ],\n",
       "        [-2.4956205 ,  2.8392558 ],\n",
       "        [-2.037748  ,  2.6732974 ],\n",
       "        [-1.9733455 ,  2.5406122 ],\n",
       "        [-2.5975604 ,  2.8808556 ],\n",
       "        [-2.4950857 ,  2.8308334 ],\n",
       "        [ 1.2655079 , -1.7518928 ],\n",
       "        [-2.4743752 ,  2.816675  ],\n",
       "        [ 1.5808215 , -2.0885594 ],\n",
       "        [ 0.25704235, -0.40832734],\n",
       "        [-1.6028532 ,  1.849175  ],\n",
       "        [-2.5245872 ,  2.8471687 ],\n",
       "        [-2.5399818 ,  2.9957821 ],\n",
       "        [-2.5474434 ,  2.9914541 ],\n",
       "        [-2.6206162 ,  2.958657  ],\n",
       "        [-1.4456754 ,  1.5866381 ],\n",
       "        [-0.8475302 ,  0.9664309 ],\n",
       "        [-2.2332606 ,  2.78343   ],\n",
       "        [ 1.1969084 , -1.2580341 ],\n",
       "        [-1.6076216 ,  1.9758502 ],\n",
       "        [-2.5171041 ,  2.8332243 ],\n",
       "        [-2.5221348 ,  2.966561  ],\n",
       "        [-2.5091653 ,  2.8930788 ],\n",
       "        [-2.356895  ,  2.6763253 ],\n",
       "        [-2.347147  ,  2.8013072 ],\n",
       "        [ 1.7339303 , -2.2395003 ],\n",
       "        [ 1.8118616 , -2.273585  ],\n",
       "        [-2.5394342 ,  2.9725945 ],\n",
       "        [-2.5536532 ,  2.915126  ],\n",
       "        [-2.5140834 ,  2.9391556 ]], dtype=float32),\n",
       " array([[ 1.5413854, -1.9967985],\n",
       "        [ 1.4495852, -1.8306279],\n",
       "        [-2.1869948,  2.5367038],\n",
       "        [-2.5000181,  2.963158 ],\n",
       "        [-1.27816  ,  1.3305027],\n",
       "        [-2.422123 ,  2.7356052],\n",
       "        [-2.2349572,  2.5031626],\n",
       "        [-2.2642999,  2.6571746],\n",
       "        [ 1.5006834, -1.9109505],\n",
       "        [-2.403346 ,  2.8298492],\n",
       "        [ 1.4481599, -1.8066716],\n",
       "        [ 1.8127992, -2.2591805],\n",
       "        [-1.5457695,  1.6862386],\n",
       "        [-2.5325985,  3.0971384],\n",
       "        [-2.4531913,  2.83787  ],\n",
       "        [-1.4733704,  1.6330221],\n",
       "        [-2.5563145,  2.926813 ],\n",
       "        [-2.4339223,  2.86181  ],\n",
       "        [-2.6057003,  2.9486156],\n",
       "        [ 1.8338966, -2.2966719],\n",
       "        [-2.5441446,  2.9180593],\n",
       "        [-2.4988317,  2.9227407],\n",
       "        [-2.5888972,  2.8953216],\n",
       "        [ 1.4477065, -1.7146221],\n",
       "        [-2.5070267,  2.9342177],\n",
       "        [-2.4515536,  2.9298244],\n",
       "        [-2.6144586,  2.997017 ],\n",
       "        [ 1.8431208, -2.3054745],\n",
       "        [ 1.2777195, -1.7420989],\n",
       "        [-2.2631602,  2.5627716],\n",
       "        [-2.4626493,  2.8022122],\n",
       "        [-2.3888469,  2.6954248]], dtype=float32),\n",
       " array([[-2.1599493,  2.6181111],\n",
       "        [-2.3306158,  2.8081613],\n",
       "        [-2.4437232,  2.9455338],\n",
       "        [-2.262906 ,  2.7267878],\n",
       "        [ 1.6377919, -2.0837793],\n",
       "        [ 1.4424825, -1.7094977],\n",
       "        [-2.3329525,  2.814401 ],\n",
       "        [-2.36363  ,  2.8199098],\n",
       "        [-2.5854263,  2.9404283],\n",
       "        [-2.4935343,  2.937303 ],\n",
       "        [-2.4058785,  2.9021   ],\n",
       "        [-1.9282744,  2.6536846],\n",
       "        [-2.1784902,  2.4895945],\n",
       "        [-1.6200206,  1.9258386],\n",
       "        [-2.5681796,  2.85097  ],\n",
       "        [-2.2013056,  2.7537746],\n",
       "        [-2.3935993,  2.8244617],\n",
       "        [-2.3988483,  2.7132688],\n",
       "        [-2.593963 ,  3.0497475],\n",
       "        [-1.5412056,  1.5051297],\n",
       "        [ 1.9715028, -2.3234117],\n",
       "        [-1.4378755,  1.7928528],\n",
       "        [-2.3783526,  2.910622 ],\n",
       "        [-2.333753 ,  2.8300867],\n",
       "        [-1.2790911,  1.5533113],\n",
       "        [ 1.1062753, -1.2062781],\n",
       "        [-2.484734 ,  2.905394 ],\n",
       "        [-2.5234501,  2.90793  ],\n",
       "        [-2.4744742,  2.795164 ],\n",
       "        [ 1.7945256, -2.1954994],\n",
       "        [ 1.9526408, -2.373707 ],\n",
       "        [ 1.8838536, -2.3342369]], dtype=float32),\n",
       " array([[-2.3432379 ,  2.8162396 ],\n",
       "        [-2.492991  ,  3.071449  ],\n",
       "        [-2.4998922 ,  3.0334902 ],\n",
       "        [-2.5476086 ,  2.9873013 ],\n",
       "        [ 1.8283461 , -2.1737018 ],\n",
       "        [-1.4342517 ,  1.872471  ],\n",
       "        [-2.6141257 ,  2.9642587 ],\n",
       "        [-2.466249  ,  2.8157449 ],\n",
       "        [-2.4660835 ,  2.9306276 ],\n",
       "        [-2.3310375 ,  2.9126287 ],\n",
       "        [ 1.8218226 , -2.1535509 ],\n",
       "        [-2.330502  ,  2.95127   ],\n",
       "        [-2.5878963 ,  2.8741126 ],\n",
       "        [-2.4900975 ,  2.8065457 ],\n",
       "        [-2.4964554 ,  2.8748593 ],\n",
       "        [ 0.7089265 , -0.9619961 ],\n",
       "        [-1.6335251 ,  2.0103564 ],\n",
       "        [ 1.6590912 , -2.2109716 ],\n",
       "        [-2.5173898 ,  2.9062676 ],\n",
       "        [-2.420661  ,  2.871552  ],\n",
       "        [-2.3804557 ,  3.0477405 ],\n",
       "        [-2.48801   ,  2.6712668 ],\n",
       "        [-2.645145  ,  3.084525  ],\n",
       "        [-2.5447104 ,  2.9880958 ],\n",
       "        [-0.7446896 ,  0.90387726],\n",
       "        [ 0.9290718 , -1.1324986 ],\n",
       "        [ 1.5762333 , -2.00812   ],\n",
       "        [-2.3269794 ,  2.8855734 ],\n",
       "        [-1.887756  ,  2.3497367 ],\n",
       "        [ 0.47434282, -0.7174437 ],\n",
       "        [-1.6738698 ,  2.1135125 ],\n",
       "        [-2.225768  ,  2.3529563 ]], dtype=float32),\n",
       " array([[ 0.06453387, -0.27237925],\n",
       "        [-2.4932106 ,  2.8762608 ],\n",
       "        [ 0.745828  , -0.8272947 ],\n",
       "        [ 0.9145147 , -1.2367401 ],\n",
       "        [-2.171601  ,  2.53351   ],\n",
       "        [ 1.8099229 , -2.2510715 ],\n",
       "        [ 1.4456177 , -1.5573568 ],\n",
       "        [ 1.6342742 , -1.8623494 ],\n",
       "        [-2.5580387 ,  3.0640922 ],\n",
       "        [ 1.1923685 , -1.5493858 ],\n",
       "        [ 1.3805776 , -1.67398   ],\n",
       "        [-2.4884672 ,  2.839306  ],\n",
       "        [-1.9573706 ,  2.382556  ],\n",
       "        [ 1.7483011 , -2.20291   ],\n",
       "        [-1.8095458 ,  2.291113  ],\n",
       "        [-2.0175261 ,  2.4100323 ],\n",
       "        [-1.5517018 ,  2.1665444 ],\n",
       "        [-2.001374  ,  2.309156  ],\n",
       "        [ 0.9851122 , -1.330194  ],\n",
       "        [-2.1063335 ,  2.2224517 ],\n",
       "        [-2.5119843 ,  2.7302518 ],\n",
       "        [ 0.42191994, -0.6084829 ],\n",
       "        [-2.5266824 ,  2.9675908 ],\n",
       "        [-1.4091944 ,  1.5638717 ],\n",
       "        [-0.7050028 ,  0.6958923 ],\n",
       "        [-1.9248267 ,  2.0182986 ],\n",
       "        [-2.275723  ,  2.8608613 ],\n",
       "        [-2.3081546 ,  2.8320427 ],\n",
       "        [-2.0229328 ,  2.5053694 ],\n",
       "        [-2.1789079 ,  2.7056105 ],\n",
       "        [-1.8022779 ,  2.0852766 ],\n",
       "        [-2.44597   ,  2.9488618 ]], dtype=float32),\n",
       " array([[-2.4439073,  2.9909613],\n",
       "        [-2.562238 ,  3.073948 ],\n",
       "        [-2.367277 ,  3.0135298],\n",
       "        [-2.095732 ,  2.542016 ]], dtype=float32)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 0, 0, 0, 1]),\n",
       " array([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0]),\n",
       " array([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 1, 1, 0]),\n",
       " array([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1]),\n",
       " array([0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 0, 1]),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 1, 1, 0, 1]),\n",
       " array([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 1, 1]),\n",
       " array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0]),\n",
       " array([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 0, 1, 1])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.566\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8217054263565892"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(flat_true_labels, flat_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty good performance. Note that we used [Matthews Correlation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) to meausure this. It ranges from -1 to 1, with +1 being the best. The Google BERT model has a similar score too, so this model performed quite well. It took a long time though, approximately a day with no GPU. It would be significantly faster if a CUDA enabled machine ran this. Hence, we recommend that you run this on the Collab notebook.\n",
    "\n",
    "The following lines save the model to disk, if you would like to: note that we ran this in the colab file to save it to disk there as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did this in google colab\n",
    "# import os\n",
    "\n",
    "# # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "#output_dir = './model_save/'\n",
    "\n",
    "# # Create output directory if needed\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "#print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# # They can then be reloaded using `from_pretrained()`\n",
    "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "# model_to_save.save_pretrained(output_dir)\n",
    "# tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# # Good practice: save your training arguments together with the trained model\n",
    "# # torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"..data/cola_public/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings, Context Words\n",
    "\n",
    "We saw how a bootstrapped BERT model performed so much better than a model trained from scatch. Because BERT's method of capturing context is bidirectional, meaning that words can now have different word embedding values based on their location within a sentence. Let us use the same BERT model to capture sentence and word embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through the sentence format for the BERT model, as well as how our vocabulary looks like. Note that you have to use the BERT tokenizer to use the BERT model because of the similar vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTS model uses a WordPiece technique to do its tokenizing, as described in the paper. That's why the word embedding is split up the way it is.\n",
    "A quick peek at what the voabulary looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peninsula',\n",
       " 'adults',\n",
       " 'novels',\n",
       " 'emerged',\n",
       " 'vienna',\n",
       " 'metro',\n",
       " 'debuted',\n",
       " 'shoes',\n",
       " 'tamil',\n",
       " 'songwriter',\n",
       " 'meets',\n",
       " 'prove',\n",
       " 'beating',\n",
       " 'instance',\n",
       " 'heaven',\n",
       " 'scared',\n",
       " 'sending',\n",
       " 'marks',\n",
       " 'artistic',\n",
       " 'passage',\n",
       " 'superior',\n",
       " '03',\n",
       " 'significantly',\n",
       " 'shopping',\n",
       " '##tive',\n",
       " 'retained',\n",
       " '##izing',\n",
       " 'malaysia',\n",
       " 'technique',\n",
       " 'cheeks']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[6000:6030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Judge Walker had suggested that the group lacked standing because he found no harm caused by granting queer people the right to marry.\"\n",
    "\n",
    "marked_text2 = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text2 = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens2 = tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "judge         3,648\n",
      "walker        5,232\n",
      "had           2,018\n",
      "suggested     4,081\n",
      "that          2,008\n",
      "the           1,996\n",
      "group         2,177\n",
      "lacked       10,858\n",
      "standing      3,061\n",
      "because       2,138\n",
      "he            2,002\n",
      "found         2,179\n",
      "no            2,053\n",
      "harm          7,386\n",
      "caused        3,303\n",
      "by            2,011\n",
      "granting     15,080\n",
      "gay           5,637\n",
      "people        2,111\n",
      "the           1,996\n",
      "right         2,157\n",
      "to            2,000\n",
      "marry         5,914\n",
      ".             1,012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "#text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "text = \"Judge Walker had suggested that the group lacked standing because he found no harm caused by granting gay people the right to marry.\"\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indices.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 3648,\n",
       " 5232,\n",
       " 2018,\n",
       " 4081,\n",
       " 2008,\n",
       " 1996,\n",
       " 2177,\n",
       " 10858,\n",
       " 3061,\n",
       " 2138,\n",
       " 2002,\n",
       " 2179,\n",
       " 2053,\n",
       " 7386,\n",
       " 3303,\n",
       " 2011,\n",
       " 15080,\n",
       " 5637,\n",
       " 2111,\n",
       " 1996,\n",
       " 2157,\n",
       " 2000,\n",
       " 5914,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment ID\n",
    "\n",
    "BERT is trained on and expects sentence pairs, using 1s and 0s to distinguish between the two sentences. That is, for each token in â€œtokenized_text,â€ we must specify which sentence it belongs to: sentence 0 (a series of 0s) or sentence 1 (a series of 1s). For our purposes, single-sentence inputs only require a series of 1s, so we will create a vector of 1s for each token in our input sentence.\n",
    "\n",
    "If you want to process two sentences, assign each word in the first sentence plus the â€˜[SEP]â€™ token a 0, and all tokens of the second sentence a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids2 = [0] *  len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens_compare = indexed_tokens + indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids_compare = segments_ids + segment_ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 3648,\n",
       " 5232,\n",
       " 2018,\n",
       " 4081,\n",
       " 2008,\n",
       " 1996,\n",
       " 2177,\n",
       " 10858,\n",
       " 3061,\n",
       " 2138,\n",
       " 2002,\n",
       " 2179,\n",
       " 2053,\n",
       " 7386,\n",
       " 3303,\n",
       " 2011,\n",
       " 15080,\n",
       " 5637,\n",
       " 2111,\n",
       " 1996,\n",
       " 2157,\n",
       " 2000,\n",
       " 5914,\n",
       " 1012,\n",
       " 102,\n",
       " 101,\n",
       " 3648,\n",
       " 5232,\n",
       " 2018,\n",
       " 4081,\n",
       " 2008,\n",
       " 1996,\n",
       " 2177,\n",
       " 10858,\n",
       " 3061,\n",
       " 2138,\n",
       " 2002,\n",
       " 2179,\n",
       " 2053,\n",
       " 7386,\n",
       " 3303,\n",
       " 2011,\n",
       " 15080,\n",
       " 5637,\n",
       " 2111,\n",
       " 1996,\n",
       " 2157,\n",
       " 2000,\n",
       " 5914,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did for classification, we now convert these segments to tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding layer is the hidden state layer, and this is what we pick up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens_compare])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afba623463a4c6cb96e9bb0bd2281d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099027b6c0934436b74e0f550d5b9219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "#model_embedding = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "#model_embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_embedding(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[0][0][0]), len(output[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Output\n",
    "\n",
    "This kind of forward pass returns us the last layer of the net, which we will use to make our vectors. The first object returned contains the batch number, followed by each of the tokens and their vector values. The second object contains a vector value, which I suspect is the sentence vector of the tokens. \n",
    "\n",
    "The first index is the batch size, and our batch size is 1, so we just choose the 0th index and work with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, use the pipeline functions or the word or sentence vector functions (e.g., similarity) to explore the social game underlying the production and meaning of texts associated with your final project. You have used similar, but often weaker versions in previous weeks. How does BERT help you gain insight regarding your research question that is similar and different from prior methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 2 Write-Up (Code Below)*</span>\n",
    "\n",
    "In my project I am attempting to do the following: \n",
    "- Study how the description of LGBTQ groups have changed over the last 20 years in literature and the broader culture.\n",
    "- Quantify the change over time using word embeddings to analyze biases in adjectives describing LGBTQ groups\n",
    "- Determine where various words related to sexual orientation and gender identity (Aggressive, stud, butch, androgynous, bigender, agender, etc.) are located on the cultural dimensions of race, class and gender\n",
    "- Detect linguistic shifts in the meaning of transgender and queer over the last 20 years\n",
    "\n",
    "I wanted to use BERT to investigate semantic similarities of sentences using the words queer and gay in my corpus, and understand how these different words in the same context could change BERT's understanding of the sentiment of the sentence and the meaning of the sentence. In my code found this sentence in my corpus:  â€œJudge Walker had suggested that the group lacked standing because he found no harm caused by granting gay people the right to marry.â€\n",
    "\n",
    "I then switched out the word gay for queer in the sentence, and analyzed how the sentiment of the sentence and the meaning changed. I found that the sentence using queer lies far away in semantic space to the same sentence using gay! I believe this implies that the words changed the meaning of the sentence quite dramatically. Using the word queer also made the sentiment of the sentence slightly more positive. \n",
    "\n",
    "I also thought it would be interesting to look at how the BERT model could identify the sentiment of a sentence if many 'negative' words were used in it, even if it had a positive meaning overall. I used words/sentences within the LGBTQ lexicon to investigate. \n",
    "\n",
    "I worked with this sentece: \"The show was conceived, said Gonzalo Casals, the museum director, as an intimate platform for artwork that holds up a mirror to the lives of sex workers in the L.G.B.T.Q. community, some pieces by artists who themselves worked as prostitutes.\"\n",
    "\n",
    "BERT classifies the words prostitutes and sex workers has highly negative, but identified the sentence as being positive. Cool! BERT is obvioulsy good and identifying context of a sentence\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings, sentence_embedding = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4323, -0.1664, -0.6218,  ..., -0.1718,  0.1952,  0.4205],\n",
       "        [ 0.4478, -0.4209, -0.3102,  ..., -0.0591,  0.9497, -0.5697],\n",
       "        [ 0.7333, -0.1828, -0.4000,  ...,  0.0864, -0.4870, -0.1581],\n",
       "        ...,\n",
       "        [ 1.6263,  0.4086,  0.7332,  ..., -0.8292,  0.3163, -0.0532],\n",
       "        [ 0.6933,  0.1688, -0.2805,  ...,  0.3156, -0.2754, -0.2117],\n",
       "        [ 0.5493,  0.2476, -0.1886,  ...,  0.3532, -0.5498, -0.1831]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s take a quick look at the range of values for a given layer and token.\n",
    "\n",
    "Youâ€™ll find that the range is fairly similar for all layers and tokens, with the majority of values falling between [-2, 2], and a small smattering of values around -10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = word_embeddings[0][0]\n",
    "vec = vec.detach().numpy()\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are grouped by layer - we can use the permute function to make it grouped by each individual token instead. Let us look at what the later looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors\n",
    "\n",
    "So each of those tokens have embedding values - let us try and compare them with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 52, 768])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vecs = []\n",
    "# For each token in the sentence...\n",
    "for embedding in word_embeddings[0]:\n",
    "    cat_vec = embedding.detach().numpy()\n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs.append(cat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.8154e-01, -4.8191e-01, -9.5558e-01,  7.0310e-01,  8.0981e-01,\n",
       "         -2.0727e-01,  6.2650e-01,  2.8391e-01, -8.6687e-01, -9.9997e-01,\n",
       "         -6.4925e-01,  9.7543e-01,  9.6107e-01,  5.5462e-01,  7.0953e-01,\n",
       "         -6.4091e-01, -5.9326e-01, -5.5313e-01,  4.3453e-01,  4.2118e-01,\n",
       "          3.7870e-01,  1.0000e+00, -2.5453e-01,  1.6822e-01,  4.0132e-01,\n",
       "          9.8343e-01, -7.6134e-01,  7.3326e-01,  9.1786e-01,  6.2285e-01,\n",
       "         -4.4070e-01,  3.4793e-01, -9.8615e-01, -1.1608e-01, -9.5848e-01,\n",
       "         -9.9037e-01,  5.1258e-01, -4.2681e-01,  2.0660e-01, -1.5951e-01,\n",
       "         -7.0017e-01,  2.7608e-01,  9.9999e-01, -5.1135e-01,  6.9867e-01,\n",
       "         -1.6588e-01, -1.0000e+00,  3.7266e-01, -7.4756e-01,  9.1981e-01,\n",
       "          8.7197e-01,  9.6612e-01,  3.1925e-01,  5.1414e-01,  5.2147e-01,\n",
       "         -7.6341e-01,  9.9657e-02,  2.2467e-01, -2.7184e-01, -6.1230e-01,\n",
       "         -5.4873e-01,  3.4441e-01, -8.7648e-01, -8.5492e-01,  9.5744e-01,\n",
       "          8.4266e-01, -4.0202e-01, -4.6886e-01, -1.9025e-01, -2.3102e-01,\n",
       "          8.0108e-01,  2.5497e-01, -4.5127e-01, -4.6548e-01,  7.2718e-01,\n",
       "          1.6574e-01, -6.2629e-01,  1.0000e+00, -1.7980e-01, -9.3916e-01,\n",
       "          9.6057e-01,  8.9190e-01,  5.2649e-01, -4.8533e-01,  4.2792e-01,\n",
       "         -1.0000e+00,  6.9053e-01, -7.4276e-02, -9.7387e-01,  3.3793e-01,\n",
       "          6.5830e-01, -4.7957e-01,  8.4961e-01,  5.4268e-01, -6.0639e-01,\n",
       "         -6.8234e-01, -3.3189e-01, -8.5770e-01, -2.5887e-01, -5.1808e-01,\n",
       "          2.5951e-01, -3.6352e-01, -4.2675e-01, -4.3690e-01,  4.3038e-01,\n",
       "         -5.9467e-01,  6.5477e-02,  6.0034e-01,  1.2714e-01,  7.2790e-01,\n",
       "          4.7253e-01, -3.6136e-01,  4.7419e-01, -8.6436e-01,  5.7207e-01,\n",
       "         -4.1517e-01, -9.8236e-01, -5.6126e-01, -9.7769e-01,  6.3345e-01,\n",
       "         -3.6226e-01, -2.9253e-01,  6.8416e-01, -4.4683e-01,  4.0921e-01,\n",
       "         -1.9560e-01, -9.7448e-01, -1.0000e+00, -6.9966e-01, -6.5210e-01,\n",
       "         -4.5441e-01, -3.9933e-01, -9.5381e-01, -9.4003e-01,  6.5453e-01,\n",
       "          8.3656e-01,  3.4708e-01,  9.9984e-01, -5.0172e-01,  8.9453e-01,\n",
       "         -4.6286e-01, -9.1849e-01,  7.5453e-01, -4.7475e-01,  7.7058e-01,\n",
       "          2.4726e-01, -2.0372e-01,  3.0614e-01, -6.4736e-01,  3.9786e-01,\n",
       "         -8.6997e-01, -4.1435e-01, -8.7540e-01, -6.4895e-01, -4.1947e-01,\n",
       "          7.6481e-01, -7.1249e-01, -9.6860e-01, -3.3936e-01, -3.3092e-01,\n",
       "         -3.9271e-01,  5.6066e-01,  8.3440e-01,  5.1750e-01, -2.8984e-01,\n",
       "          5.2132e-01,  1.7205e-01,  5.3244e-01, -7.2978e-01, -4.0630e-01,\n",
       "          5.8663e-01, -3.8302e-01, -8.9262e-01, -9.6680e-01, -5.0261e-01,\n",
       "          3.9369e-01,  9.7180e-01,  6.5950e-01,  3.4164e-01,  8.8073e-01,\n",
       "         -3.9859e-01,  8.0083e-01, -9.2634e-01,  9.6970e-01, -2.0508e-01,\n",
       "          3.9779e-01, -7.4563e-01,  5.9100e-01, -6.2579e-01,  6.1283e-02,\n",
       "          7.6980e-01, -7.1703e-01, -6.7265e-01, -2.8766e-01, -4.8789e-01,\n",
       "         -4.0705e-01, -9.0054e-01,  5.8714e-01, -3.1415e-01, -2.5035e-01,\n",
       "         -9.5974e-02,  7.0557e-01,  8.9061e-01,  4.4857e-01,  5.4888e-01,\n",
       "          5.8062e-01, -7.1969e-01, -8.1573e-02,  1.5762e-01,  2.0119e-01,\n",
       "          1.7354e-01,  9.7675e-01, -9.1012e-01, -1.1493e-01, -7.5861e-01,\n",
       "         -9.4558e-01,  1.1821e-01, -7.6992e-01, -3.2269e-01, -6.3272e-01,\n",
       "          6.3635e-01, -6.7325e-01,  3.8649e-01,  2.8090e-01, -1.6048e-01,\n",
       "         -6.0506e-01,  3.7215e-01, -4.4734e-01,  3.4538e-01, -2.5186e-01,\n",
       "          9.5732e-01,  9.2857e-01, -6.4716e-01, -2.1257e-01,  9.2611e-01,\n",
       "         -9.7183e-01, -6.7834e-01,  2.9988e-02, -3.0601e-01,  7.8723e-01,\n",
       "         -6.4685e-01,  9.7073e-01,  9.3798e-01,  7.2976e-01, -8.3854e-01,\n",
       "         -8.8359e-01, -7.0035e-01, -7.5367e-01, -1.6775e-01, -1.7432e-01,\n",
       "          9.2593e-01,  5.6173e-01,  4.2266e-01,  3.9529e-01, -5.6579e-01,\n",
       "          9.5450e-01, -9.0385e-01, -9.0240e-01, -8.9134e-01, -2.9030e-01,\n",
       "         -9.7710e-01,  8.6522e-01,  2.9160e-01,  5.8798e-01, -5.4932e-01,\n",
       "         -7.4110e-01, -9.0118e-01,  3.4875e-01,  3.1963e-01,  8.5421e-01,\n",
       "         -6.9041e-01, -7.2139e-01, -6.4235e-01, -7.8540e-01, -4.0201e-02,\n",
       "         -1.9107e-01, -5.5190e-01,  1.4257e-01, -7.4494e-01,  4.9533e-01,\n",
       "          4.0023e-01,  5.0497e-01, -9.3833e-01,  9.9147e-01,  1.0000e+00,\n",
       "          9.6088e-01,  6.7853e-01,  5.6748e-01, -9.9997e-01, -8.7719e-01,\n",
       "          9.9999e-01, -9.9587e-01, -1.0000e+00, -8.2523e-01, -6.4905e-01,\n",
       "          2.7228e-01, -1.0000e+00, -3.0818e-01, -1.1146e-02, -7.2296e-01,\n",
       "          7.9456e-01,  9.1723e-01,  9.1179e-01, -1.0000e+00,  8.3375e-01,\n",
       "          8.3808e-01, -5.8687e-01,  9.5939e-01, -4.5568e-01,  9.4791e-01,\n",
       "          7.2455e-01,  7.5505e-01, -3.2541e-01,  3.9638e-01, -9.7617e-01,\n",
       "         -7.2487e-01, -7.6592e-01, -8.9412e-01,  9.9956e-01,  9.5613e-02,\n",
       "         -7.4999e-01, -6.5053e-01,  8.3267e-01, -5.3260e-04,  1.9933e-03,\n",
       "         -9.2410e-01, -4.4377e-01,  8.3812e-01,  7.3588e-01,  1.8654e-01,\n",
       "          4.8484e-01, -4.5564e-01,  4.3341e-01,  1.8699e-01, -2.8381e-01,\n",
       "          5.9371e-01, -8.6220e-01, -1.4991e-01,  2.7948e-01,  4.1041e-01,\n",
       "         -7.1822e-01, -9.4212e-01,  8.7524e-01, -4.0819e-01,  9.6215e-01,\n",
       "          1.0000e+00,  7.9248e-01, -5.3372e-01,  6.8263e-01,  3.8803e-01,\n",
       "         -7.5426e-01,  1.0000e+00,  8.1935e-01, -9.4903e-01, -5.3794e-01,\n",
       "          6.5374e-01, -6.3365e-01, -6.5926e-01,  9.9934e-01, -2.7860e-01,\n",
       "         -8.5629e-01, -6.8395e-01,  9.7624e-01, -9.7688e-01,  9.9888e-01,\n",
       "         -6.5138e-01, -9.1106e-01,  8.8947e-01,  8.1466e-01, -7.7341e-01,\n",
       "         -5.9641e-01,  1.2562e-01, -7.1007e-01,  4.7355e-01, -6.8207e-01,\n",
       "          8.6659e-01,  3.4949e-01,  5.4585e-04,  6.9132e-01, -4.6054e-01,\n",
       "         -4.7587e-01,  5.0279e-01, -8.0558e-01, -5.7794e-01,  9.6336e-01,\n",
       "          4.9802e-01, -6.1885e-02,  2.3267e-01, -3.5537e-01, -8.7374e-01,\n",
       "         -8.9499e-01,  8.3521e-01,  1.0000e+00, -4.6283e-01,  8.7869e-01,\n",
       "         -6.2745e-01, -5.3796e-02, -1.0900e-01,  5.7785e-01,  6.0077e-01,\n",
       "         -3.6229e-01, -6.7708e-01,  8.3500e-01, -5.9877e-01, -9.8850e-01,\n",
       "          1.5299e-01,  2.2092e-01, -2.5645e-01,  9.9999e-01,  5.8848e-01,\n",
       "          3.4202e-01,  4.5481e-01,  9.8510e-01,  8.2778e-02,  1.5335e-01,\n",
       "          9.1499e-01,  9.6584e-01, -3.7703e-01,  5.5295e-01,  3.0944e-01,\n",
       "         -9.5198e-01, -1.9347e-01, -6.7800e-01,  3.3426e-02, -8.5396e-01,\n",
       "         -6.1397e-02, -8.6169e-01,  9.2340e-01,  9.7167e-01,  4.3371e-01,\n",
       "          2.0387e-01,  9.1307e-01,  1.0000e+00, -9.7983e-01,  4.5660e-01,\n",
       "          6.1224e-01, -1.2443e-01, -9.9995e-01, -2.7377e-01, -3.5788e-01,\n",
       "         -1.9606e-01, -8.6011e-01, -3.1266e-01,  2.7453e-01, -9.1419e-01,\n",
       "          8.8505e-01,  7.8926e-01, -6.1234e-01, -9.7321e-01, -5.8607e-01,\n",
       "          7.4726e-01,  4.0884e-01, -9.9334e-01, -7.0288e-01, -5.1454e-01,\n",
       "          8.0032e-01, -4.0131e-01, -7.6089e-01, -5.8001e-01, -4.2328e-01,\n",
       "          4.7071e-01, -3.7606e-01,  4.9902e-01,  9.0757e-01,  8.5229e-01,\n",
       "         -9.5473e-01, -6.7419e-01, -3.2768e-01, -7.7957e-01,  6.4561e-01,\n",
       "         -5.6719e-01, -9.5503e-01, -2.3232e-01,  1.0000e+00, -6.5489e-01,\n",
       "          9.3843e-01,  2.9279e-01,  2.2581e-01, -4.6198e-01,  2.6525e-01,\n",
       "          9.5137e-01,  3.4758e-01, -7.0138e-01, -9.2670e-01,  4.4736e-01,\n",
       "         -4.1619e-01,  5.6197e-01,  9.0525e-01,  7.6659e-01,  6.5945e-01,\n",
       "          9.5692e-01,  3.3671e-01, -1.1986e-01,  8.2292e-02,  9.8869e-01,\n",
       "         -1.8799e-01, -3.1139e-01, -5.2272e-01, -2.6066e-01, -5.0912e-01,\n",
       "          5.4177e-01,  1.0000e+00,  3.9300e-01,  7.7547e-01, -9.8741e-01,\n",
       "         -9.4111e-01, -7.5328e-01,  1.0000e+00,  7.7296e-01, -7.3063e-01,\n",
       "          7.3171e-01,  5.6497e-01, -3.5417e-01,  2.5195e-01, -4.1572e-01,\n",
       "         -2.8357e-01,  2.2267e-01,  1.2359e-01,  8.8818e-01, -5.4284e-01,\n",
       "         -9.6015e-01, -6.6396e-01,  4.6191e-01, -8.7685e-01,  9.9999e-01,\n",
       "         -7.0114e-01, -4.8379e-01, -3.8227e-01, -5.9333e-01, -8.2201e-01,\n",
       "          4.4814e-02, -9.5046e-01, -2.4614e-01,  1.3336e-01,  9.1676e-01,\n",
       "          2.6326e-01, -4.6813e-01, -6.1236e-01,  9.1378e-01,  8.4792e-01,\n",
       "         -9.3707e-01, -8.2245e-01,  9.0977e-01, -8.2438e-01,  5.3672e-01,\n",
       "          1.0000e+00,  5.7783e-01,  3.0560e-01,  5.0748e-01, -3.9977e-01,\n",
       "          4.4463e-01, -5.9661e-01,  4.6836e-01, -7.8458e-01, -1.7582e-01,\n",
       "         -3.8380e-01,  5.1935e-01, -8.8867e-02, -9.4681e-01,  5.1127e-01,\n",
       "          1.8757e-02, -4.9556e-01, -5.9518e-01, -2.9982e-01,  6.1652e-01,\n",
       "          8.5234e-01, -3.0308e-01, -2.8224e-01,  2.0303e-01, -1.0234e-01,\n",
       "         -5.8927e-01, -5.4449e-01, -5.5293e-01, -1.0000e+00,  5.5083e-01,\n",
       "         -1.0000e+00,  7.6577e-01,  3.6194e-01, -2.9284e-01,  6.3506e-01,\n",
       "          7.8707e-01,  9.4185e-01, -4.7871e-01, -9.3012e-01,  3.7891e-01,\n",
       "          6.0485e-01, -4.5784e-01, -5.1538e-01, -2.9557e-01,  2.8267e-01,\n",
       "         -4.3862e-02,  1.6339e-01, -6.4443e-01,  6.6181e-01, -2.6400e-01,\n",
       "          1.0000e+00,  2.2942e-01, -6.2798e-01, -6.0376e-01,  3.8758e-01,\n",
       "         -2.7591e-01,  1.0000e+00, -6.3941e-01, -9.3477e-01,  2.7774e-01,\n",
       "         -8.0129e-01, -5.3020e-01,  3.5418e-01,  2.8510e-01, -8.1568e-01,\n",
       "         -9.7838e-01,  5.1432e-01,  8.0497e-01, -6.6244e-01,  7.7751e-01,\n",
       "         -4.3733e-01, -6.7702e-01,  8.9557e-02,  9.0308e-01,  9.6238e-01,\n",
       "          6.5269e-01,  6.7562e-01, -8.6425e-01, -6.8105e-01,  8.8221e-01,\n",
       "          2.0719e-01, -5.2430e-02,  2.0608e-02,  1.0000e+00,  3.5198e-01,\n",
       "         -8.4004e-01, -9.4981e-02, -8.1687e-01, -3.7925e-01, -7.4123e-01,\n",
       "          4.2056e-01,  2.8315e-01,  8.1832e-01, -3.9849e-01,  8.6982e-01,\n",
       "         -9.4012e-01, -2.1605e-02, -6.3276e-01, -6.4601e-01,  4.3488e-01,\n",
       "         -8.3099e-01, -9.7413e-01, -9.6320e-01,  6.8878e-01, -3.3821e-01,\n",
       "         -3.3321e-01,  3.2778e-01,  6.1258e-03,  5.2483e-01,  4.0249e-01,\n",
       "         -1.0000e+00,  8.6605e-01,  4.1268e-01,  9.3461e-01,  9.1845e-01,\n",
       "          8.6530e-01,  8.0069e-01,  4.0741e-01, -9.4130e-01, -5.9345e-01,\n",
       "         -4.3873e-01, -3.2246e-01,  4.6502e-01,  7.1243e-01,  5.5404e-01,\n",
       "          3.8640e-01, -3.7549e-01, -8.0286e-01, -7.5768e-01, -8.9987e-01,\n",
       "         -9.8438e-01,  4.6508e-01, -7.1396e-01, -6.5660e-01,  9.0988e-01,\n",
       "         -9.4660e-03, -1.3984e-01, -5.0339e-03, -9.0116e-01,  2.3053e-01,\n",
       "          6.4262e-01,  6.1905e-02,  1.7843e-01,  5.0067e-01,  7.2539e-01,\n",
       "          7.7641e-01,  9.7751e-01, -9.2416e-01,  7.8131e-01, -7.9505e-01,\n",
       "          3.7392e-01,  9.6450e-01, -8.3807e-01,  3.5829e-01,  7.3394e-01,\n",
       "         -5.0276e-01,  2.5702e-01, -4.2174e-01, -3.8524e-01,  9.4725e-01,\n",
       "         -3.9231e-01,  6.0347e-01, -3.6220e-01, -9.6977e-02, -3.7145e-01,\n",
       "         -3.6109e-01, -7.5562e-01, -7.4682e-01,  6.3400e-01,  2.7875e-01,\n",
       "          7.9028e-01,  8.5028e-01, -2.1083e-01, -5.9684e-01, -3.8922e-01,\n",
       "         -7.8017e-01, -8.3641e-01,  5.6787e-01, -1.5805e-01, -2.7709e-01,\n",
       "          8.3426e-01, -3.0878e-02,  9.9111e-01,  4.5781e-01, -4.9190e-01,\n",
       "         -3.6228e-01, -6.5895e-01,  6.8475e-01, -9.2927e-01, -5.8974e-01,\n",
       "         -5.5253e-01,  7.3529e-01,  5.2333e-01,  1.0000e+00, -8.4559e-01,\n",
       "         -9.0528e-01, -7.7695e-01, -3.7960e-01,  5.0481e-01, -5.5343e-01,\n",
       "         -1.0000e+00,  3.9320e-01, -7.9826e-01,  7.7393e-01, -7.6284e-01,\n",
       "          8.6557e-01, -7.7767e-01, -7.1463e-01, -4.3832e-01,  7.9214e-01,\n",
       "          8.8067e-01, -5.2317e-01, -4.5600e-01,  4.8534e-01, -2.6095e-01,\n",
       "          9.7976e-01,  6.3501e-01, -8.7557e-01, -1.3709e-01,  5.6863e-01,\n",
       "         -8.7132e-01, -5.5176e-01,  3.4372e-01]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method to create the vectors is to sum the last four layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Vector\n",
    "\n",
    "To get a single vector for our entire sentence we have multiple application-dependent strategies - we could just average all the tokens in our sentence. We can also use this oppurtunity to see if the second vector returned is a sentence vector too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding_0 = sentence_embedding.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding_1 = np.mean(token_vecs[0:26], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.12442372e-02, -1.18398257e-01, -1.95655569e-01, -1.93611145e-01,\n",
       "       -1.99026577e-02,  1.00996054e-03,  5.69927454e-01,  2.02327788e-01,\n",
       "       -2.45849192e-01,  4.46894288e-01,  9.62142423e-02, -4.62434292e-01,\n",
       "       -4.66805845e-02,  1.54015094e-01, -4.60431069e-01,  6.25361085e-01,\n",
       "        8.67376700e-02,  3.44263874e-02, -2.35432044e-01,  2.60743629e-02,\n",
       "        2.62815803e-01, -1.89200953e-01, -3.34959865e-01,  5.56512833e-01,\n",
       "        6.70387864e-01,  2.01287165e-01,  1.63198382e-01,  2.06647024e-01,\n",
       "       -3.49875420e-01, -3.74109328e-01,  8.84570122e-01,  4.56150591e-01,\n",
       "       -3.72379452e-01, -3.22243512e-01, -2.29569882e-01,  1.49024636e-01,\n",
       "       -1.72443867e-01, -5.48351943e-01, -5.45619369e-01,  3.49652469e-01,\n",
       "       -6.39623344e-01, -1.51680097e-01, -2.42454842e-01, -1.20894745e-01,\n",
       "        2.19583929e-01,  1.42181173e-01,  5.15659571e-01, -4.88235019e-02,\n",
       "        3.47727954e-01,  5.75957745e-02, -6.17620498e-02,  1.36891469e-01,\n",
       "       -2.77361095e-01, -2.01068550e-01,  7.35590637e-01,  8.73226583e-01,\n",
       "       -5.17703891e-01, -5.87427735e-01, -2.64688045e-01, -5.15201926e-01,\n",
       "        1.24849714e-01,  6.67001158e-02,  2.83715248e-01, -6.30913198e-01,\n",
       "        9.87394527e-02,  9.27531272e-02,  2.05521490e-02,  6.74377382e-01,\n",
       "       -4.38057542e-01, -6.55134488e-03, -2.78355181e-01, -4.79039311e-01,\n",
       "       -2.30660260e-01,  2.65691578e-01, -1.69402674e-01,  5.65449834e-01,\n",
       "       -4.47855353e-01,  1.45908758e-01, -9.28988829e-02, -1.00008696e-01,\n",
       "        4.45965677e-02,  4.33965266e-01, -2.06933051e-01,  6.70828581e-01,\n",
       "        5.52543765e-03, -1.06284365e-01, -1.15715630e-01,  1.68506801e-01,\n",
       "       -4.00856137e-01,  4.98279989e-01, -4.58733618e-01,  3.07579845e-01,\n",
       "       -1.69212952e-01,  9.16183770e-01, -2.28167251e-02, -1.94297284e-01,\n",
       "        3.53404820e-01,  1.40848234e-01,  4.46658820e-01,  5.12626350e-01,\n",
       "        4.89163935e-01, -2.64286697e-01,  2.64058679e-01,  6.37816563e-02,\n",
       "       -1.73631042e-01, -1.47317514e-01,  6.40480876e-01, -2.26439148e-01,\n",
       "        1.98941231e-01,  5.97448684e-02,  1.49867713e-01, -1.69078037e-01,\n",
       "        1.15584418e-01, -2.12297305e-01, -4.64199871e-01,  5.99756598e-01,\n",
       "        3.65335196e-02, -1.45519599e-01, -1.50870755e-01,  3.22030187e-01,\n",
       "        3.20982009e-01, -7.74205476e-02,  3.64926793e-02,  7.34617114e-01,\n",
       "        2.40382552e-03,  4.37654182e-02,  2.50443608e-01,  3.30774158e-01,\n",
       "       -4.44463044e-01, -1.79131970e-01,  1.86454058e-01, -3.58636938e-02,\n",
       "        4.60858226e-01, -2.54961580e-01, -6.70599818e-01,  4.19405192e-01,\n",
       "       -1.38296574e-01, -4.98576522e-01, -7.28522658e-01,  1.86417490e-01,\n",
       "        2.07378492e-01, -1.36873141e-01,  3.19849074e-01, -3.89710933e-01,\n",
       "        4.32315648e-01, -1.96794137e-01,  4.05113369e-01,  1.09947070e-01,\n",
       "        7.97941834e-02,  1.28439590e-01,  2.12828055e-01,  2.98487872e-01,\n",
       "       -1.79037198e-01, -1.12842340e-02, -1.19999379e-01, -6.93522468e-02,\n",
       "       -3.64224732e-01,  4.19850290e-01, -1.81440085e-01,  4.34259623e-01,\n",
       "        4.85888690e-01, -2.38272563e-01, -1.89009503e-01,  3.04206163e-01,\n",
       "       -1.46561842e-02,  4.36927825e-01, -5.06596684e-01,  3.96587223e-01,\n",
       "       -8.73337910e-02,  6.31876826e-01, -3.69168252e-01, -7.51529753e-01,\n",
       "        7.05668986e-01, -3.94551903e-01, -1.06374614e-01, -1.16509676e-01,\n",
       "       -6.29175156e-02, -1.19823506e-02,  3.10573101e-01,  9.48214456e-02,\n",
       "       -8.97336841e-01,  1.88172594e-01,  2.33319938e-01,  6.70200944e-01,\n",
       "        2.58061439e-01, -4.47947621e-01,  1.44201815e-01, -2.72923768e-01,\n",
       "        2.86569387e-01, -7.38145784e-02, -1.79926738e-01, -6.09312177e-01,\n",
       "       -3.38936329e-01, -2.71012843e-01,  2.22631559e-01, -3.55421513e-01,\n",
       "        2.34471962e-01,  3.22268791e-02, -5.59513986e-01,  7.68857449e-02,\n",
       "       -8.71923044e-02, -1.04984000e-01,  1.58693954e-01,  3.37501884e-01,\n",
       "       -4.32015248e-02,  1.97340652e-01, -2.53645331e-01, -3.35794926e-01,\n",
       "       -2.43895620e-01,  4.90084320e-01, -9.45240408e-02,  4.57098991e-01,\n",
       "       -1.25371069e-01, -1.10022783e-01,  2.66481161e-01, -9.16968212e-02,\n",
       "        2.54007071e-01,  1.07829817e-01,  1.35811314e-01, -1.14882506e-01,\n",
       "        2.06859618e-01,  1.57821000e-01, -2.07537234e-01,  3.94774020e-01,\n",
       "       -1.92797840e-01,  9.67603445e-01, -1.67222127e-01, -1.07413210e-01,\n",
       "       -1.95379049e-01,  3.86330247e-01,  9.05265808e-02,  2.12469265e-01,\n",
       "        9.46208835e-01, -2.72164404e-01,  3.93232377e-03, -7.38112926e-02,\n",
       "       -5.57524085e-01, -1.81240797e-01, -9.17840458e-04,  5.96896186e-02,\n",
       "       -2.79919863e-01,  3.33723724e-01,  2.25949734e-01,  3.31673145e-01,\n",
       "        1.21356398e-01, -7.94519112e-02, -6.85185427e-03,  2.66497105e-01,\n",
       "       -3.66688609e-01,  2.29542792e-01,  7.21939951e-02, -6.95944190e-01,\n",
       "       -1.52901024e-01, -2.61193782e-01,  7.32010305e-02, -3.33873853e-02,\n",
       "       -1.62716642e-01, -1.29936105e-02,  4.54614609e-02,  8.02301019e-02,\n",
       "        1.36466324e-01, -6.69124424e-02,  2.31329575e-01,  2.24781349e-01,\n",
       "       -6.46501660e-01, -5.28944492e-01,  7.61984438e-02,  9.00713056e-02,\n",
       "        3.95520926e-02, -9.91885662e-02,  5.15954830e-02, -4.31710184e-01,\n",
       "        2.80748401e-02,  3.46317083e-01, -6.49841964e-01, -1.66234493e-01,\n",
       "       -9.37277898e-02,  1.63091287e-01,  1.34224519e-01, -1.12766586e-01,\n",
       "        2.82664760e-03,  5.51859498e-01, -4.87416923e-01,  2.77440608e-01,\n",
       "        1.82068884e-01, -1.87985748e-01,  2.48173904e-02, -2.99570877e-02,\n",
       "       -1.87345803e-01, -1.35711938e-01, -1.35925025e-01,  1.62735000e-01,\n",
       "       -8.63392055e-02, -5.43479323e-01,  5.76981783e-01,  3.81573051e-01,\n",
       "        1.88796893e-01,  3.42517644e-01,  4.97401416e-01, -4.51385140e-01,\n",
       "       -4.31287915e-01,  2.09199358e-02, -5.05041629e-02,  2.52739072e-01,\n",
       "       -1.45520344e-01,  2.61749864e-01, -4.27883178e-01, -3.52469921e-01,\n",
       "       -2.83814216e+00,  1.26281574e-01, -1.77201733e-01,  2.80446112e-01,\n",
       "        1.44797295e-01, -7.64416605e-02,  2.54055560e-01, -2.92004973e-01,\n",
       "       -4.64339614e-01, -5.00910506e-02, -3.97430398e-02, -4.87711251e-01,\n",
       "        2.53198624e-01,  3.68217498e-01,  2.09744006e-01,  2.43782103e-01,\n",
       "        2.74531960e-01, -7.80918658e-01,  1.04365990e-01,  4.53227818e-01,\n",
       "       -2.22010121e-01, -8.02928805e-01,  1.47568444e-02, -4.69760537e-01,\n",
       "        7.53241479e-01,  4.56248492e-01, -1.80904418e-01,  1.43457904e-01,\n",
       "       -2.03737646e-01, -6.59449220e-01,  1.21965446e-01,  7.46375695e-02,\n",
       "        1.51388764e-01,  2.41180047e-01, -1.95425987e-01,  3.36571485e-01,\n",
       "        2.25066751e-01, -4.25390661e-01, -2.51330733e-01, -2.43362516e-01,\n",
       "       -4.00037020e-01, -3.86636406e-01, -5.18934011e-01,  1.10312000e-01,\n",
       "        5.62817156e-01, -4.16127443e-02, -2.96248019e-01, -2.10424393e-01,\n",
       "       -3.41534972e-01,  2.87711978e-01,  1.79403633e-01,  2.70590663e-01,\n",
       "       -2.68519819e-02,  2.77752429e-01, -4.60495770e-01,  2.15255663e-01,\n",
       "        2.89116383e-01,  3.48873734e-01, -4.18259025e-01, -6.57185972e-01,\n",
       "        1.98425469e-03, -3.21494073e-01, -4.59846646e-01,  2.87327133e-02,\n",
       "       -2.30457440e-01, -2.59869009e-01, -5.25675058e-01,  8.77854973e-02,\n",
       "        4.17122990e-01,  2.22823583e-02,  3.28337222e-01,  3.64014506e-01,\n",
       "       -6.61748648e-01, -7.31941760e-01, -6.46811187e-01, -3.23717922e-01,\n",
       "        4.93482798e-01, -2.52652019e-01,  3.41346115e-01, -7.36547858e-02,\n",
       "       -1.22060269e-01, -3.87105018e-01, -1.67512432e-01,  1.83677077e-02,\n",
       "       -1.47829372e-02, -1.93014696e-01,  1.07710809e-01,  5.51655352e-01,\n",
       "       -3.05884540e-01, -3.32434148e-01,  5.51349372e-02,  3.79072070e-01,\n",
       "        9.22921896e-02,  2.82333314e-01, -2.96145320e-01, -1.67587057e-01,\n",
       "        1.13509730e-01, -4.07539397e-01, -1.12032495e-01,  5.23845740e-02,\n",
       "       -4.08557832e-01, -2.03564957e-01,  5.52981794e-01, -1.25551954e-01,\n",
       "       -1.10494629e-01, -6.14356622e-02, -6.10722244e-01,  5.13910875e-02,\n",
       "       -2.10803360e-01,  5.91205619e-02,  2.36750275e-01, -8.79308939e-01,\n",
       "        5.79543948e-01,  3.32637519e-01, -1.52303696e-01, -1.04062356e-01,\n",
       "        6.75754696e-02,  7.04860449e-01,  1.31987751e-01,  5.94528019e-01,\n",
       "        5.36669791e-01,  4.93561864e-01, -5.41205823e-01, -2.13985622e-01,\n",
       "       -8.17633033e-01, -9.90990326e-02, -1.91175774e-01,  3.07304114e-01,\n",
       "       -1.67295635e-01,  1.99259520e-01, -1.28579795e-01, -1.61244392e-01,\n",
       "       -3.51739526e-01,  2.46936142e-01,  1.49782911e-01,  1.26979351e-02,\n",
       "       -2.96794444e-01, -1.73930645e-01,  3.04523826e-01,  4.86152798e-01,\n",
       "        9.03499201e-02,  1.08520404e-01,  1.30188027e-02, -3.42777461e-01,\n",
       "        5.90345934e-02,  1.26246214e-01,  5.80649495e-01,  4.00188625e-01,\n",
       "       -2.81881690e-01,  4.06117111e-01, -4.84885514e-01, -4.62694705e-01,\n",
       "        3.55439007e-01,  2.08728816e-02, -2.49468267e-01, -6.02465943e-02,\n",
       "        2.47090191e-01,  1.28263682e-01,  2.11880922e-01, -7.18502700e-01,\n",
       "       -3.31397176e-01,  5.13642907e-01,  2.35959604e-01, -1.74899310e-01,\n",
       "       -1.20494589e-01,  4.01511639e-01,  1.05457135e-01,  1.19135141e-01,\n",
       "       -8.90725553e-02,  3.13730896e-01, -3.79693627e-01, -2.93272406e-01,\n",
       "        2.11498111e-01,  2.65689357e-03, -3.81255616e-03,  4.27823126e-01,\n",
       "       -4.36356924e-02, -1.35909587e-01, -5.07914126e-01,  3.16837192e-01,\n",
       "        2.66658753e-01,  9.93040055e-02, -6.07626498e-01, -2.65011102e-01,\n",
       "        4.08462316e-01,  1.58281982e-01, -2.61065029e-02, -1.83695048e-01,\n",
       "        4.19420414e-02, -2.50747167e-02, -5.12248576e-01,  1.31503999e-01,\n",
       "        1.14898488e-01, -3.54584008e-01, -4.49175537e-01, -2.52921551e-01,\n",
       "        2.54246771e-01, -9.32577550e-01,  1.10892326e-01,  5.34963161e-02,\n",
       "        2.90242523e-01, -1.19898036e-01, -1.36285007e-01,  1.43924654e-01,\n",
       "       -1.78466260e-01, -3.47239912e-01, -1.30035970e-02, -8.52789134e-02,\n",
       "       -4.75028545e-01,  2.15227768e-01, -7.05203950e-01, -2.46079668e-01,\n",
       "       -5.55774808e-01,  1.24601200e-01,  1.27845034e-01, -4.89548385e-01,\n",
       "        2.91438013e-01, -2.15760931e-01, -4.92012858e-01,  7.18334466e-02,\n",
       "       -4.06111658e-01, -4.25356507e-01,  3.01719159e-01,  1.53969467e-01,\n",
       "       -7.79448092e-01, -7.04139650e-01, -2.45162725e-01,  1.84456408e-01,\n",
       "       -5.10346711e-01,  2.11144596e-01, -2.89027661e-01, -4.88802224e-01,\n",
       "        2.33968899e-01,  3.09916377e-01, -1.52167290e-01,  8.72328579e-02,\n",
       "       -8.29160586e-02, -5.49315095e-01,  2.13216633e-01, -9.28909034e-02,\n",
       "       -1.06273636e-01,  1.49687633e-01,  1.99937135e-01, -1.09827360e-02,\n",
       "        4.31238919e-01, -1.03702694e-01, -1.67483419e-01,  3.24325264e-01,\n",
       "       -3.10587436e-01,  6.35744750e-01, -3.42034549e-01, -1.15001231e-01,\n",
       "       -2.84081489e-01, -2.67174006e-01, -6.34292066e-02, -4.87566888e-01,\n",
       "        2.11875781e-01, -3.09219688e-01, -1.55305803e-01,  4.89629567e-01,\n",
       "       -9.51557532e-02,  7.21800625e-02,  3.02342981e-01, -3.67979527e-01,\n",
       "        6.44237846e-02,  3.59464437e-01,  4.99342859e-01,  3.89068753e-01,\n",
       "       -1.19551606e-01, -5.55562735e-01, -1.84457988e-01, -5.08117914e-01,\n",
       "       -3.16238217e-02, -5.56678176e-01, -1.29145131e-01,  3.22708547e-01,\n",
       "        5.01615331e-02, -5.94307303e-01,  6.80349588e-01, -5.38806081e-01,\n",
       "       -3.81113946e-01,  2.33291849e-01, -1.70471321e-03, -2.57044107e-01,\n",
       "        1.97584957e-01, -2.02705085e-01,  2.04255641e-01,  7.20610499e-01,\n",
       "       -3.65679294e-01, -6.25648856e-01,  6.21723533e-01, -1.92392722e-01,\n",
       "       -1.16575651e-01,  3.81770074e-01, -3.86290222e-01, -2.26776414e-02,\n",
       "        3.29720646e-01,  1.78216547e-01,  1.71590019e-02,  1.10383350e-02,\n",
       "       -3.74015957e-01,  3.93034471e-03,  3.91917706e-01, -1.57555088e-01,\n",
       "       -1.78669274e-01,  2.64687408e-02,  1.51951134e-01, -6.33642614e-01,\n",
       "        6.48264289e-01,  6.88186884e-02, -1.97942987e-01, -5.72934747e-01,\n",
       "        6.81799948e-01,  5.35384044e-02, -4.15091991e-01, -1.99864075e-01,\n",
       "        4.61295322e-02, -7.11517334e-01, -4.67302985e-02, -2.40065023e-01,\n",
       "        1.52663484e-01,  1.59925073e-01,  6.66916192e-01, -1.49402857e-01,\n",
       "        3.67955714e-01,  5.06426871e-01, -3.82263809e-01,  2.01373607e-01,\n",
       "       -1.24099761e-01,  4.67165321e-01, -4.66148198e-01,  4.98386264e-01,\n",
       "        7.95944408e-02,  3.49464744e-01, -6.91694915e-02, -1.56916961e-01,\n",
       "        3.66617650e-01,  2.27363750e-01, -4.68425341e-02,  1.92829981e-01,\n",
       "        1.08565778e-01,  1.80222541e-01,  3.31109017e-01,  2.99928367e-01,\n",
       "        1.69851050e-01,  1.79085121e-01,  1.16980091e-01,  2.15380535e-01,\n",
       "        9.49999809e-01,  4.32473719e-01,  3.36400792e-02,  1.45196334e-01,\n",
       "        4.01719093e-01,  2.31366128e-01,  3.07116061e-01,  5.18214166e-01,\n",
       "       -1.77693870e-02,  2.97467530e-01, -3.10557812e-01,  6.61215842e-01,\n",
       "        2.35605985e-01, -1.60658658e-01,  2.28998989e-01, -5.77374637e-01,\n",
       "        2.75603235e-01, -1.84634000e-01, -1.35720717e-02, -1.52692661e-01,\n",
       "        2.10773095e-01, -3.99655290e-02,  1.93781540e-01, -2.80602396e-01,\n",
       "       -2.61353344e-01, -3.35128278e-01, -5.68209365e-02,  5.78398645e-01,\n",
       "        1.83280930e-01, -6.26753688e-01, -1.59835279e-01,  3.22917104e-01,\n",
       "       -4.46252078e-02, -1.68550432e-01, -4.48782384e-01, -4.50886041e-01,\n",
       "       -4.62304324e-01, -2.69589007e-01,  2.64310632e-02,  3.50987464e-01,\n",
       "       -3.12557340e-01,  5.50831631e-02, -5.03771678e-02,  8.96539539e-02,\n",
       "        4.64182347e-01, -1.81257144e-01, -3.39624099e-02,  2.99237251e-01,\n",
       "        2.75037467e-01, -2.11799935e-01,  5.27691722e-01, -3.94886136e-01,\n",
       "       -4.04834561e-02, -3.01241875e-01,  6.18993072e-03, -1.43867105e-01,\n",
       "       -7.57041499e-02, -2.15386063e-01,  2.13025793e-01,  2.38644198e-01,\n",
       "       -3.77943933e-01, -4.73181069e-01, -2.40731180e-01,  8.89536917e-01,\n",
       "       -9.99122739e-01, -2.31841385e-01,  4.63802076e-04, -2.23394901e-01,\n",
       "        3.20421755e-01,  3.61247122e-01, -3.81324813e-02,  1.96411923e-01,\n",
       "       -4.35564101e-01, -2.91094840e-01,  3.92474793e-02,  1.54633015e-01,\n",
       "       -3.53895247e-01,  6.90372735e-02,  2.96801865e-01,  8.01695585e-01,\n",
       "        3.84184986e-01,  8.63627717e-03, -6.72994107e-02,  9.70895663e-02,\n",
       "        2.71263402e-02,  1.03538327e-01,  2.12668344e-01, -1.31459489e-01,\n",
       "       -3.65293086e-01, -1.47770748e-01, -5.83821714e-01, -1.65509775e-01,\n",
       "        2.44819939e-01, -3.60375911e-01,  4.94687781e-02, -2.28534132e-01,\n",
       "        1.56750813e-01, -3.57459664e-01,  6.74802214e-02, -2.13450462e-01,\n",
       "        1.24205038e-01, -4.62799996e-01, -1.55679733e-01, -1.14332050e-01,\n",
       "        2.06655532e-01, -4.34702694e-01, -2.74407178e-01, -7.24381208e-01,\n",
       "        1.81550577e-01, -5.63796535e-02, -2.35414654e-01,  1.31568402e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding_2 = np.mean(token_vecs[26:52], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_embedding_1), len(sentence_embedding_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the power of these vectors is how they are context dependant - our sentence had multiple uses of the word bank. Let us see the index and the word of the sentence and check the context accordingly. We'll then print the simlarity values for the similar and different meanings and see how it turns out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 judge\n",
      "2 walker\n",
      "3 had\n",
      "4 suggested\n",
      "5 that\n",
      "6 the\n",
      "7 group\n",
      "8 lacked\n",
      "9 standing\n",
      "10 because\n",
      "11 he\n",
      "12 found\n",
      "13 no\n",
      "14 harm\n",
      "15 caused\n",
      "16 by\n",
      "17 granting\n",
      "18 gay\n",
      "19 people\n",
      "20 the\n",
      "21 right\n",
      "22 to\n",
      "23 marry\n",
      "24 .\n",
      "25 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print(i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 vector values for each instance of \"bank\".\n",
      "\n",
      "bank vault    [-0.27795744 -1.3223081  -0.48556015 -0.26806214 -0.17015272]\n",
      "bank robber   [-0.8197721   0.25485048 -0.3971712   0.02299499 -0.5749786 ]\n",
      "river bank    [-0.02428075  0.06294584  0.01925689  0.09122998  0.12184171]\n"
     ]
    }
   ],
   "source": [
    "print('First 5 vector values for each instance of \"bank\".')\n",
    "print('')\n",
    "print(\"bank vault   \", str(token_vecs[6][:5]))\n",
    "print(\"bank robber  \", str(token_vecs[10][:5]))\n",
    "print(\"river bank   \", str(token_vecs[19][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.95\n",
      "Vector similarity for *different* meanings:  0.70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the cosine similarity between the word bank \n",
    "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "diff_bank = 1 - cosine(token_vecs[10], token_vecs[19])\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(token_vecs[10], token_vecs[6])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense! Let us see if the mean value of all the tokens and what we think is the sentence vector is the same thing, by checking their cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966305136680603"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - cosine(sentence_embedding_1, sentence_embedding_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is good - it seems it is indeed the sentence vector, so we can now write two functions which calculate the word and sentence vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(text, word_id, model, tokenizer):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)   \n",
    "    vector = word_embeddings[0][word_id].detach().numpy()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_10 = word_vector(text, 6, model_embedding, tokenizer)\n",
    "word_6 = word_vector(text, 10, model_embedding, tokenizer)\n",
    "word_19 = word_vector(text, 19, model_embedding, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(text, model, tokenizer, method=\"average\"):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)\n",
    "    token_vecs = []\n",
    "    \n",
    "    for embedding in word_embeddings[0]:\n",
    "        cat_vec = embedding.detach().numpy()\n",
    "        token_vecs.append(cat_vec)\n",
    "        \n",
    "    if method == \"average\":\n",
    "        sentence_embedding = np.mean(token_vecs, axis=0)\n",
    "    if method == \"model\":\n",
    "        sentence_embedding = sentence_embeddings\n",
    "    # do something\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_vec_1 = sentence_vector(text1, model_embedding, tokenizer, method = \"model\")\n",
    "sen_vec_2 = sentence_vector(text2, model_embedding, tokenizer, method=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding_1 = sen_vec_1.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding_2 = sen_vec_2.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9978439211845398"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - cosine(sentence_embedding_1, sentence_embedding_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity metrics\n",
    "It is worth noting that word-level similarity comparisons are not appropriate with BERT embeddings because these embeddings are contextually dependent, meaning that the word vector changes depending on the sentence it appears in. This enables direct sensitivity to polysemy so that, e.g., your representation encodes river â€œbankâ€ and not a financial institution â€œbankâ€. Nevertheless, it makes direct word-to-word similarity comparisons less valuable. For sentence embeddings, however, similarity comparison is still valid such that one can query, for example, a single sentence against a dataset of other sentences in order to find the most similar. Depending on the similarity metric used, the resulting similarity values will be less informative than the relative ranking of similarity outputs as some similarity metrics make assumptions about the vector space (equally-weighted dimensions, for example) that do not hold for our 768-dimensional vector space.\n",
    "\n",
    "### Using the Vectors\n",
    "\n",
    "Without fine-tuning, BERT features may be less useful than plain GloVe or word2vec.\n",
    "They start to be interesting when you fine-tune a classifier on top of BERT. \n",
    "\n",
    "### Using Transformers Pipelines\n",
    "\n",
    "The context vectors make the other pipeline functions which transformers has built in a lot more powerful. \n",
    "\n",
    "### NOTE\n",
    "The pipeline functionality in transformers is currently being worked on and might be broken, so it is an optional part of the exercise. Do try to uncomment the lines of code and try to see if it works, though! If you have managed to get transformers v2.5.1 installed, it will work - I managed to get it to work sometimes, it can be annoying to get it to work but when it works it works well.\n",
    "\n",
    "Consider the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.7/site-packages (2.4.1)\n",
      "Requirement already satisfied: tokenizers==0.0.11 in /opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.0.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from transformers) (1.17.2)\n",
      "Requirement already satisfied: sacremoses in /opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.0.38)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.7/site-packages (from transformers) (2020.2.20)\n",
      "Requirement already satisfied: boto3 in /opt/anaconda3/lib/python3.7/site-packages (from transformers) (1.11.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.7/site-packages (from transformers) (4.36.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.3.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.0 in /opt/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.0->boto3->transformers) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.0->boto3->transformers) (0.15.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3861a6ad1ab14355a1c8f301ce82fbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=546, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac0989af2f54f4697e2684fce09b643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=754, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ccc2ff496548e191d9fc2f58317daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=230, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80cfa6689d44349bb61dcddc730c0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=267844284, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Allocate a pipeline for sentiment-analysis\n",
    "nlp_sentiment = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997735}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"This BERT model is so good at classifiying sentiment, I love it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Judge Walker had suggested that the group lacked standing because he found no harm caused by granting queer people the right to marry.'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Judge Walker had suggested that the group lacked standing because he found no harm caused by granting gay people the right to marry.'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9660618}]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9708835}]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a strong positive sentiment, which we'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997195}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"I'm so sad that I have to spend this weekend just doing HW and readings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.76138455}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"Together they suggest not an invented false history but a secret real one, as if the queerness had always been there, a kind of digital potential waiting to be released.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"The show was conceived, said Gonzalo Casals, the museum director, as an intimate platform for artwork that holds up a mirror to the lives of sex workers in the L.G.B.T.Q. community, some pieces by artists who themselves worked as prostitutes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9988113}]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.99670404}]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"prostitutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9753499}]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"sex workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9880066}]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"L.G.B.T.Q.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative label, bingo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b23de08e144d6aad52869aa1b5fbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=230, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3871980c964e618154993eeacc8135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=555, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abe1752a2094350ba48b0067aa9d948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=265481570, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Allocate a pipeline for question-answering\n",
    "nlp_question = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.87it/s]\n",
      "add example index and unique id: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1152.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.783282551410565,\n",
       " 'start': 34,\n",
       " 'end': 64,\n",
       " 'answer': 'analysing complex textual data'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_question({\n",
    "     'question': 'What is my favorite thing to do on weekends ?',\n",
    "     'context': 'There is nothing I like more than analysing complex textual data all weekend '\n",
    " })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also great at question-answering tasks!\n",
    "We can also extract features, as we manually did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c95ebe686e54be9980dd7677bcbc66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=230, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b6552ce9284502afce89b375dc20fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=267967963, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp_feature = pipeline('feature-extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = nlp_feature(\"Just sitting here exploring data all day long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.1418904960155487,\n",
       "   -0.12390569597482681,\n",
       "   0.09115805476903915,\n",
       "   -0.0890045017004013,\n",
       "   -0.05150006711483002,\n",
       "   -0.4635638892650604,\n",
       "   0.18017971515655518,\n",
       "   0.6232033371925354,\n",
       "   -0.3349596858024597,\n",
       "   -0.28818896412849426,\n",
       "   0.07291904091835022,\n",
       "   -0.17141923308372498,\n",
       "   -0.1449851393699646,\n",
       "   0.29846519231796265,\n",
       "   -0.12272804975509644,\n",
       "   0.04019373655319214,\n",
       "   0.08573569357395172,\n",
       "   0.1481054425239563,\n",
       "   0.25651639699935913,\n",
       "   0.07005636394023895,\n",
       "   0.06099243462085724,\n",
       "   -0.1371365189552307,\n",
       "   -0.023561570793390274,\n",
       "   -0.07952219247817993,\n",
       "   -0.06407849490642548,\n",
       "   -0.19339148700237274,\n",
       "   -0.09276499599218369,\n",
       "   0.04568033665418625,\n",
       "   0.07748440653085709,\n",
       "   0.07563909143209457,\n",
       "   -0.1420525163412094,\n",
       "   0.08205939829349518,\n",
       "   -0.2574387490749359,\n",
       "   -0.18543750047683716,\n",
       "   0.03804102912545204,\n",
       "   -0.21186858415603638,\n",
       "   0.10410645604133606,\n",
       "   -0.12047620117664337,\n",
       "   -0.12784770131111145,\n",
       "   0.045645780861377716,\n",
       "   -0.08709031343460083,\n",
       "   -0.011292900890111923,\n",
       "   -0.09043072164058685,\n",
       "   -0.11281096190214157,\n",
       "   0.1009974479675293,\n",
       "   -0.19919277727603912,\n",
       "   -2.113718271255493,\n",
       "   -0.020535072311758995,\n",
       "   -0.11475220322608948,\n",
       "   -0.13262847065925598,\n",
       "   0.2571108937263489,\n",
       "   -0.1427423059940338,\n",
       "   0.18744775652885437,\n",
       "   0.291480153799057,\n",
       "   0.35080069303512573,\n",
       "   0.49046021699905396,\n",
       "   -0.08307254314422607,\n",
       "   0.4114917814731598,\n",
       "   -0.1352912336587906,\n",
       "   0.15215657651424408,\n",
       "   0.3275741636753082,\n",
       "   -0.06796904653310776,\n",
       "   -0.32280123233795166,\n",
       "   -0.0848587155342102,\n",
       "   -0.17013822495937347,\n",
       "   0.06888915598392487,\n",
       "   -0.038709692656993866,\n",
       "   0.06222756952047348,\n",
       "   -0.15760046243667603,\n",
       "   0.46770209074020386,\n",
       "   -0.34611639380455017,\n",
       "   -0.17324312031269073,\n",
       "   0.2512623071670532,\n",
       "   0.06703267991542816,\n",
       "   -0.06118348240852356,\n",
       "   0.0695125013589859,\n",
       "   0.034664057195186615,\n",
       "   0.17166768014431,\n",
       "   -0.039995841681957245,\n",
       "   0.1383817046880722,\n",
       "   0.027338718995451927,\n",
       "   0.5210861563682556,\n",
       "   0.24462848901748657,\n",
       "   0.2363283634185791,\n",
       "   -0.05639226734638214,\n",
       "   0.18035364151000977,\n",
       "   -0.5635475516319275,\n",
       "   -0.3270522952079773,\n",
       "   0.24668872356414795,\n",
       "   0.30865180492401123,\n",
       "   -0.11022031307220459,\n",
       "   -0.12073197960853577,\n",
       "   0.19163836538791656,\n",
       "   0.19142544269561768,\n",
       "   0.3524211347103119,\n",
       "   -0.32553908228874207,\n",
       "   -0.09741547703742981,\n",
       "   0.06301581114530563,\n",
       "   0.24461877346038818,\n",
       "   0.2853175103664398,\n",
       "   0.17951808869838715,\n",
       "   -0.14545118808746338,\n",
       "   0.1753152310848236,\n",
       "   -0.2533212900161743,\n",
       "   0.29186564683914185,\n",
       "   -0.11479628086090088,\n",
       "   0.01644846424460411,\n",
       "   -0.287371963262558,\n",
       "   0.038053084164857864,\n",
       "   -2.4416098594665527,\n",
       "   0.10115014761686325,\n",
       "   -0.024494558572769165,\n",
       "   0.0059872837737202644,\n",
       "   -0.1647139936685562,\n",
       "   -0.14718927443027496,\n",
       "   0.08064839243888855,\n",
       "   0.22861291468143463,\n",
       "   -0.04190104454755783,\n",
       "   0.14204299449920654,\n",
       "   0.03552352637052536,\n",
       "   -0.266055166721344,\n",
       "   0.37366989254951477,\n",
       "   0.008669770322740078,\n",
       "   -0.17582780122756958,\n",
       "   -0.09769944101572037,\n",
       "   0.2766244113445282,\n",
       "   -0.14658984541893005,\n",
       "   -0.36558717489242554,\n",
       "   -0.10719677805900574,\n",
       "   0.09608856588602066,\n",
       "   0.34678658843040466,\n",
       "   0.4458197057247162,\n",
       "   0.12781231105327606,\n",
       "   -0.17231565713882446,\n",
       "   -0.3146626055240631,\n",
       "   0.1295732855796814,\n",
       "   0.36432552337646484,\n",
       "   -0.17451277375221252,\n",
       "   -0.2162947803735733,\n",
       "   0.07522764056921005,\n",
       "   -0.12373334169387817,\n",
       "   0.09256142377853394,\n",
       "   -2.797109365463257,\n",
       "   0.4012147784233093,\n",
       "   0.3705046474933624,\n",
       "   0.07605598866939545,\n",
       "   0.04045359790325165,\n",
       "   -0.0663023293018341,\n",
       "   0.11095738410949707,\n",
       "   0.08714130520820618,\n",
       "   0.0456240214407444,\n",
       "   0.026222918182611465,\n",
       "   -0.09973536431789398,\n",
       "   -0.0697738379240036,\n",
       "   -0.18034270405769348,\n",
       "   0.06845799833536148,\n",
       "   -0.45805150270462036,\n",
       "   -0.18214893341064453,\n",
       "   0.2505985498428345,\n",
       "   0.12012961506843567,\n",
       "   0.12193767726421356,\n",
       "   -0.22829391062259674,\n",
       "   -0.1478714942932129,\n",
       "   -0.04511445388197899,\n",
       "   -0.1349397599697113,\n",
       "   0.03614894673228264,\n",
       "   0.42456838488578796,\n",
       "   0.27642014622688293,\n",
       "   0.22307664155960083,\n",
       "   0.0361403189599514,\n",
       "   -0.11818432062864304,\n",
       "   0.1377280056476593,\n",
       "   0.39649927616119385,\n",
       "   -0.258299857378006,\n",
       "   -0.04830164089798927,\n",
       "   0.016391297802329063,\n",
       "   0.13549911975860596,\n",
       "   0.26198846101760864,\n",
       "   0.006679613143205643,\n",
       "   -0.0591934397816658,\n",
       "   -0.013115018606185913,\n",
       "   0.47327107191085815,\n",
       "   0.11453486979007721,\n",
       "   0.030791983008384705,\n",
       "   0.09757646173238754,\n",
       "   -0.0767909586429596,\n",
       "   0.24749687314033508,\n",
       "   -0.15404705703258514,\n",
       "   -0.25761380791664124,\n",
       "   0.32242637872695923,\n",
       "   0.01183176040649414,\n",
       "   -0.2098158597946167,\n",
       "   0.19943997263908386,\n",
       "   -0.0011041630059480667,\n",
       "   0.3713664412498474,\n",
       "   -0.059849098324775696,\n",
       "   -0.07729865610599518,\n",
       "   -0.575110137462616,\n",
       "   0.2230915129184723,\n",
       "   0.06476004421710968,\n",
       "   -0.15482306480407715,\n",
       "   -0.05584552884101868,\n",
       "   -0.08775688707828522,\n",
       "   0.08447933197021484,\n",
       "   -0.3391745686531067,\n",
       "   3.7770628929138184,\n",
       "   0.08900050073862076,\n",
       "   -0.1689547896385193,\n",
       "   0.12498337030410767,\n",
       "   0.2513558864593506,\n",
       "   -0.2379981428384781,\n",
       "   0.1931479573249817,\n",
       "   -0.09071103483438492,\n",
       "   -0.06573504209518433,\n",
       "   0.031218912452459335,\n",
       "   0.02351543679833412,\n",
       "   0.25586602091789246,\n",
       "   0.13599815964698792,\n",
       "   -0.13029168546199799,\n",
       "   0.008056849241256714,\n",
       "   0.12279849499464035,\n",
       "   0.2043232023715973,\n",
       "   -0.1989932656288147,\n",
       "   0.44520053267478943,\n",
       "   -0.1125999391078949,\n",
       "   0.1698506772518158,\n",
       "   0.08140996098518372,\n",
       "   0.07979127764701843,\n",
       "   -0.04773540049791336,\n",
       "   -1.1796174049377441,\n",
       "   0.07820683717727661,\n",
       "   -0.17446298897266388,\n",
       "   -0.056143805384635925,\n",
       "   0.2717456817626953,\n",
       "   -0.15645334124565125,\n",
       "   -0.07792578637599945,\n",
       "   0.03904718905687332,\n",
       "   -0.024818768724799156,\n",
       "   0.07453440874814987,\n",
       "   0.01453494280576706,\n",
       "   -0.19642990827560425,\n",
       "   0.022992420941591263,\n",
       "   0.4081132411956787,\n",
       "   0.28501302003860474,\n",
       "   -0.07469596713781357,\n",
       "   0.49267086386680603,\n",
       "   0.2357170432806015,\n",
       "   0.04317600280046463,\n",
       "   -0.06692805141210556,\n",
       "   -0.16627201437950134,\n",
       "   0.30129313468933105,\n",
       "   0.0061749741435050964,\n",
       "   0.026484331116080284,\n",
       "   -0.3685031235218048,\n",
       "   0.045019276440143585,\n",
       "   -0.18027809262275696,\n",
       "   -0.1471211016178131,\n",
       "   -0.02641485258936882,\n",
       "   -0.27540066838264465,\n",
       "   0.109749436378479,\n",
       "   -0.2229069024324417,\n",
       "   -0.11364613473415375,\n",
       "   0.08221238106489182,\n",
       "   -0.03070291131734848,\n",
       "   -0.5620907545089722,\n",
       "   -0.29795563220977783,\n",
       "   0.1342983990907669,\n",
       "   -0.19699952006340027,\n",
       "   0.132863849401474,\n",
       "   0.03327300772070885,\n",
       "   -0.01831173524260521,\n",
       "   -0.02003767341375351,\n",
       "   -0.36027729511260986,\n",
       "   -3.6358063220977783,\n",
       "   -0.069569431245327,\n",
       "   -0.08991318941116333,\n",
       "   0.15681545436382294,\n",
       "   0.2150997817516327,\n",
       "   0.015525110065937042,\n",
       "   0.10404001176357269,\n",
       "   0.3134252727031708,\n",
       "   0.3558163344860077,\n",
       "   -0.34730491042137146,\n",
       "   0.5014415383338928,\n",
       "   0.187752366065979,\n",
       "   -0.16797463595867157,\n",
       "   0.25570717453956604,\n",
       "   -0.2325272560119629,\n",
       "   0.10884809494018555,\n",
       "   -0.0830933079123497,\n",
       "   -0.011513765901327133,\n",
       "   0.012671148404479027,\n",
       "   -0.08796361088752747,\n",
       "   0.005888909101486206,\n",
       "   0.1797654926776886,\n",
       "   -0.11733395606279373,\n",
       "   0.24883802235126495,\n",
       "   -0.2787545919418335,\n",
       "   0.00906851515173912,\n",
       "   -0.2308131903409958,\n",
       "   -0.15986421704292297,\n",
       "   -0.04999157786369324,\n",
       "   0.11388680338859558,\n",
       "   0.02912559174001217,\n",
       "   -0.19876264035701752,\n",
       "   0.12203583121299744,\n",
       "   -0.07379253208637238,\n",
       "   -0.28443631529808044,\n",
       "   -2.6703317165374756,\n",
       "   -0.07504606992006302,\n",
       "   -0.2874096632003784,\n",
       "   -0.04683266580104828,\n",
       "   -0.13761301338672638,\n",
       "   -0.1087309867143631,\n",
       "   0.25434455275535583,\n",
       "   -0.19275790452957153,\n",
       "   -0.3420206606388092,\n",
       "   -0.12357380986213684,\n",
       "   0.025007883086800575,\n",
       "   0.08245402574539185,\n",
       "   0.1197836846113205,\n",
       "   0.3692665994167328,\n",
       "   0.43653610348701477,\n",
       "   0.04310813546180725,\n",
       "   0.21161724627017975,\n",
       "   0.04201541468501091,\n",
       "   0.1371009349822998,\n",
       "   0.22451984882354736,\n",
       "   0.030232220888137817,\n",
       "   -0.09338127076625824,\n",
       "   0.09719795733690262,\n",
       "   -0.03243466466665268,\n",
       "   0.12845763564109802,\n",
       "   0.40371325612068176,\n",
       "   -0.47691601514816284,\n",
       "   0.104756198823452,\n",
       "   -0.2220056653022766,\n",
       "   0.005673728883266449,\n",
       "   0.07900476455688477,\n",
       "   -0.3455296456813812,\n",
       "   -7.523596286773682e-05,\n",
       "   -0.013653483241796494,\n",
       "   -0.20257627964019775,\n",
       "   -0.06899616122245789,\n",
       "   0.05335055664181709,\n",
       "   0.23100414872169495,\n",
       "   0.5370945930480957,\n",
       "   0.28927725553512573,\n",
       "   -0.17156898975372314,\n",
       "   0.40652045607566833,\n",
       "   0.12200430035591125,\n",
       "   0.26002123951911926,\n",
       "   0.6548902988433838,\n",
       "   0.26176029443740845,\n",
       "   0.22242623567581177,\n",
       "   -0.1455944925546646,\n",
       "   -0.16454073786735535,\n",
       "   0.1452081799507141,\n",
       "   -0.005631288513541222,\n",
       "   0.09310902655124664,\n",
       "   1.1785125732421875,\n",
       "   -0.15568041801452637,\n",
       "   0.004576824605464935,\n",
       "   -0.4021523892879486,\n",
       "   0.5373490452766418,\n",
       "   0.2973577380180359,\n",
       "   -0.08571963012218475,\n",
       "   -0.028071172535419464,\n",
       "   0.4157194495201111,\n",
       "   -0.3545483648777008,\n",
       "   0.07484577596187592,\n",
       "   -0.19623655080795288,\n",
       "   -0.028843604028224945,\n",
       "   -0.2533099055290222,\n",
       "   0.2777811884880066,\n",
       "   -0.3476596772670746,\n",
       "   0.09802307933568954,\n",
       "   0.14054705202579498,\n",
       "   -0.0008706487715244293,\n",
       "   0.30697914958000183,\n",
       "   -0.10163162648677826,\n",
       "   -0.9693422317504883,\n",
       "   -0.06378746777772903,\n",
       "   0.26465338468551636,\n",
       "   -0.0957287847995758,\n",
       "   0.05315543711185455,\n",
       "   0.14277459681034088,\n",
       "   0.26404887437820435,\n",
       "   -0.2133878469467163,\n",
       "   -0.14993979036808014,\n",
       "   -0.18730954825878143,\n",
       "   0.2281569093465805,\n",
       "   -0.20437562465667725,\n",
       "   -0.48528236150741577,\n",
       "   -0.283250629901886,\n",
       "   -0.02492949552834034,\n",
       "   -0.2672514021396637,\n",
       "   0.06694117188453674,\n",
       "   -0.13197506964206696,\n",
       "   0.15867720544338226,\n",
       "   0.30929163098335266,\n",
       "   0.17555655539035797,\n",
       "   0.30699002742767334,\n",
       "   -0.09701485186815262,\n",
       "   0.2784273028373718,\n",
       "   -0.862104058265686,\n",
       "   0.1963396668434143,\n",
       "   -0.22644494473934174,\n",
       "   0.12367911636829376,\n",
       "   -0.20192041993141174,\n",
       "   -0.054795779287815094,\n",
       "   0.18924103677272797,\n",
       "   -0.2010272741317749,\n",
       "   -0.19321247935295105,\n",
       "   -0.2267119288444519,\n",
       "   0.2725566029548645,\n",
       "   -0.19538503885269165,\n",
       "   0.20754672586917877,\n",
       "   -0.16967445611953735,\n",
       "   0.1601499319076538,\n",
       "   0.14345918595790863,\n",
       "   0.15589797496795654,\n",
       "   0.8449884653091431,\n",
       "   -0.13603079319000244,\n",
       "   0.053615204989910126,\n",
       "   0.24068966507911682,\n",
       "   -0.1678590327501297,\n",
       "   0.20468422770500183,\n",
       "   0.11762490123510361,\n",
       "   0.2877520024776459,\n",
       "   0.0018879398703575134,\n",
       "   -0.1329669952392578,\n",
       "   -0.18435430526733398,\n",
       "   -0.19231536984443665,\n",
       "   0.016373280435800552,\n",
       "   -0.3463776111602783,\n",
       "   -0.20720510184764862,\n",
       "   0.012300833128392696,\n",
       "   0.08587910234928131,\n",
       "   0.22372981905937195,\n",
       "   -0.1234249547123909,\n",
       "   -0.47368788719177246,\n",
       "   -0.10674330592155457,\n",
       "   -0.28601813316345215,\n",
       "   -0.09750853478908539,\n",
       "   -0.1059197336435318,\n",
       "   0.41973987221717834,\n",
       "   0.11004963517189026,\n",
       "   0.428110808134079,\n",
       "   0.22474762797355652,\n",
       "   0.0015340521931648254,\n",
       "   0.41923144459724426,\n",
       "   -0.27890104055404663,\n",
       "   0.5886233448982239,\n",
       "   -0.04204599931836128,\n",
       "   0.061058059334754944,\n",
       "   -0.0055882688611745834,\n",
       "   0.3022271692752838,\n",
       "   -0.2770402133464813,\n",
       "   -0.19603395462036133,\n",
       "   -0.11507012695074081,\n",
       "   -0.05349528044462204,\n",
       "   0.3971264958381653,\n",
       "   0.012007907032966614,\n",
       "   -0.004653559997677803,\n",
       "   -0.19939492642879486,\n",
       "   0.14083890616893768,\n",
       "   -0.0043095978908240795,\n",
       "   0.0032924339175224304,\n",
       "   0.06677988916635513,\n",
       "   -1.1960666179656982,\n",
       "   0.34319499135017395,\n",
       "   0.11449305713176727,\n",
       "   0.01673436164855957,\n",
       "   0.057170432060956955,\n",
       "   -0.09412826597690582,\n",
       "   0.06575699150562286,\n",
       "   0.3144322633743286,\n",
       "   0.07001997530460358,\n",
       "   0.15073731541633606,\n",
       "   -0.11785658448934555,\n",
       "   -0.09624361246824265,\n",
       "   -0.23725391924381256,\n",
       "   0.11956368386745453,\n",
       "   -0.018450967967510223,\n",
       "   0.014626411721110344,\n",
       "   -0.1685342937707901,\n",
       "   0.07488320022821426,\n",
       "   -0.017560036852955818,\n",
       "   -0.055007874965667725,\n",
       "   0.060208577662706375,\n",
       "   0.3215946555137634,\n",
       "   0.1810104250907898,\n",
       "   -0.004348006099462509,\n",
       "   0.06847730278968811,\n",
       "   -0.013363266363739967,\n",
       "   -0.025836564600467682,\n",
       "   0.39342331886291504,\n",
       "   0.09830377995967865,\n",
       "   0.3078402578830719,\n",
       "   0.051593877375125885,\n",
       "   -0.20729994773864746,\n",
       "   -0.4855772852897644,\n",
       "   -0.197921484708786,\n",
       "   0.35640886425971985,\n",
       "   0.2481798678636551,\n",
       "   0.12402091920375824,\n",
       "   -0.06164819002151489,\n",
       "   0.08690886199474335,\n",
       "   -0.011069579049944878,\n",
       "   -0.37212979793548584,\n",
       "   0.29203200340270996,\n",
       "   0.011650148779153824,\n",
       "   -0.07840302586555481,\n",
       "   0.5851747989654541,\n",
       "   0.18865257501602173,\n",
       "   -0.051950328052043915,\n",
       "   0.10395728051662445,\n",
       "   -0.022299155592918396,\n",
       "   -0.33299046754837036,\n",
       "   -0.25136512517929077,\n",
       "   -0.1907152682542801,\n",
       "   -0.12615558505058289,\n",
       "   0.05102447420358658,\n",
       "   0.13642767071723938,\n",
       "   -0.04824777692556381,\n",
       "   -0.018592286854982376,\n",
       "   0.008768076077103615,\n",
       "   -0.22478683292865753,\n",
       "   0.09383650124073029,\n",
       "   0.11110759526491165,\n",
       "   -0.2884536683559418,\n",
       "   -0.21345025300979614,\n",
       "   0.019240640103816986,\n",
       "   -0.19699864089488983,\n",
       "   -0.4873712658882141,\n",
       "   -0.22288936376571655,\n",
       "   -0.19702807068824768,\n",
       "   -0.041084423661231995,\n",
       "   0.037911832332611084,\n",
       "   0.21005341410636902,\n",
       "   -0.16229811310768127,\n",
       "   -0.23629754781723022,\n",
       "   0.21396857500076294,\n",
       "   -0.2849985361099243,\n",
       "   0.26482757925987244,\n",
       "   0.06592506915330887,\n",
       "   0.1457568258047104,\n",
       "   0.03145930543541908,\n",
       "   -0.2852051854133606,\n",
       "   0.11509358882904053,\n",
       "   -0.44860583543777466,\n",
       "   -0.24094067513942719,\n",
       "   0.18610233068466187,\n",
       "   -0.15505032241344452,\n",
       "   0.2546258866786957,\n",
       "   -0.26098552346229553,\n",
       "   -0.10706187784671783,\n",
       "   0.11842045187950134,\n",
       "   -0.11190129816532135,\n",
       "   -0.16902431845664978,\n",
       "   -0.22297242283821106,\n",
       "   0.002895776182413101,\n",
       "   -0.08206239342689514,\n",
       "   -0.04077577590942383,\n",
       "   0.07998060435056686,\n",
       "   0.22379225492477417,\n",
       "   -0.17129851877689362,\n",
       "   0.11806778609752655,\n",
       "   -0.06212474778294563,\n",
       "   -0.2654874324798584,\n",
       "   0.3395911455154419,\n",
       "   0.2996237874031067,\n",
       "   0.27134621143341064,\n",
       "   0.014310427010059357,\n",
       "   0.28366175293922424,\n",
       "   0.3591310679912567,\n",
       "   -0.016698339954018593,\n",
       "   -0.10803913325071335,\n",
       "   -0.05379287526011467,\n",
       "   -0.14951327443122864,\n",
       "   -0.025165637955069542,\n",
       "   -0.16531479358673096,\n",
       "   0.10242272913455963,\n",
       "   0.05050203949213028,\n",
       "   -0.22047656774520874,\n",
       "   -0.043205469846725464,\n",
       "   -0.2259204238653183,\n",
       "   2.0817759037017822,\n",
       "   0.4467206597328186,\n",
       "   0.11490706354379654,\n",
       "   -0.11260270327329636,\n",
       "   0.14487603306770325,\n",
       "   -0.03374583646655083,\n",
       "   -0.08374068140983582,\n",
       "   0.41037121415138245,\n",
       "   -0.05910996347665787,\n",
       "   0.2217167764902115,\n",
       "   -0.11393222212791443,\n",
       "   0.2520650625228882,\n",
       "   -0.17494535446166992,\n",
       "   0.17411968111991882,\n",
       "   0.409193217754364,\n",
       "   0.11452315747737885,\n",
       "   0.22857342660427094,\n",
       "   -0.3063148856163025,\n",
       "   -0.2248758226633072,\n",
       "   -0.037247370928525925,\n",
       "   -0.4895465672016144,\n",
       "   0.2638457417488098,\n",
       "   0.27213892340660095,\n",
       "   -0.001576542854309082,\n",
       "   -0.046288467943668365,\n",
       "   0.32568368315696716,\n",
       "   0.15255853533744812,\n",
       "   -0.11119668185710907,\n",
       "   0.27868592739105225,\n",
       "   0.16447541117668152,\n",
       "   0.0326741598546505,\n",
       "   0.09207035601139069,\n",
       "   0.12340331077575684,\n",
       "   0.3943895101547241,\n",
       "   -0.3725793957710266,\n",
       "   -0.22407039999961853,\n",
       "   -0.02505563199520111,\n",
       "   -0.16032415628433228,\n",
       "   -0.15286144614219666,\n",
       "   0.12003813683986664,\n",
       "   0.10215038061141968,\n",
       "   -0.4209567904472351,\n",
       "   0.3861692249774933,\n",
       "   -0.08763951063156128,\n",
       "   -0.11373264342546463,\n",
       "   0.4380152225494385,\n",
       "   -0.10041730105876923,\n",
       "   -0.35476914048194885,\n",
       "   0.2963767647743225,\n",
       "   0.20037971436977386,\n",
       "   -0.00357949361205101,\n",
       "   0.017506390810012817,\n",
       "   -0.3323913812637329,\n",
       "   0.021644389256834984,\n",
       "   0.01372719556093216,\n",
       "   -0.15821780264377594,\n",
       "   0.09430884569883347,\n",
       "   0.04238278791308403,\n",
       "   -0.07403700798749924,\n",
       "   -0.08196845650672913,\n",
       "   -0.05646125227212906,\n",
       "   0.13998696208000183,\n",
       "   0.28176847100257874,\n",
       "   0.22388865053653717,\n",
       "   0.24760104715824127,\n",
       "   0.10161270946264267,\n",
       "   -0.15582408010959625,\n",
       "   0.06966262310743332,\n",
       "   0.06744484603404999,\n",
       "   -0.048552557826042175,\n",
       "   0.06390456110239029,\n",
       "   0.32811716198921204,\n",
       "   0.4234822392463684,\n",
       "   0.012863945215940475,\n",
       "   0.1584283709526062,\n",
       "   -0.08838453888893127,\n",
       "   0.466240257024765,\n",
       "   0.16123101115226746,\n",
       "   -0.05961567535996437,\n",
       "   -2.7199811935424805,\n",
       "   0.2381746619939804,\n",
       "   0.07918217778205872,\n",
       "   -0.08866871893405914,\n",
       "   -0.17323580384254456,\n",
       "   0.3579196035861969,\n",
       "   0.3832073509693146,\n",
       "   -0.0831792801618576,\n",
       "   -0.017860323190689087,\n",
       "   -0.08431632816791534,\n",
       "   0.2706400156021118,\n",
       "   0.15971139073371887,\n",
       "   0.4034496247768402,\n",
       "   0.024495624005794525,\n",
       "   0.07221892476081848,\n",
       "   -0.010796409100294113,\n",
       "   0.053474314510822296,\n",
       "   -0.21729570627212524,\n",
       "   -0.1028476282954216,\n",
       "   -0.11736209690570831,\n",
       "   -0.09312650561332703,\n",
       "   0.36695390939712524,\n",
       "   0.03739113360643387,\n",
       "   -0.2933957278728485,\n",
       "   -0.33690398931503296,\n",
       "   0.24429692327976227,\n",
       "   -0.1464226096868515,\n",
       "   -0.25056493282318115,\n",
       "   0.011083688586950302,\n",
       "   0.14152418076992035,\n",
       "   -0.05228033661842346,\n",
       "   0.21956442296504974,\n",
       "   -0.34925466775894165,\n",
       "   -0.14026695489883423,\n",
       "   -0.02492867410182953,\n",
       "   0.03821305185556412,\n",
       "   -0.2552134096622467,\n",
       "   -0.10916638374328613,\n",
       "   0.029009047895669937,\n",
       "   0.30063724517822266,\n",
       "   -0.15047931671142578,\n",
       "   0.5533101558685303,\n",
       "   -0.13361482322216034,\n",
       "   0.24501268565654755,\n",
       "   0.03126008063554764,\n",
       "   -0.08708354830741882,\n",
       "   0.4189358353614807,\n",
       "   -0.43592169880867004,\n",
       "   0.06549257040023804,\n",
       "   -0.36129090189933777,\n",
       "   -0.002467665821313858,\n",
       "   0.02010163478553295,\n",
       "   0.33038586378097534,\n",
       "   -0.03063591755926609,\n",
       "   0.18530960381031036,\n",
       "   -0.0006399750709533691,\n",
       "   0.34903866052627563,\n",
       "   0.03211037814617157,\n",
       "   -0.06552385538816452,\n",
       "   -0.11441125720739365,\n",
       "   0.11997190862894058,\n",
       "   0.004203781485557556,\n",
       "   0.02772895246744156,\n",
       "   -0.0742703527212143,\n",
       "   0.1780519336462021,\n",
       "   -0.13183021545410156,\n",
       "   -0.27580228447914124,\n",
       "   0.008217573165893555,\n",
       "   0.013235707767307758,\n",
       "   -0.16991813480854034,\n",
       "   -0.3152107000350952,\n",
       "   -0.31308990716934204,\n",
       "   0.22926592826843262,\n",
       "   0.1697162240743637,\n",
       "   0.05662501975893974,\n",
       "   -0.10752058029174805,\n",
       "   0.3375281095504761,\n",
       "   0.045586466789245605,\n",
       "   0.18099337816238403,\n",
       "   0.0568348728120327,\n",
       "   -0.19691485166549683,\n",
       "   -0.15452653169631958,\n",
       "   0.08786527067422867,\n",
       "   -0.20492950081825256,\n",
       "   0.00790654681622982,\n",
       "   -7.392797946929932,\n",
       "   -0.07288683205842972,\n",
       "   -0.14927850663661957,\n",
       "   -0.052446264773607254,\n",
       "   -0.0672488808631897,\n",
       "   -0.242489293217659,\n",
       "   -0.04998275265097618,\n",
       "   -0.06269954890012741,\n",
       "   0.06842712312936783,\n",
       "   -0.21331310272216797,\n",
       "   0.25745245814323425,\n",
       "   -0.046422429382801056,\n",
       "   -0.035300951451063156,\n",
       "   -0.04799402132630348,\n",
       "   0.4119160771369934,\n",
       "   0.15952685475349426],\n",
       "  [0.5480237603187561,\n",
       "   -0.14845868945121765,\n",
       "   0.008829627186059952,\n",
       "   0.31825703382492065,\n",
       "   -0.23657812178134918,\n",
       "   -0.3616675138473511,\n",
       "   -0.3843996226787567,\n",
       "   1.007442831993103,\n",
       "   -0.14436616003513336,\n",
       "   -0.34350019693374634,\n",
       "   -0.18949897587299347,\n",
       "   -0.5735834240913391,\n",
       "   -0.3061424493789673,\n",
       "   0.5645260214805603,\n",
       "   -0.4282355010509491,\n",
       "   0.3803177773952484,\n",
       "   0.5713324546813965,\n",
       "   -0.05658905208110809,\n",
       "   0.2236577421426773,\n",
       "   0.738961935043335,\n",
       "   0.04447446018457413,\n",
       "   -0.1088843047618866,\n",
       "   -0.4199511408805847,\n",
       "   0.2129136323928833,\n",
       "   -0.14594879746437073,\n",
       "   -0.4835052788257599,\n",
       "   0.13144278526306152,\n",
       "   -0.0494258813560009,\n",
       "   -0.13575661182403564,\n",
       "   0.048401497304439545,\n",
       "   0.16814063489437103,\n",
       "   -0.47513705492019653,\n",
       "   -0.5965955853462219,\n",
       "   -0.8206641674041748,\n",
       "   -0.2998703718185425,\n",
       "   -0.3057009279727936,\n",
       "   -0.10300754010677338,\n",
       "   0.3123207986354828,\n",
       "   -0.3212054371833801,\n",
       "   -0.3408324122428894,\n",
       "   0.29044264554977417,\n",
       "   -0.6943026185035706,\n",
       "   -0.09934459626674652,\n",
       "   0.017194634303450584,\n",
       "   0.32339775562286377,\n",
       "   -0.48505377769470215,\n",
       "   0.20475085079669952,\n",
       "   -0.028271915391087532,\n",
       "   0.40037792921066284,\n",
       "   -0.9029913544654846,\n",
       "   -0.019333310425281525,\n",
       "   -0.031793560832738876,\n",
       "   0.4206923246383667,\n",
       "   0.40731003880500793,\n",
       "   0.12199501693248749,\n",
       "   0.814873993396759,\n",
       "   -0.10859876871109009,\n",
       "   0.22361236810684204,\n",
       "   -0.1585245430469513,\n",
       "   0.22044043242931366,\n",
       "   -0.01771702617406845,\n",
       "   0.11685797572135925,\n",
       "   0.31598082184791565,\n",
       "   -0.6617785096168518,\n",
       "   -0.05075594037771225,\n",
       "   0.5818212032318115,\n",
       "   0.1814865618944168,\n",
       "   -0.3395247459411621,\n",
       "   -0.36153900623321533,\n",
       "   0.2497875988483429,\n",
       "   -0.40384092926979065,\n",
       "   -0.5412757992744446,\n",
       "   -0.1273431032896042,\n",
       "   0.11237284541130066,\n",
       "   -0.1359516978263855,\n",
       "   -0.2485721856355667,\n",
       "   0.07609234750270844,\n",
       "   0.16767850518226624,\n",
       "   0.04638465493917465,\n",
       "   0.06914055347442627,\n",
       "   0.44793251156806946,\n",
       "   1.083795428276062,\n",
       "   -0.7081340551376343,\n",
       "   0.48198050260543823,\n",
       "   -0.05634790658950806,\n",
       "   -0.005013372749090195,\n",
       "   -1.1245070695877075,\n",
       "   -0.16009224951267242,\n",
       "   0.09298800677061081,\n",
       "   0.43543553352355957,\n",
       "   -0.015456998720765114,\n",
       "   -0.01118633896112442,\n",
       "   0.23997846245765686,\n",
       "   0.042224541306495667,\n",
       "   0.06052376329898834,\n",
       "   -0.9535399675369263,\n",
       "   -0.24815623462200165,\n",
       "   0.2426549792289734,\n",
       "   0.8001958131790161,\n",
       "   0.6220464706420898,\n",
       "   0.0118921659886837,\n",
       "   -0.3501270115375519,\n",
       "   0.032588422298431396,\n",
       "   -0.6158797740936279,\n",
       "   -0.04741174355149269,\n",
       "   -0.45724359154701233,\n",
       "   0.128825843334198,\n",
       "   0.5110242962837219,\n",
       "   0.17902591824531555,\n",
       "   -1.1052614450454712,\n",
       "   -0.047722265124320984,\n",
       "   -0.42047590017318726,\n",
       "   0.048958152532577515,\n",
       "   -0.6583156585693359,\n",
       "   0.01452074944972992,\n",
       "   0.41297170519828796,\n",
       "   0.05576355755329132,\n",
       "   -0.3623030483722687,\n",
       "   -0.25437337160110474,\n",
       "   0.1532156616449356,\n",
       "   0.018677491694688797,\n",
       "   0.46428391337394714,\n",
       "   -0.1146593689918518,\n",
       "   0.4118681252002716,\n",
       "   -0.07520890980958939,\n",
       "   0.17173779010772705,\n",
       "   -0.2675684988498688,\n",
       "   -0.07007255405187607,\n",
       "   -0.2507686913013458,\n",
       "   -0.7456348538398743,\n",
       "   0.5662546157836914,\n",
       "   0.8582725524902344,\n",
       "   0.28296399116516113,\n",
       "   -0.7885465025901794,\n",
       "   -0.05711652338504791,\n",
       "   0.053421370685100555,\n",
       "   0.5970462560653687,\n",
       "   -0.16704872250556946,\n",
       "   -0.3856920599937439,\n",
       "   0.10397666692733765,\n",
       "   0.5304443836212158,\n",
       "   0.24595290422439575,\n",
       "   -0.1763099581003189,\n",
       "   -0.008562469854950905,\n",
       "   0.647146463394165,\n",
       "   -0.01676919311285019,\n",
       "   -0.10213311016559601,\n",
       "   -0.6444417834281921,\n",
       "   -0.003705345094203949,\n",
       "   0.46237924695014954,\n",
       "   -0.5517072081565857,\n",
       "   -0.04227307066321373,\n",
       "   0.0309414342045784,\n",
       "   -0.3187812864780426,\n",
       "   -0.1955261528491974,\n",
       "   0.5770872831344604,\n",
       "   -0.820559561252594,\n",
       "   -0.18129238486289978,\n",
       "   0.45717141032218933,\n",
       "   0.16589179635047913,\n",
       "   0.31876856088638306,\n",
       "   -0.26040512323379517,\n",
       "   -0.33094170689582825,\n",
       "   0.514926552772522,\n",
       "   -0.6850187182426453,\n",
       "   0.1945309191942215,\n",
       "   0.23228655755519867,\n",
       "   0.41867706179618835,\n",
       "   0.2772766947746277,\n",
       "   0.3352217972278595,\n",
       "   -0.39406201243400574,\n",
       "   0.010492686182260513,\n",
       "   0.658283531665802,\n",
       "   -0.20806430280208588,\n",
       "   0.034453101456165314,\n",
       "   -0.13958212733268738,\n",
       "   0.4114782512187958,\n",
       "   -0.0911828875541687,\n",
       "   0.4855627417564392,\n",
       "   0.2323191910982132,\n",
       "   -0.44360417127609253,\n",
       "   1.1419862508773804,\n",
       "   0.09372551739215851,\n",
       "   -0.0324033759534359,\n",
       "   -0.3611433506011963,\n",
       "   -0.28055432438850403,\n",
       "   0.6646409630775452,\n",
       "   -0.32190176844596863,\n",
       "   -0.06906889379024506,\n",
       "   0.702990710735321,\n",
       "   0.6107891798019409,\n",
       "   -0.30704835057258606,\n",
       "   0.09244377911090851,\n",
       "   0.011981774121522903,\n",
       "   1.1350396871566772,\n",
       "   -0.21958881616592407,\n",
       "   -0.33483004570007324,\n",
       "   -1.1814134120941162,\n",
       "   -0.044488903135061264,\n",
       "   0.14514264464378357,\n",
       "   -0.11236711591482162,\n",
       "   -0.2702992260456085,\n",
       "   0.4639211595058441,\n",
       "   0.2995873689651489,\n",
       "   -0.7404305934906006,\n",
       "   1.6404907703399658,\n",
       "   -0.0766177624464035,\n",
       "   -0.6446245908737183,\n",
       "   -0.11050005257129669,\n",
       "   0.34644433856010437,\n",
       "   -0.14852546155452728,\n",
       "   0.43366777896881104,\n",
       "   0.09361004084348679,\n",
       "   -0.25282880663871765,\n",
       "   0.0989348515868187,\n",
       "   -0.13983017206192017,\n",
       "   0.4022026062011719,\n",
       "   0.14470139145851135,\n",
       "   -0.013543259352445602,\n",
       "   -0.0275149866938591,\n",
       "   0.17938120663166046,\n",
       "   0.126535102725029,\n",
       "   -0.5491381883621216,\n",
       "   1.192535400390625,\n",
       "   0.2579996585845947,\n",
       "   0.906652569770813,\n",
       "   -0.06440867483615875,\n",
       "   -0.11334575712680817,\n",
       "   0.023700464516878128,\n",
       "   -0.2176532745361328,\n",
       "   -0.17692780494689941,\n",
       "   -0.4294939935207367,\n",
       "   0.1860273778438568,\n",
       "   0.4538586139678955,\n",
       "   0.017947807908058167,\n",
       "   -0.5317068696022034,\n",
       "   -0.38800621032714844,\n",
       "   0.29943475127220154,\n",
       "   -0.11485116928815842,\n",
       "   0.2320040762424469,\n",
       "   -0.45716914534568787,\n",
       "   -0.4663318991661072,\n",
       "   0.16227179765701294,\n",
       "   0.21900534629821777,\n",
       "   -0.13548970222473145,\n",
       "   0.567883312702179,\n",
       "   0.13193804025650024,\n",
       "   -0.4783163070678711,\n",
       "   -0.6644120216369629,\n",
       "   -0.0509842224419117,\n",
       "   -0.46128612756729126,\n",
       "   -0.5400322079658508,\n",
       "   0.12402272969484329,\n",
       "   -1.1062144041061401,\n",
       "   -0.15981894731521606,\n",
       "   -0.06416048109531403,\n",
       "   -0.36119741201400757,\n",
       "   0.08349601924419403,\n",
       "   -0.40901151299476624,\n",
       "   0.8476133942604065,\n",
       "   -0.33646348118782043,\n",
       "   -0.42597994208335876,\n",
       "   0.37512320280075073,\n",
       "   -0.12289893627166748,\n",
       "   -0.8794047832489014,\n",
       "   -0.4459584951400757,\n",
       "   -0.16557389497756958,\n",
       "   0.254611074924469,\n",
       "   0.627490222454071,\n",
       "   0.5192663073539734,\n",
       "   -0.029077406972646713,\n",
       "   -0.4047282934188843,\n",
       "   0.09279438853263855,\n",
       "   -0.7053236961364746,\n",
       "   0.05983896926045418,\n",
       "   -0.18621790409088135,\n",
       "   0.41132989525794983,\n",
       "   -0.07263441383838654,\n",
       "   -0.32159116864204407,\n",
       "   0.2209753543138504,\n",
       "   0.03289865702390671,\n",
       "   0.7478380799293518,\n",
       "   0.09448385238647461,\n",
       "   0.5862067341804504,\n",
       "   -0.019327232614159584,\n",
       "   -0.5197616815567017,\n",
       "   0.28776076436042786,\n",
       "   0.4449087381362915,\n",
       "   -0.7446215152740479,\n",
       "   -0.15034119784832,\n",
       "   -0.1747678965330124,\n",
       "   0.5562825202941895,\n",
       "   -0.2972884476184845,\n",
       "   -0.34471195936203003,\n",
       "   0.05215436592698097,\n",
       "   -0.2754983603954315,\n",
       "   0.4538043141365051,\n",
       "   -0.5570634603500366,\n",
       "   -0.073170006275177,\n",
       "   -0.08189557492733002,\n",
       "   0.16318649053573608,\n",
       "   -0.6558435559272766,\n",
       "   -0.1936151385307312,\n",
       "   0.19741961359977722,\n",
       "   0.39245161414146423,\n",
       "   0.0048165395855903625,\n",
       "   -0.16515357792377472,\n",
       "   -0.7891227006912231,\n",
       "   -3.70302414894104,\n",
       "   -0.22065064311027527,\n",
       "   -0.5570077300071716,\n",
       "   0.4285967946052551,\n",
       "   -0.12305040657520294,\n",
       "   -0.46490973234176636,\n",
       "   0.43743911385536194,\n",
       "   -0.3639322817325592,\n",
       "   -0.6636691093444824,\n",
       "   -0.41938623785972595,\n",
       "   -0.41136935353279114,\n",
       "   0.08179301023483276,\n",
       "   0.5035276412963867,\n",
       "   0.6287649869918823,\n",
       "   0.7637034058570862,\n",
       "   0.40999308228492737,\n",
       "   0.06827762722969055,\n",
       "   -0.11346395313739777,\n",
       "   0.10303959995508194,\n",
       "   0.863805890083313,\n",
       "   0.06092967092990875,\n",
       "   -0.13977156579494476,\n",
       "   0.10896485298871994,\n",
       "   -0.36886659264564514,\n",
       "   0.46384477615356445,\n",
       "   0.8958062529563904,\n",
       "   -0.6079283356666565,\n",
       "   0.2566434442996979,\n",
       "   -0.1393914520740509,\n",
       "   0.2683935761451721,\n",
       "   -0.19812005758285522,\n",
       "   0.26861587166786194,\n",
       "   0.19239839911460876,\n",
       "   -0.0977228656411171,\n",
       "   0.4855671525001526,\n",
       "   0.23797334730625153,\n",
       "   -0.26704883575439453,\n",
       "   0.15076440572738647,\n",
       "   0.6117843389511108,\n",
       "   0.7182925343513489,\n",
       "   0.10295265913009644,\n",
       "   -0.5211327075958252,\n",
       "   -0.40391409397125244,\n",
       "   0.32009631395339966,\n",
       "   0.5659374594688416,\n",
       "   0.4315907955169678,\n",
       "   0.45316755771636963,\n",
       "   -0.5684137344360352,\n",
       "   0.176207035779953,\n",
       "   0.2381148338317871,\n",
       "   -0.25972437858581543,\n",
       "   -0.4535973072052002,\n",
       "   0.36701107025146484,\n",
       "   0.04899521917104721,\n",
       "   0.1494988352060318,\n",
       "   -0.6571471691131592,\n",
       "   0.37137383222579956,\n",
       "   0.5120848417282104,\n",
       "   0.02422468364238739,\n",
       "   -0.7820193767547607,\n",
       "   -0.02872379869222641,\n",
       "   -0.8362464904785156,\n",
       "   -0.7251567840576172,\n",
       "   -0.10580262541770935,\n",
       "   -0.07926835119724274,\n",
       "   -0.13732028007507324,\n",
       "   -0.2744695544242859,\n",
       "   -0.03505781292915344,\n",
       "   0.6040624976158142,\n",
       "   0.11284002661705017,\n",
       "   0.024973629042506218,\n",
       "   0.4458657503128052,\n",
       "   0.26215124130249023,\n",
       "   -1.3161460161209106,\n",
       "   0.0373053178191185,\n",
       "   0.5146856307983398,\n",
       "   -0.5743353366851807,\n",
       "   -0.1947791874408722,\n",
       "   0.04903920739889145,\n",
       "   0.8029783964157104,\n",
       "   -0.40960752964019775,\n",
       "   -0.6916356682777405,\n",
       "   -0.040193021297454834,\n",
       "   -0.021068690344691277,\n",
       "   0.35764095187187195,\n",
       "   -1.195138931274414,\n",
       "   -0.06859119236469269,\n",
       "   0.0700191780924797,\n",
       "   0.0964311733841896,\n",
       "   -0.3765721619129181,\n",
       "   0.2199394404888153,\n",
       "   0.44110655784606934,\n",
       "   0.6054270267486572,\n",
       "   0.2066033035516739,\n",
       "   0.3187384605407715,\n",
       "   -0.04441554844379425,\n",
       "   0.23612722754478455,\n",
       "   -0.9643439054489136,\n",
       "   0.8393526673316956,\n",
       "   -0.2235761135816574,\n",
       "   0.0010597854852676392,\n",
       "   -0.19569995999336243,\n",
       "   0.6328479051589966,\n",
       "   -0.6216014623641968,\n",
       "   0.6351650357246399,\n",
       "   -0.3669487237930298,\n",
       "   -0.27356356382369995,\n",
       "   -0.08406701683998108,\n",
       "   -0.43691128492355347,\n",
       "   0.15587404370307922,\n",
       "   -0.14349250495433807,\n",
       "   -0.1615232229232788,\n",
       "   0.2646596133708954,\n",
       "   -0.11218827217817307,\n",
       "   0.2585715651512146,\n",
       "   -0.16014519333839417,\n",
       "   -0.1607106626033783,\n",
       "   0.5239595770835876,\n",
       "   -0.7551089525222778,\n",
       "   -0.03821949660778046,\n",
       "   0.2123740017414093,\n",
       "   0.8418468832969666,\n",
       "   -0.1262402981519699,\n",
       "   -0.9210245013237,\n",
       "   -0.5652161240577698,\n",
       "   0.1326671838760376,\n",
       "   0.21005432307720184,\n",
       "   -1.0234622955322266,\n",
       "   -0.9835813641548157,\n",
       "   -0.027767792344093323,\n",
       "   -0.061776500195264816,\n",
       "   0.02770032361149788,\n",
       "   0.04302950203418732,\n",
       "   -0.2976340651512146,\n",
       "   0.10308197140693665,\n",
       "   -0.5022477507591248,\n",
       "   -0.47802379727363586,\n",
       "   -0.8494635820388794,\n",
       "   0.5103839635848999,\n",
       "   -0.019774891436100006,\n",
       "   0.46758297085762024,\n",
       "   0.12798067927360535,\n",
       "   0.1315496414899826,\n",
       "   0.38550177216529846,\n",
       "   -0.6004295349121094,\n",
       "   1.0337287187576294,\n",
       "   -0.254205584526062,\n",
       "   -0.10616877675056458,\n",
       "   0.45527809858322144,\n",
       "   0.5696635842323303,\n",
       "   -0.5607628226280212,\n",
       "   -0.00951792299747467,\n",
       "   -0.15570421516895294,\n",
       "   -0.24294543266296387,\n",
       "   0.7047399282455444,\n",
       "   -0.20874294638633728,\n",
       "   0.5205749273300171,\n",
       "   -0.26910972595214844,\n",
       "   0.19585499167442322,\n",
       "   -0.44308048486709595,\n",
       "   -0.7055363059043884,\n",
       "   0.29885241389274597,\n",
       "   -0.3898206651210785,\n",
       "   0.17153729498386383,\n",
       "   0.18418574333190918,\n",
       "   0.5199678540229797,\n",
       "   -0.30326810479164124,\n",
       "   0.3500746488571167,\n",
       "   0.33846911787986755,\n",
       "   -0.014202818274497986,\n",
       "   -0.005810232367366552,\n",
       "   0.028009705245494843,\n",
       "   -0.08528632670640945,\n",
       "   -0.655104398727417,\n",
       "   -0.6799242496490479,\n",
       "   -0.03616840019822121,\n",
       "   -0.11956998705863953,\n",
       "   0.42150214314460754,\n",
       "   -0.3845459222793579,\n",
       "   0.333253413438797,\n",
       "   -0.2256004810333252,\n",
       "   -0.10133343189954758,\n",
       "   0.22791901230812073,\n",
       "   -0.17950333654880524,\n",
       "   0.36442330479621887,\n",
       "   0.5808071494102478,\n",
       "   -0.15473562479019165,\n",
       "   0.10536013543605804,\n",
       "   -0.10373225808143616,\n",
       "   0.7940303087234497,\n",
       "   0.37991371750831604,\n",
       "   0.26222848892211914,\n",
       "   -0.35745251178741455,\n",
       "   -0.3309193253517151,\n",
       "   -0.5105805397033691,\n",
       "   -0.6084388494491577,\n",
       "   0.27627548575401306,\n",
       "   0.051409393548965454,\n",
       "   -0.03444725647568703,\n",
       "   0.0009597623720765114,\n",
       "   -0.15245506167411804,\n",
       "   -0.3772922456264496,\n",
       "   -0.5318343043327332,\n",
       "   0.06065679341554642,\n",
       "   0.05854892358183861,\n",
       "   -0.3501185476779938,\n",
       "   0.9166208505630493,\n",
       "   0.75948566198349,\n",
       "   -0.2453659176826477,\n",
       "   0.5257811546325684,\n",
       "   -1.4047771692276,\n",
       "   -0.611815333366394,\n",
       "   -0.1985597014427185,\n",
       "   -0.25637122988700867,\n",
       "   -0.13342231512069702,\n",
       "   -0.19910410046577454,\n",
       "   0.3794983923435211,\n",
       "   0.008992306888103485,\n",
       "   -0.19470389187335968,\n",
       "   -0.19171105325222015,\n",
       "   -0.3835846185684204,\n",
       "   0.06422911584377289,\n",
       "   -0.6185909509658813,\n",
       "   -0.08484840393066406,\n",
       "   -0.9843340516090393,\n",
       "   0.29065847396850586,\n",
       "   -0.386626273393631,\n",
       "   -0.7816746234893799,\n",
       "   -0.6757745146751404,\n",
       "   -0.19171607494354248,\n",
       "   0.26398006081581116,\n",
       "   -0.6965309381484985,\n",
       "   0.5570574998855591,\n",
       "   0.15037739276885986,\n",
       "   0.0842544212937355,\n",
       "   0.3100064992904663,\n",
       "   -0.27077579498291016,\n",
       "   0.6164090633392334,\n",
       "   0.6288579702377319,\n",
       "   0.33216315507888794,\n",
       "   0.11992594599723816,\n",
       "   -0.18978483974933624,\n",
       "   0.02428262308239937,\n",
       "   -0.7807081341743469,\n",
       "   0.12053355574607849,\n",
       "   -0.4725976884365082,\n",
       "   0.0005058012902736664,\n",
       "   0.5502937436103821,\n",
       "   -0.560975193977356,\n",
       "   0.26952096819877625,\n",
       "   0.3862918019294739,\n",
       "   -0.3495948016643524,\n",
       "   0.05352028086781502,\n",
       "   -0.416021466255188,\n",
       "   -0.19744761288166046,\n",
       "   -0.5295332670211792,\n",
       "   -0.7702571153640747,\n",
       "   -0.13656660914421082,\n",
       "   0.3023615777492523,\n",
       "   -0.15056243538856506,\n",
       "   0.516816258430481,\n",
       "   0.05797770246863365,\n",
       "   0.20439402759075165,\n",
       "   0.164251908659935,\n",
       "   -0.03418135643005371,\n",
       "   0.735736608505249,\n",
       "   0.7527304887771606,\n",
       "   0.1726912260055542,\n",
       "   0.14367125928401947,\n",
       "   -0.03881324082612991,\n",
       "   0.04333707317709923,\n",
       "   -0.10228683054447174,\n",
       "   0.03789228945970535,\n",
       "   0.1730785220861435,\n",
       "   0.33980512619018555,\n",
       "   0.012285657227039337,\n",
       "   0.08542703837156296,\n",
       "   0.03468065708875656,\n",
       "   -0.4350906014442444,\n",
       "   -0.1457763910293579,\n",
       "   0.6623182892799377,\n",
       "   1.0606015920639038,\n",
       "   -0.0670602023601532,\n",
       "   -0.4232570230960846,\n",
       "   0.26972001791000366,\n",
       "   0.0662364661693573,\n",
       "   -0.03497147187590599,\n",
       "   0.9924848675727844,\n",
       "   0.17531055212020874,\n",
       "   0.6078311800956726,\n",
       "   0.22371765971183777,\n",
       "   0.3356904983520508,\n",
       "   0.01343533769249916,\n",
       "   0.03804950416088104,\n",
       "   0.009907416999340057,\n",
       "   -0.43282264471054077,\n",
       "   0.31554466485977173,\n",
       "   0.12938663363456726,\n",
       "   -0.21453766524791718,\n",
       "   0.29110029339790344,\n",
       "   -0.7209134101867676,\n",
       "   -0.2428162693977356,\n",
       "   0.10288994014263153,\n",
       "   0.528408408164978,\n",
       "   -0.3081730306148529,\n",
       "   -0.17661786079406738,\n",
       "   0.4831751585006714,\n",
       "   -0.11660586297512054,\n",
       "   0.5142393708229065,\n",
       "   0.15762600302696228,\n",
       "   -0.06389179825782776,\n",
       "   -0.26068663597106934,\n",
       "   0.6166674494743347,\n",
       "   0.1224287673830986,\n",
       "   -0.9337987899780273,\n",
       "   -0.32962581515312195,\n",
       "   -0.08930589258670807,\n",
       "   0.10961930453777313,\n",
       "   -0.22611947357654572,\n",
       "   0.16078853607177734,\n",
       "   0.3130777180194855,\n",
       "   -0.680301308631897,\n",
       "   0.21488754451274872,\n",
       "   -0.3159742057323456,\n",
       "   0.34314796328544617,\n",
       "   0.412405401468277,\n",
       "   -0.3975825011730194,\n",
       "   -0.4775451123714447,\n",
       "   0.3012162744998932,\n",
       "   0.09670275449752808,\n",
       "   0.11045608669519424,\n",
       "   0.12489720433950424,\n",
       "   -0.22060281038284302,\n",
       "   0.32580599188804626,\n",
       "   -0.07067796587944031,\n",
       "   0.2441311776638031,\n",
       "   0.6019012331962585,\n",
       "   -0.12822037935256958,\n",
       "   0.1437700092792511,\n",
       "   -0.7378180027008057,\n",
       "   0.053493253886699677,\n",
       "   0.9588487148284912,\n",
       "   0.9473273158073425,\n",
       "   1.0565731525421143,\n",
       "   0.5861403942108154,\n",
       "   0.1041637733578682,\n",
       "   0.15093529224395752,\n",
       "   0.015964515507221222,\n",
       "   0.5101616978645325,\n",
       "   0.08035604655742645,\n",
       "   0.4144385755062103,\n",
       "   0.592953085899353,\n",
       "   0.38892677426338196,\n",
       "   -0.1901308000087738,\n",
       "   0.23345324397087097,\n",
       "   -0.7391020059585571,\n",
       "   0.2146170437335968,\n",
       "   0.6153817772865295,\n",
       "   0.18774598836898804,\n",
       "   -1.2895339727401733,\n",
       "   0.14138346910476685,\n",
       "   -0.4500500559806824,\n",
       "   -0.17100030183792114,\n",
       "   -0.406206876039505,\n",
       "   0.4042195975780487,\n",
       "   0.5433071255683899,\n",
       "   0.3350769281387329,\n",
       "   0.33745527267456055,\n",
       "   -0.5856893658638,\n",
       "   0.25903528928756714,\n",
       "   -0.1313517987728119,\n",
       "   -0.024154681712388992,\n",
       "   -0.16252359747886658,\n",
       "   -0.06100085377693176,\n",
       "   0.21227653324604034,\n",
       "   0.3899315297603607,\n",
       "   0.3338185250759125,\n",
       "   -0.47154971957206726,\n",
       "   -0.18409690260887146,\n",
       "   0.4431362450122833,\n",
       "   0.5106481313705444,\n",
       "   0.18120020627975464,\n",
       "   -0.47513437271118164,\n",
       "   -0.6137814521789551,\n",
       "   0.18104173243045807,\n",
       "   -0.7962200045585632,\n",
       "   -0.7734267711639404,\n",
       "   0.008084230124950409,\n",
       "   0.26715636253356934,\n",
       "   -0.29558065533638,\n",
       "   0.4046670198440552,\n",
       "   -0.36656394600868225,\n",
       "   -0.49022728204727173,\n",
       "   -1.1809275150299072,\n",
       "   0.08916261792182922,\n",
       "   -0.7436590194702148,\n",
       "   -0.1489938497543335,\n",
       "   0.6232388615608215,\n",
       "   0.3790704607963562,\n",
       "   -0.06093139573931694,\n",
       "   1.3053972721099854,\n",
       "   0.27239567041397095,\n",
       "   0.009811781346797943,\n",
       "   -0.4075290560722351,\n",
       "   -0.5822189450263977,\n",
       "   0.30249476432800293,\n",
       "   -1.0892366170883179,\n",
       "   0.15525369346141815,\n",
       "   -0.3951553404331207,\n",
       "   0.0029899515211582184,\n",
       "   0.4478568136692047,\n",
       "   0.595890462398529,\n",
       "   -0.5170363187789917,\n",
       "   -0.13761836290359497,\n",
       "   -0.5169315934181213,\n",
       "   0.2230120599269867,\n",
       "   0.4548146724700928,\n",
       "   -0.4167877435684204,\n",
       "   -0.09140725433826447,\n",
       "   0.3714846670627594,\n",
       "   0.07608184218406677,\n",
       "   0.06626186519861221,\n",
       "   0.0428694523870945,\n",
       "   0.05046210065484047,\n",
       "   -0.02147756889462471,\n",
       "   -0.6383672952651978,\n",
       "   0.10978856682777405,\n",
       "   0.8090053200721741,\n",
       "   -0.1824968308210373,\n",
       "   -0.43932926654815674,\n",
       "   -1.0398930311203003,\n",
       "   0.01907121203839779,\n",
       "   0.5684471130371094,\n",
       "   -0.19738492369651794,\n",
       "   -0.39192095398902893,\n",
       "   0.2834884524345398,\n",
       "   0.24380892515182495,\n",
       "   0.1692839413881302,\n",
       "   -0.13076327741146088,\n",
       "   -0.5157577991485596,\n",
       "   0.17053653299808502,\n",
       "   0.43806061148643494,\n",
       "   0.17145861685276031,\n",
       "   -0.5900394916534424,\n",
       "   -1.4654134511947632,\n",
       "   -0.2181471586227417,\n",
       "   -0.9514141082763672,\n",
       "   -0.6698653697967529,\n",
       "   0.6599797606468201,\n",
       "   0.146255224943161,\n",
       "   0.2754875123500824,\n",
       "   -0.32893121242523193,\n",
       "   0.245604008436203,\n",
       "   -0.30548566579818726,\n",
       "   0.49368980526924133,\n",
       "   0.023876354098320007,\n",
       "   0.06893296539783478,\n",
       "   0.1420731246471405,\n",
       "   0.8880271315574646,\n",
       "   0.38844963908195496],\n",
       "  [0.5202009081840515,\n",
       "   0.24978218972682953,\n",
       "   0.38667386770248413,\n",
       "   0.3759375810623169,\n",
       "   -0.16484521329402924,\n",
       "   -0.3782500624656677,\n",
       "   -0.29962339997291565,\n",
       "   1.0650105476379395,\n",
       "   -0.8018839955329895,\n",
       "   -0.05962402746081352,\n",
       "   0.030076250433921814,\n",
       "   -0.5185372233390808,\n",
       "   -0.11581317335367203,\n",
       "   0.6928450465202332,\n",
       "   0.19691242277622223,\n",
       "   0.3523682951927185,\n",
       "   0.3698021471500397,\n",
       "   -0.24978449940681458,\n",
       "   -0.5353106260299683,\n",
       "   0.6733986735343933,\n",
       "   -0.0008893236517906189,\n",
       "   -0.2597058117389679,\n",
       "   -0.10588479042053223,\n",
       "   0.043873924762010574,\n",
       "   -0.07111290097236633,\n",
       "   -0.5803884267807007,\n",
       "   -0.21674060821533203,\n",
       "   -0.09102288633584976,\n",
       "   -0.20511630177497864,\n",
       "   0.14294493198394775,\n",
       "   0.15732437372207642,\n",
       "   0.06811515986919403,\n",
       "   -0.6518790125846863,\n",
       "   -0.2917350232601166,\n",
       "   0.24675241112709045,\n",
       "   -0.22669629752635956,\n",
       "   0.14588592946529388,\n",
       "   0.37634631991386414,\n",
       "   -0.10562257468700409,\n",
       "   -0.08479700982570648,\n",
       "   -0.2913089394569397,\n",
       "   -0.7393677234649658,\n",
       "   -0.07084890455007553,\n",
       "   -0.0177205391228199,\n",
       "   -0.28429555892944336,\n",
       "   -0.4492953419685364,\n",
       "   0.8485286235809326,\n",
       "   0.345039039850235,\n",
       "   0.47941774129867554,\n",
       "   -0.513028085231781,\n",
       "   -0.382058322429657,\n",
       "   0.4708564877510071,\n",
       "   0.1396155059337616,\n",
       "   0.05638941377401352,\n",
       "   -0.09220230579376221,\n",
       "   1.1690384149551392,\n",
       "   0.15751978754997253,\n",
       "   -0.3094257414340973,\n",
       "   -0.4188787043094635,\n",
       "   0.006410904228687286,\n",
       "   0.13387596607208252,\n",
       "   -0.29542380571365356,\n",
       "   0.20807422697544098,\n",
       "   -0.5287595391273499,\n",
       "   -0.1055295318365097,\n",
       "   0.1597885936498642,\n",
       "   0.07826171815395355,\n",
       "   -0.3218601942062378,\n",
       "   0.052903950214385986,\n",
       "   0.38413485884666443,\n",
       "   -0.8722490668296814,\n",
       "   -0.0820942297577858,\n",
       "   -0.47600460052490234,\n",
       "   0.35192230343818665,\n",
       "   -0.6732466220855713,\n",
       "   -0.02384094148874283,\n",
       "   0.016441909596323967,\n",
       "   0.4548375606536865,\n",
       "   0.24220964312553406,\n",
       "   0.1877322494983673,\n",
       "   0.17415300011634827,\n",
       "   0.9227738976478577,\n",
       "   -0.8598779439926147,\n",
       "   0.5335029363632202,\n",
       "   0.22639742493629456,\n",
       "   0.0012989416718482971,\n",
       "   -0.719295084476471,\n",
       "   -0.24645569920539856,\n",
       "   -0.016512084752321243,\n",
       "   0.6856384873390198,\n",
       "   0.14522872865200043,\n",
       "   0.00770752876996994,\n",
       "   0.18428760766983032,\n",
       "   0.18738925457000732,\n",
       "   -0.24825476109981537,\n",
       "   -0.6098089814186096,\n",
       "   -0.2964942157268524,\n",
       "   0.2515289783477783,\n",
       "   -0.14359356462955475,\n",
       "   0.4988764822483063,\n",
       "   0.6169962882995605,\n",
       "   -1.0013960599899292,\n",
       "   -0.14071886241436005,\n",
       "   -0.07576281577348709,\n",
       "   0.1480531394481659,\n",
       "   -0.06578396260738373,\n",
       "   0.2606937289237976,\n",
       "   0.160381019115448,\n",
       "   -0.09234035015106201,\n",
       "   -0.15883907675743103,\n",
       "   -0.07847858965396881,\n",
       "   -0.6631360054016113,\n",
       "   0.35791128873825073,\n",
       "   -0.28934913873672485,\n",
       "   -0.1485571265220642,\n",
       "   0.10952046513557434,\n",
       "   -0.11722443997859955,\n",
       "   -0.6309601664543152,\n",
       "   -0.21880552172660828,\n",
       "   0.09334437549114227,\n",
       "   -0.2576283812522888,\n",
       "   -0.05945354700088501,\n",
       "   -0.41384369134902954,\n",
       "   0.9994451999664307,\n",
       "   -0.15973801910877228,\n",
       "   0.0028907600790262222,\n",
       "   0.045231446623802185,\n",
       "   -0.2589656710624695,\n",
       "   0.12734979391098022,\n",
       "   -0.4664595425128937,\n",
       "   0.7977514863014221,\n",
       "   0.33430323004722595,\n",
       "   0.7027818560600281,\n",
       "   -0.8950892090797424,\n",
       "   -0.17617595195770264,\n",
       "   -0.042638666927814484,\n",
       "   0.11127868294715881,\n",
       "   -0.4579254984855652,\n",
       "   -0.551620364189148,\n",
       "   0.19624358415603638,\n",
       "   -0.0006800796836614609,\n",
       "   0.07522112131118774,\n",
       "   1.0011333227157593,\n",
       "   0.30654990673065186,\n",
       "   0.6643911004066467,\n",
       "   0.12305653095245361,\n",
       "   -0.4310242533683777,\n",
       "   -0.3413117527961731,\n",
       "   -0.17427031695842743,\n",
       "   0.061178822070360184,\n",
       "   -0.4607851505279541,\n",
       "   -0.67165607213974,\n",
       "   -0.20520484447479248,\n",
       "   -0.2806342542171478,\n",
       "   -0.11089398711919785,\n",
       "   0.003786608576774597,\n",
       "   -0.8088805675506592,\n",
       "   -0.18834736943244934,\n",
       "   0.640964925289154,\n",
       "   0.19703857600688934,\n",
       "   0.549302875995636,\n",
       "   -0.22219453752040863,\n",
       "   -0.41744235157966614,\n",
       "   0.022619377821683884,\n",
       "   0.1311541348695755,\n",
       "   -0.18589180707931519,\n",
       "   -0.004888230003416538,\n",
       "   0.3052408993244171,\n",
       "   0.22622129321098328,\n",
       "   0.22113479673862457,\n",
       "   -0.45711538195610046,\n",
       "   -0.26037871837615967,\n",
       "   0.695064902305603,\n",
       "   -0.45362982153892517,\n",
       "   0.002917356789112091,\n",
       "   -0.125796377658844,\n",
       "   0.44176730513572693,\n",
       "   -0.18121443688869476,\n",
       "   0.30031728744506836,\n",
       "   0.42827802896499634,\n",
       "   -0.544304609298706,\n",
       "   0.21860355138778687,\n",
       "   -0.03403228148818016,\n",
       "   0.039839405566453934,\n",
       "   0.2031833380460739,\n",
       "   -0.3050119876861572,\n",
       "   0.9084163904190063,\n",
       "   -0.3144444227218628,\n",
       "   -0.4423023462295532,\n",
       "   0.2874186635017395,\n",
       "   0.05651664733886719,\n",
       "   -0.4199571907520294,\n",
       "   -0.2032729834318161,\n",
       "   0.07212067395448685,\n",
       "   0.6342688202857971,\n",
       "   -0.29185056686401367,\n",
       "   -0.29413485527038574,\n",
       "   -1.0635442733764648,\n",
       "   0.14425018429756165,\n",
       "   0.02277565188705921,\n",
       "   0.044149816036224365,\n",
       "   -0.19924326241016388,\n",
       "   0.09116700291633606,\n",
       "   0.3088274896144867,\n",
       "   -0.5154768228530884,\n",
       "   0.5166388750076294,\n",
       "   -0.2584410607814789,\n",
       "   -0.5162892937660217,\n",
       "   -0.25096315145492554,\n",
       "   0.20910976827144623,\n",
       "   -0.39905303716659546,\n",
       "   0.7093627452850342,\n",
       "   0.04346179962158203,\n",
       "   0.4762749969959259,\n",
       "   -0.2817583382129669,\n",
       "   -0.14661702513694763,\n",
       "   0.09933684021234512,\n",
       "   -0.06981852650642395,\n",
       "   -0.4998490810394287,\n",
       "   0.07874857634305954,\n",
       "   -0.030875584110617638,\n",
       "   0.24947300553321838,\n",
       "   -0.3214957118034363,\n",
       "   0.8830131888389587,\n",
       "   0.3802318572998047,\n",
       "   0.8233014941215515,\n",
       "   0.11808422207832336,\n",
       "   -0.34758710861206055,\n",
       "   -0.10504531860351562,\n",
       "   0.1005791425704956,\n",
       "   -0.03553423658013344,\n",
       "   -0.2668868899345398,\n",
       "   0.2563479244709015,\n",
       "   -0.4319114089012146,\n",
       "   -0.2230106145143509,\n",
       "   -0.3680444657802582,\n",
       "   -0.15739527344703674,\n",
       "   0.16832217574119568,\n",
       "   0.014968222007155418,\n",
       "   -0.2769882082939148,\n",
       "   -0.6017557978630066,\n",
       "   0.12840266525745392,\n",
       "   0.3182692229747772,\n",
       "   0.1614340841770172,\n",
       "   0.11810602247714996,\n",
       "   0.24400518834590912,\n",
       "   -0.12141892313957214,\n",
       "   0.15211766958236694,\n",
       "   -0.4715667963027954,\n",
       "   -0.23999574780464172,\n",
       "   -0.26751166582107544,\n",
       "   -0.4379798173904419,\n",
       "   -0.056530460715293884,\n",
       "   -1.057035207748413,\n",
       "   -0.5074779391288757,\n",
       "   -0.40098506212234497,\n",
       "   -0.2265682965517044,\n",
       "   -0.27896246314048767,\n",
       "   -0.4550102651119232,\n",
       "   0.8586692810058594,\n",
       "   -0.3104006350040436,\n",
       "   -0.4345463812351227,\n",
       "   0.43365544080734253,\n",
       "   0.07051020115613937,\n",
       "   -0.6887557506561279,\n",
       "   -0.5871008634567261,\n",
       "   0.03927868604660034,\n",
       "   0.11106210201978683,\n",
       "   0.5842707753181458,\n",
       "   0.33507102727890015,\n",
       "   0.3193795084953308,\n",
       "   -0.37735477089881897,\n",
       "   0.08425699174404144,\n",
       "   0.8817158341407776,\n",
       "   -0.024357007816433907,\n",
       "   -0.3541298806667328,\n",
       "   -0.15321537852287292,\n",
       "   -0.2309686839580536,\n",
       "   -0.19217221438884735,\n",
       "   -0.5492734313011169,\n",
       "   0.27904224395751953,\n",
       "   0.4959513545036316,\n",
       "   0.03995825722813606,\n",
       "   0.19264838099479675,\n",
       "   0.732471227645874,\n",
       "   -0.7850894331932068,\n",
       "   0.29922065138816833,\n",
       "   0.08097945153713226,\n",
       "   -0.5648396015167236,\n",
       "   -0.19529663026332855,\n",
       "   0.1444421261548996,\n",
       "   0.5468251705169678,\n",
       "   -0.5241607427597046,\n",
       "   -0.09714679419994354,\n",
       "   0.08234255015850067,\n",
       "   -0.0698000118136406,\n",
       "   0.37116625905036926,\n",
       "   -0.2583487033843994,\n",
       "   0.25862613320350647,\n",
       "   0.059789787977933884,\n",
       "   0.017477817833423615,\n",
       "   -0.46212857961654663,\n",
       "   0.059381742030382156,\n",
       "   0.3167532682418823,\n",
       "   0.24864713847637177,\n",
       "   0.20802199840545654,\n",
       "   -0.03632064163684845,\n",
       "   -1.167827844619751,\n",
       "   -4.063626766204834,\n",
       "   -0.15257421135902405,\n",
       "   -0.7040585875511169,\n",
       "   0.3236781358718872,\n",
       "   -0.0366639606654644,\n",
       "   0.27324771881103516,\n",
       "   -0.0002083703875541687,\n",
       "   -0.2294580042362213,\n",
       "   -1.2515026330947876,\n",
       "   -0.41162192821502686,\n",
       "   -0.757739245891571,\n",
       "   0.050546299666166306,\n",
       "   0.9932506084442139,\n",
       "   0.7079377174377441,\n",
       "   0.6782169342041016,\n",
       "   0.6520744562149048,\n",
       "   0.15873843431472778,\n",
       "   -0.23837612569332123,\n",
       "   0.019557684659957886,\n",
       "   0.9026749730110168,\n",
       "   -0.09279617667198181,\n",
       "   -0.42968764901161194,\n",
       "   0.09829779714345932,\n",
       "   0.059482403099536896,\n",
       "   0.6838988661766052,\n",
       "   0.8232332468032837,\n",
       "   -0.3850705623626709,\n",
       "   0.07661966979503632,\n",
       "   -0.036653630435466766,\n",
       "   -0.1402394324541092,\n",
       "   -0.33855941891670227,\n",
       "   -0.22606226801872253,\n",
       "   -0.007509946823120117,\n",
       "   -0.39850500226020813,\n",
       "   0.34197235107421875,\n",
       "   0.2246524542570114,\n",
       "   -0.08712214231491089,\n",
       "   -0.09652864187955856,\n",
       "   0.09031425416469574,\n",
       "   0.49470284581184387,\n",
       "   0.044815730303525925,\n",
       "   -1.1069947481155396,\n",
       "   -0.2904212772846222,\n",
       "   0.6179383397102356,\n",
       "   0.9604947566986084,\n",
       "   0.14016754925251007,\n",
       "   0.17025494575500488,\n",
       "   -0.6204341053962708,\n",
       "   -0.031793344765901566,\n",
       "   0.13601058721542358,\n",
       "   0.4227607846260071,\n",
       "   0.0052680354565382,\n",
       "   0.10681246221065521,\n",
       "   -0.1811237633228302,\n",
       "   0.018167216330766678,\n",
       "   -0.6441609859466553,\n",
       "   0.5980717539787292,\n",
       "   1.200028419494629,\n",
       "   0.04520769789814949,\n",
       "   -0.596829354763031,\n",
       "   -0.12980888783931732,\n",
       "   -0.41132888197898865,\n",
       "   -0.6329442858695984,\n",
       "   -0.04708204045891762,\n",
       "   -0.5168933868408203,\n",
       "   -0.3939777612686157,\n",
       "   -0.3386833071708679,\n",
       "   0.21461552381515503,\n",
       "   0.5986301898956299,\n",
       "   0.3776344358921051,\n",
       "   0.004472212865948677,\n",
       "   0.5689431428909302,\n",
       "   0.2831944227218628,\n",
       "   -0.9524165391921997,\n",
       "   0.1585158407688141,\n",
       "   0.2917940020561218,\n",
       "   -0.19376416504383087,\n",
       "   0.008956514298915863,\n",
       "   0.4555692672729492,\n",
       "   0.33948007225990295,\n",
       "   -0.5787520408630371,\n",
       "   -0.6484442353248596,\n",
       "   0.2003350704908371,\n",
       "   -0.2902458608150482,\n",
       "   0.4821065068244934,\n",
       "   -1.3537664413452148,\n",
       "   -0.19496504962444305,\n",
       "   0.23023197054862976,\n",
       "   -0.08581280708312988,\n",
       "   -0.4928009808063507,\n",
       "   0.42128604650497437,\n",
       "   0.26961785554885864,\n",
       "   0.9019497632980347,\n",
       "   0.21069106459617615,\n",
       "   0.3154827058315277,\n",
       "   0.1285550892353058,\n",
       "   0.31581881642341614,\n",
       "   -0.4043188691139221,\n",
       "   0.6567494869232178,\n",
       "   -0.31313803791999817,\n",
       "   0.15016502141952515,\n",
       "   0.059661008417606354,\n",
       "   0.9087273478507996,\n",
       "   -0.34017568826675415,\n",
       "   0.09361016750335693,\n",
       "   -0.4644893407821655,\n",
       "   -0.6389843225479126,\n",
       "   0.05983921140432358,\n",
       "   -0.29340845346450806,\n",
       "   0.40867000818252563,\n",
       "   -0.22117407619953156,\n",
       "   0.23209211230278015,\n",
       "   0.8546119332313538,\n",
       "   -0.3987692594528198,\n",
       "   0.008439620956778526,\n",
       "   0.03339546546339989,\n",
       "   0.34390783309936523,\n",
       "   0.7284137010574341,\n",
       "   -0.6049227118492126,\n",
       "   -0.11570341885089874,\n",
       "   -0.0421152301132679,\n",
       "   0.7696922421455383,\n",
       "   -0.0626879632472992,\n",
       "   -0.7453229427337646,\n",
       "   -0.5205519199371338,\n",
       "   0.006800994277000427,\n",
       "   -0.2624512016773224,\n",
       "   -0.4174097180366516,\n",
       "   -0.7275769710540771,\n",
       "   -0.01890723593533039,\n",
       "   -0.28147903084754944,\n",
       "   -0.16917239129543304,\n",
       "   0.1583957076072693,\n",
       "   0.4445292353630066,\n",
       "   0.14212805032730103,\n",
       "   -0.13917791843414307,\n",
       "   -0.10778304934501648,\n",
       "   -0.6532717347145081,\n",
       "   0.36663001775741577,\n",
       "   0.46264901757240295,\n",
       "   0.554663896560669,\n",
       "   -0.0018159300088882446,\n",
       "   0.09289475530385971,\n",
       "   -0.011132396757602692,\n",
       "   -0.4901733100414276,\n",
       "   0.863226056098938,\n",
       "   -0.08547799289226532,\n",
       "   -0.19290289282798767,\n",
       "   0.29222092032432556,\n",
       "   0.47121912240982056,\n",
       "   -0.8181086778640747,\n",
       "   -0.07473814487457275,\n",
       "   -0.5368248820304871,\n",
       "   -0.05314754694700241,\n",
       "   0.19846491515636444,\n",
       "   -0.39867985248565674,\n",
       "   0.23037055134773254,\n",
       "   -0.5128791332244873,\n",
       "   0.7169837951660156,\n",
       "   -0.08313411474227905,\n",
       "   -0.40029051899909973,\n",
       "   0.3027084767818451,\n",
       "   0.07814912497997284,\n",
       "   0.340907484292984,\n",
       "   0.28501564264297485,\n",
       "   0.38553133606910706,\n",
       "   -0.024600865319371223,\n",
       "   0.028679490089416504,\n",
       "   0.35258185863494873,\n",
       "   0.15018481016159058,\n",
       "   -0.42845121026039124,\n",
       "   -0.19682776927947998,\n",
       "   0.23999923467636108,\n",
       "   -0.16957421600818634,\n",
       "   -0.5303825736045837,\n",
       "   0.30028223991394043,\n",
       "   0.22521039843559265,\n",
       "   0.3407149314880371,\n",
       "   -0.1843881458044052,\n",
       "   0.43027395009994507,\n",
       "   -0.29114827513694763,\n",
       "   -0.09757408499717712,\n",
       "   -0.17854280769824982,\n",
       "   -0.15950451791286469,\n",
       "   0.6757084131240845,\n",
       "   0.024192556738853455,\n",
       "   -0.15316423773765564,\n",
       "   0.3915725648403168,\n",
       "   0.03862770274281502,\n",
       "   0.14359569549560547,\n",
       "   0.0950433537364006,\n",
       "   -0.10839670896530151,\n",
       "   -0.41671666502952576,\n",
       "   -0.6383025646209717,\n",
       "   -0.3916531801223755,\n",
       "   -0.5089495182037354,\n",
       "   0.8012180924415588,\n",
       "   -0.035114288330078125,\n",
       "   0.026831377297639847,\n",
       "   -0.12137594074010849,\n",
       "   -0.09151166677474976,\n",
       "   -0.22161102294921875,\n",
       "   -0.6097092628479004,\n",
       "   0.1800752431154251,\n",
       "   0.2800799608230591,\n",
       "   -0.45384377241134644,\n",
       "   0.466077595949173,\n",
       "   0.6294800639152527,\n",
       "   -0.48224419355392456,\n",
       "   0.40588992834091187,\n",
       "   -0.8106997609138489,\n",
       "   -0.5145949125289917,\n",
       "   0.33114978671073914,\n",
       "   0.01698491722345352,\n",
       "   0.1503768414258957,\n",
       "   0.09822047501802444,\n",
       "   0.42809489369392395,\n",
       "   0.17344985902309418,\n",
       "   -0.4640246629714966,\n",
       "   0.015403589233756065,\n",
       "   -0.2863389849662781,\n",
       "   0.01612893119454384,\n",
       "   -0.4363994598388672,\n",
       "   -0.2020992487668991,\n",
       "   -0.7981902360916138,\n",
       "   0.00253981351852417,\n",
       "   0.27035266160964966,\n",
       "   -0.13112874329090118,\n",
       "   -0.47803995013237,\n",
       "   -0.3591264486312866,\n",
       "   0.15411680936813354,\n",
       "   -0.6642229557037354,\n",
       "   0.1300189048051834,\n",
       "   -0.12335693836212158,\n",
       "   -0.6462597250938416,\n",
       "   -0.020996369421482086,\n",
       "   -0.11195831000804901,\n",
       "   0.0832127258181572,\n",
       "   0.2301054149866104,\n",
       "   0.1606494039297104,\n",
       "   0.04935825243592262,\n",
       "   -0.33907780051231384,\n",
       "   -0.11391127109527588,\n",
       "   -1.2447278499603271,\n",
       "   -0.22632604837417603,\n",
       "   -0.17602448165416718,\n",
       "   -0.05267762020230293,\n",
       "   0.37947654724121094,\n",
       "   -0.6882948875427246,\n",
       "   0.09268710017204285,\n",
       "   0.34943294525146484,\n",
       "   -0.09563028812408447,\n",
       "   0.08998312056064606,\n",
       "   -0.2689705789089203,\n",
       "   0.3297056555747986,\n",
       "   -0.23129746317863464,\n",
       "   -0.6343390941619873,\n",
       "   0.48066291213035583,\n",
       "   0.0017113462090492249,\n",
       "   -0.8439880013465881,\n",
       "   0.32233911752700806,\n",
       "   -0.28965792059898376,\n",
       "   0.0943550318479538,\n",
       "   -0.02604619413614273,\n",
       "   0.1298978477716446,\n",
       "   0.1316763013601303,\n",
       "   0.6147550940513611,\n",
       "   0.5363351106643677,\n",
       "   0.7081305980682373,\n",
       "   -0.260912150144577,\n",
       "   0.2727918028831482,\n",
       "   -0.04005289077758789,\n",
       "   0.467691034078598,\n",
       "   -0.4370446801185608,\n",
       "   -0.20039933919906616,\n",
       "   -0.07097864151000977,\n",
       "   -0.12218427658081055,\n",
       "   -0.021411316469311714,\n",
       "   0.5280552506446838,\n",
       "   -0.02082831785082817,\n",
       "   -0.19681470096111298,\n",
       "   0.46194517612457275,\n",
       "   0.42242786288261414,\n",
       "   -0.21155408024787903,\n",
       "   0.4367983937263489,\n",
       "   -0.13441945612430573,\n",
       "   0.08380140364170074,\n",
       "   1.0468776226043701,\n",
       "   0.05724906921386719,\n",
       "   -0.18703442811965942,\n",
       "   -0.24260073900222778,\n",
       "   0.3099949359893799,\n",
       "   0.22821855545043945,\n",
       "   0.028680721297860146,\n",
       "   -0.1253138780593872,\n",
       "   -0.04779999330639839,\n",
       "   0.6976090669631958,\n",
       "   -0.21836331486701965,\n",
       "   0.4812692403793335,\n",
       "   0.20872312784194946,\n",
       "   -0.9582600593566895,\n",
       "   0.06255041062831879,\n",
       "   0.24915173649787903,\n",
       "   0.15480723977088928,\n",
       "   0.20367014408111572,\n",
       "   0.2240406572818756,\n",
       "   0.4855641722679138,\n",
       "   -0.4961070120334625,\n",
       "   0.6746115684509277,\n",
       "   -0.16203385591506958,\n",
       "   0.12323607504367828,\n",
       "   -0.1510925441980362,\n",
       "   0.6215982437133789,\n",
       "   0.3636350631713867,\n",
       "   -0.8018443584442139,\n",
       "   -0.49698761105537415,\n",
       "   0.08491789549589157,\n",
       "   -0.20962172746658325,\n",
       "   0.10172100365161896,\n",
       "   -0.08576813340187073,\n",
       "   0.06588447839021683,\n",
       "   -0.48594310879707336,\n",
       "   0.2518608570098877,\n",
       "   0.06886067986488342,\n",
       "   0.3280864357948303,\n",
       "   0.26580262184143066,\n",
       "   -0.08760713785886765,\n",
       "   -0.1932319849729538,\n",
       "   -0.11110815405845642,\n",
       "   0.42104849219322205,\n",
       "   0.06769127398729324,\n",
       "   0.1718774288892746,\n",
       "   -0.3359045088291168,\n",
       "   0.19517381489276886,\n",
       "   -0.1566726714372635,\n",
       "   -0.00392095698043704,\n",
       "   0.8974785208702087,\n",
       "   0.24079260230064392,\n",
       "   -0.06750582903623581,\n",
       "   -0.5387305617332458,\n",
       "   -0.3285084664821625,\n",
       "   0.556753396987915,\n",
       "   0.2965314984321594,\n",
       "   1.208210825920105,\n",
       "   0.3757661283016205,\n",
       "   0.11214461177587509,\n",
       "   -0.10421127825975418,\n",
       "   0.010799147188663483,\n",
       "   0.18251211941242218,\n",
       "   0.300804078578949,\n",
       "   0.5639983415603638,\n",
       "   0.9050698280334473,\n",
       "   0.0618826262652874,\n",
       "   -0.12907572090625763,\n",
       "   0.585767388343811,\n",
       "   -0.054831139743328094,\n",
       "   0.3125167191028595,\n",
       "   0.5317217707633972,\n",
       "   -0.085908442735672,\n",
       "   0.6737107038497925,\n",
       "   0.31957998871803284,\n",
       "   0.30091142654418945,\n",
       "   -0.3239101469516754,\n",
       "   -0.07614539563655853,\n",
       "   -0.12257640063762665,\n",
       "   0.3395945727825165,\n",
       "   0.3654937744140625,\n",
       "   -0.20403917133808136,\n",
       "   0.05873309075832367,\n",
       "   0.2994697093963623,\n",
       "   -0.048412736505270004,\n",
       "   0.059543631970882416,\n",
       "   0.34073948860168457,\n",
       "   -0.431578665971756,\n",
       "   0.16696105897426605,\n",
       "   0.13997873663902283,\n",
       "   -0.3755005896091461,\n",
       "   -0.4275035858154297,\n",
       "   -0.09054300934076309,\n",
       "   0.2718641459941864,\n",
       "   0.23034973442554474,\n",
       "   0.33561572432518005,\n",
       "   -0.7032433748245239,\n",
       "   -0.10617436468601227,\n",
       "   -0.36419105529785156,\n",
       "   -0.7300216555595398,\n",
       "   -0.1938886195421219,\n",
       "   0.48713359236717224,\n",
       "   0.605692982673645,\n",
       "   -0.22442948818206787,\n",
       "   0.029128290712833405,\n",
       "   -0.10595463216304779,\n",
       "   0.1158561035990715,\n",
       "   -0.9291775226593018,\n",
       "   0.3988727927207947,\n",
       "   -0.3188484311103821,\n",
       "   0.056051746010780334,\n",
       "   0.252066045999527,\n",
       "   0.3827603757381439,\n",
       "   -0.15607982873916626,\n",
       "   0.4133147597312927,\n",
       "   0.2389979064464569,\n",
       "   -0.09465835243463516,\n",
       "   -0.23925620317459106,\n",
       "   -0.4764827489852905,\n",
       "   0.5462371706962585,\n",
       "   -0.6986441016197205,\n",
       "   -0.3398149013519287,\n",
       "   -0.4707218408584595,\n",
       "   -0.2837943732738495,\n",
       "   -0.031188461929559708,\n",
       "   0.7159544825553894,\n",
       "   -0.476826012134552,\n",
       "   -0.39096635580062866,\n",
       "   -0.40586015582084656,\n",
       "   -0.10969729721546173,\n",
       "   0.4803248345851898,\n",
       "   -0.16351403295993805,\n",
       "   0.05036928877234459,\n",
       "   0.21976792812347412,\n",
       "   -0.07217888534069061,\n",
       "   -0.2610888183116913,\n",
       "   -0.05526424199342728,\n",
       "   -0.08167946338653564,\n",
       "   -0.03158093988895416,\n",
       "   -0.6774318218231201,\n",
       "   0.22284163534641266,\n",
       "   0.18520860373973846,\n",
       "   -0.4652092456817627,\n",
       "   -0.16866490244865417,\n",
       "   -0.6165668368339539,\n",
       "   -0.04643108695745468,\n",
       "   0.5021039247512817,\n",
       "   -0.259738564491272,\n",
       "   -0.5291770100593567,\n",
       "   -0.14793922007083893,\n",
       "   -0.28673309087753296,\n",
       "   0.18604503571987152,\n",
       "   -0.37798938155174255,\n",
       "   -0.5843672752380371,\n",
       "   0.08874741196632385,\n",
       "   0.2560301423072815,\n",
       "   0.4971715807914734,\n",
       "   -0.5083743929862976,\n",
       "   0.7352003455162048,\n",
       "   -0.008982416242361069,\n",
       "   -0.5575684905052185,\n",
       "   -0.6419664621353149,\n",
       "   0.6920610666275024,\n",
       "   0.04763413220643997,\n",
       "   -0.07604871690273285,\n",
       "   -0.11207077652215958,\n",
       "   0.2457195222377777,\n",
       "   -0.45990994572639465,\n",
       "   0.3722197413444519,\n",
       "   -0.1874600052833557,\n",
       "   0.17760515213012695,\n",
       "   -0.051677312701940536,\n",
       "   0.2916169762611389,\n",
       "   0.031551264226436615],\n",
       "  [0.3012484610080719,\n",
       "   0.6142284274101257,\n",
       "   0.2892266511917114,\n",
       "   0.43884462118148804,\n",
       "   0.24167926609516144,\n",
       "   -0.5282638072967529,\n",
       "   -0.6562861800193787,\n",
       "   0.9579882621765137,\n",
       "   -0.7039215564727783,\n",
       "   0.150966078042984,\n",
       "   0.4500768184661865,\n",
       "   -0.29061630368232727,\n",
       "   -0.3415276110172272,\n",
       "   0.6203674674034119,\n",
       "   -0.054062820971012115,\n",
       "   0.510759711265564,\n",
       "   0.4020000100135803,\n",
       "   0.07847482711076736,\n",
       "   -0.07824729382991791,\n",
       "   0.40695348381996155,\n",
       "   0.07435072958469391,\n",
       "   -0.13979819416999817,\n",
       "   -0.24099023640155792,\n",
       "   0.10900223255157471,\n",
       "   0.03362788259983063,\n",
       "   -0.5254400372505188,\n",
       "   0.28747501969337463,\n",
       "   -0.21368351578712463,\n",
       "   0.0447775200009346,\n",
       "   0.1832151561975479,\n",
       "   0.05676170065999031,\n",
       "   0.0993557870388031,\n",
       "   -0.3895730972290039,\n",
       "   -0.6946349143981934,\n",
       "   0.516364574432373,\n",
       "   0.21162253618240356,\n",
       "   0.413680762052536,\n",
       "   0.2957789897918701,\n",
       "   -0.04384354501962662,\n",
       "   -0.0413723848760128,\n",
       "   -0.5621915459632874,\n",
       "   -0.448173850774765,\n",
       "   0.16768746078014374,\n",
       "   0.05840002000331879,\n",
       "   -0.3120371103286743,\n",
       "   -0.36015236377716064,\n",
       "   0.8657071590423584,\n",
       "   0.27196067571640015,\n",
       "   0.4263131022453308,\n",
       "   -0.11563510447740555,\n",
       "   -0.4995885491371155,\n",
       "   0.13035520911216736,\n",
       "   0.17221064865589142,\n",
       "   -0.26286718249320984,\n",
       "   -0.02677374705672264,\n",
       "   1.0931578874588013,\n",
       "   0.11277692764997482,\n",
       "   -0.6777494549751282,\n",
       "   -0.2944616377353668,\n",
       "   0.21384687721729279,\n",
       "   0.5599306225776672,\n",
       "   -0.18147841095924377,\n",
       "   -0.062151554971933365,\n",
       "   -0.5007856488227844,\n",
       "   -0.035235218703746796,\n",
       "   0.2640811800956726,\n",
       "   0.16553203761577606,\n",
       "   -0.14729253947734833,\n",
       "   -0.2100336104631424,\n",
       "   0.06223464012145996,\n",
       "   -0.5056452751159668,\n",
       "   -0.6398829221725464,\n",
       "   -0.3681424856185913,\n",
       "   0.28552132844924927,\n",
       "   -0.7464624643325806,\n",
       "   -0.022881194949150085,\n",
       "   -0.04617939889431,\n",
       "   0.1709207147359848,\n",
       "   0.2822285294532776,\n",
       "   0.5432115197181702,\n",
       "   0.03137922286987305,\n",
       "   0.7728010416030884,\n",
       "   -0.2520216405391693,\n",
       "   0.3300413489341736,\n",
       "   0.2590304911136627,\n",
       "   -0.1702459454536438,\n",
       "   -0.7840876579284668,\n",
       "   -0.1446308195590973,\n",
       "   0.36276137828826904,\n",
       "   1.11593759059906,\n",
       "   -0.08127513527870178,\n",
       "   0.15864184498786926,\n",
       "   0.10117888450622559,\n",
       "   0.23860673606395721,\n",
       "   -0.19569234549999237,\n",
       "   -0.42305153608322144,\n",
       "   -0.23440520465373993,\n",
       "   0.6472069025039673,\n",
       "   -0.4085462987422943,\n",
       "   0.6692240238189697,\n",
       "   0.20528043806552887,\n",
       "   -1.0157504081726074,\n",
       "   0.26547303795814514,\n",
       "   -0.010790539905428886,\n",
       "   0.654184877872467,\n",
       "   -0.05707258731126785,\n",
       "   0.4365905821323395,\n",
       "   0.024974839761853218,\n",
       "   -0.12929634749889374,\n",
       "   -0.17506913840770721,\n",
       "   -0.32864058017730713,\n",
       "   -0.8537305593490601,\n",
       "   0.5373208522796631,\n",
       "   -0.4961366355419159,\n",
       "   0.10511621087789536,\n",
       "   0.3714168667793274,\n",
       "   0.012855814769864082,\n",
       "   -0.156555637717247,\n",
       "   0.13949012756347656,\n",
       "   -0.21836794912815094,\n",
       "   -0.15840889513492584,\n",
       "   -0.20967578887939453,\n",
       "   -0.048073139041662216,\n",
       "   0.9022949934005737,\n",
       "   0.1534973829984665,\n",
       "   -0.2547385096549988,\n",
       "   -0.06237471476197243,\n",
       "   -0.31971246004104614,\n",
       "   0.16492047905921936,\n",
       "   -0.5585846900939941,\n",
       "   0.7684794068336487,\n",
       "   0.43200522661209106,\n",
       "   0.6199870109558105,\n",
       "   -1.0878170728683472,\n",
       "   0.039584070444107056,\n",
       "   0.34776052832603455,\n",
       "   0.4137133061885834,\n",
       "   -0.4422014355659485,\n",
       "   -0.6372237801551819,\n",
       "   -0.027329692617058754,\n",
       "   0.6140305995941162,\n",
       "   0.5766873359680176,\n",
       "   0.9867008924484253,\n",
       "   0.2539784908294678,\n",
       "   0.4891444742679596,\n",
       "   0.14502833783626556,\n",
       "   -0.2907668650150299,\n",
       "   -0.4541735053062439,\n",
       "   -0.07086053490638733,\n",
       "   -0.034775711596012115,\n",
       "   -0.2774059474468231,\n",
       "   -0.667901337146759,\n",
       "   0.09834660589694977,\n",
       "   -0.24829205870628357,\n",
       "   0.23246431350708008,\n",
       "   -0.5067768692970276,\n",
       "   -0.25572720170021057,\n",
       "   -0.16833758354187012,\n",
       "   0.9031234979629517,\n",
       "   0.23976175487041473,\n",
       "   0.39590781927108765,\n",
       "   -0.16996335983276367,\n",
       "   -0.009675274603068829,\n",
       "   0.4774996340274811,\n",
       "   -0.006817241199314594,\n",
       "   -0.01406000554561615,\n",
       "   -0.05062546208500862,\n",
       "   0.5117493271827698,\n",
       "   0.259187787771225,\n",
       "   0.10544116795063019,\n",
       "   -0.23449401557445526,\n",
       "   0.11372466385364532,\n",
       "   0.7511257529258728,\n",
       "   -0.3698233664035797,\n",
       "   -0.4861990511417389,\n",
       "   -0.03469175472855568,\n",
       "   0.3288455307483673,\n",
       "   0.3169551491737366,\n",
       "   0.39433884620666504,\n",
       "   0.34405726194381714,\n",
       "   -0.44039469957351685,\n",
       "   -0.15730929374694824,\n",
       "   -0.016574157401919365,\n",
       "   -0.10367467999458313,\n",
       "   0.24184279143810272,\n",
       "   -0.39972174167633057,\n",
       "   0.9058843851089478,\n",
       "   -0.01945287548005581,\n",
       "   -0.25070130825042725,\n",
       "   0.25539517402648926,\n",
       "   -0.2761232554912567,\n",
       "   0.3075876235961914,\n",
       "   -0.22040680050849915,\n",
       "   0.023391231894493103,\n",
       "   0.2688698470592499,\n",
       "   -0.519245445728302,\n",
       "   -0.6591772437095642,\n",
       "   -0.5908243060112,\n",
       "   0.31717649102211,\n",
       "   0.2529606223106384,\n",
       "   0.029707947745919228,\n",
       "   0.153290793299675,\n",
       "   0.27616599202156067,\n",
       "   -0.07406286895275116,\n",
       "   -0.5502030849456787,\n",
       "   0.1055678278207779,\n",
       "   -0.1902686059474945,\n",
       "   -0.20118771493434906,\n",
       "   -0.18242308497428894,\n",
       "   -0.3222986161708832,\n",
       "   -0.38730108737945557,\n",
       "   0.8520626425743103,\n",
       "   0.2781537175178528,\n",
       "   0.008955538272857666,\n",
       "   -0.28968745470046997,\n",
       "   -0.059800222516059875,\n",
       "   0.2986066937446594,\n",
       "   -0.2769320011138916,\n",
       "   -0.26493051648139954,\n",
       "   0.1497151255607605,\n",
       "   0.08108901977539062,\n",
       "   0.16333697736263275,\n",
       "   -0.37306883931159973,\n",
       "   0.6808721423149109,\n",
       "   0.3114984631538391,\n",
       "   0.8589571714401245,\n",
       "   0.28272488713264465,\n",
       "   -0.33936020731925964,\n",
       "   -0.12840428948402405,\n",
       "   0.42369240522384644,\n",
       "   0.12759697437286377,\n",
       "   -0.39501824975013733,\n",
       "   0.38736429810523987,\n",
       "   -0.2864214777946472,\n",
       "   -0.4684339761734009,\n",
       "   -0.0936766117811203,\n",
       "   -0.10407860577106476,\n",
       "   0.22784516215324402,\n",
       "   0.29679015278816223,\n",
       "   -0.100035160779953,\n",
       "   -0.6161572933197021,\n",
       "   0.15785779058933258,\n",
       "   0.47290554642677307,\n",
       "   -0.07156103849411011,\n",
       "   0.13251949846744537,\n",
       "   0.08123987913131714,\n",
       "   -0.0055938344448804855,\n",
       "   0.12938469648361206,\n",
       "   -0.5370581150054932,\n",
       "   -0.7009090185165405,\n",
       "   -0.07183828949928284,\n",
       "   -1.0181711912155151,\n",
       "   -0.0893222764134407,\n",
       "   -0.7828116416931152,\n",
       "   -0.47604116797447205,\n",
       "   -0.5332269668579102,\n",
       "   -0.3320785164833069,\n",
       "   0.05459411069750786,\n",
       "   0.0026775323785841465,\n",
       "   0.40948525071144104,\n",
       "   0.31631916761398315,\n",
       "   -0.4658670127391815,\n",
       "   -0.18924885988235474,\n",
       "   0.13452807068824768,\n",
       "   -0.6931135654449463,\n",
       "   -0.7795425653457642,\n",
       "   0.2599000334739685,\n",
       "   0.5242189168930054,\n",
       "   0.32018500566482544,\n",
       "   -0.06881163269281387,\n",
       "   0.1246950626373291,\n",
       "   -0.5700681805610657,\n",
       "   0.23291590809822083,\n",
       "   0.9291576743125916,\n",
       "   0.08639185130596161,\n",
       "   -0.26740068197250366,\n",
       "   -0.20876803994178772,\n",
       "   0.06435989588499069,\n",
       "   -0.1895536184310913,\n",
       "   -0.7018195986747742,\n",
       "   0.46003246307373047,\n",
       "   0.5303493142127991,\n",
       "   -0.23197601735591888,\n",
       "   0.09869521111249924,\n",
       "   0.29416725039482117,\n",
       "   -0.6526493430137634,\n",
       "   0.4590621292591095,\n",
       "   0.08028030395507812,\n",
       "   -0.2642129063606262,\n",
       "   0.15708059072494507,\n",
       "   0.06628695875406265,\n",
       "   0.4859335720539093,\n",
       "   -0.5113754272460938,\n",
       "   -0.5092442035675049,\n",
       "   0.25740668177604675,\n",
       "   -0.2314629703760147,\n",
       "   0.40030285716056824,\n",
       "   -0.25165826082229614,\n",
       "   -0.3735547959804535,\n",
       "   -0.13655884563922882,\n",
       "   -0.21146005392074585,\n",
       "   -0.16349589824676514,\n",
       "   0.18562135100364685,\n",
       "   0.6997151374816895,\n",
       "   0.12651245296001434,\n",
       "   0.2527446150779724,\n",
       "   0.0009186416864395142,\n",
       "   -1.2978049516677856,\n",
       "   -4.08228063583374,\n",
       "   0.015660196542739868,\n",
       "   -0.5124517679214478,\n",
       "   0.04550991952419281,\n",
       "   0.12897825241088867,\n",
       "   0.006304269656538963,\n",
       "   -0.3128429651260376,\n",
       "   -0.5207604169845581,\n",
       "   -1.114439606666565,\n",
       "   -0.053735774010419846,\n",
       "   -0.345202773809433,\n",
       "   -0.2591325640678406,\n",
       "   0.39610111713409424,\n",
       "   0.5299169421195984,\n",
       "   0.5313814282417297,\n",
       "   0.3557620048522949,\n",
       "   0.2021261602640152,\n",
       "   -0.24601297080516815,\n",
       "   -0.33185264468193054,\n",
       "   0.4717121720314026,\n",
       "   -0.37553054094314575,\n",
       "   -0.747288167476654,\n",
       "   0.07608097791671753,\n",
       "   0.030696989968419075,\n",
       "   0.8227475881576538,\n",
       "   0.7344169020652771,\n",
       "   -0.23100633919239044,\n",
       "   0.3749980926513672,\n",
       "   -0.353903591632843,\n",
       "   0.2187601923942566,\n",
       "   -0.09086541831493378,\n",
       "   -0.5151087045669556,\n",
       "   -0.07793910801410675,\n",
       "   -0.07609116286039352,\n",
       "   -0.05410988628864288,\n",
       "   0.12097682058811188,\n",
       "   0.08147946000099182,\n",
       "   -0.06718222796916962,\n",
       "   -0.1620263308286667,\n",
       "   0.2926846444606781,\n",
       "   0.045657988637685776,\n",
       "   -0.9957935214042664,\n",
       "   -0.2747400999069214,\n",
       "   0.2850741446018219,\n",
       "   1.0342990159988403,\n",
       "   -0.41367268562316895,\n",
       "   0.07893835008144379,\n",
       "   -0.537548303604126,\n",
       "   0.11969505250453949,\n",
       "   0.1846076250076294,\n",
       "   0.2274816930294037,\n",
       "   -0.0033067408949136734,\n",
       "   -0.11201702803373337,\n",
       "   -0.5322847962379456,\n",
       "   -0.569871723651886,\n",
       "   -0.6972588300704956,\n",
       "   0.7054128646850586,\n",
       "   0.5219326019287109,\n",
       "   -0.14945237338542938,\n",
       "   -0.6078150868415833,\n",
       "   0.0325964018702507,\n",
       "   -0.39982253313064575,\n",
       "   -1.120249629020691,\n",
       "   -0.21389149129390717,\n",
       "   0.034692831337451935,\n",
       "   -0.7283518314361572,\n",
       "   -0.22069145739078522,\n",
       "   0.03221287950873375,\n",
       "   0.5841429829597473,\n",
       "   0.23210085928440094,\n",
       "   -0.028833694756031036,\n",
       "   0.37934353947639465,\n",
       "   -0.03677809238433838,\n",
       "   -1.051430344581604,\n",
       "   -0.03546511009335518,\n",
       "   0.5251980423927307,\n",
       "   0.1897907704114914,\n",
       "   -0.21598999202251434,\n",
       "   0.4499904215335846,\n",
       "   0.3862748444080353,\n",
       "   -0.7143846750259399,\n",
       "   -0.4228208661079407,\n",
       "   0.2901354730129242,\n",
       "   -0.16592171788215637,\n",
       "   0.33473071455955505,\n",
       "   -1.2235573530197144,\n",
       "   0.1249203085899353,\n",
       "   -0.32356101274490356,\n",
       "   -0.2604837417602539,\n",
       "   -0.5140064358711243,\n",
       "   0.09573618322610855,\n",
       "   0.181968554854393,\n",
       "   0.25770464539527893,\n",
       "   0.18789035081863403,\n",
       "   0.15778566896915436,\n",
       "   0.39479464292526245,\n",
       "   0.2539753317832947,\n",
       "   -0.199151411652565,\n",
       "   0.14989915490150452,\n",
       "   -0.26219722628593445,\n",
       "   0.12662506103515625,\n",
       "   0.07078174501657486,\n",
       "   0.8862401843070984,\n",
       "   -0.15998157858848572,\n",
       "   0.3022332787513733,\n",
       "   -0.3066003918647766,\n",
       "   -0.8445014357566833,\n",
       "   0.28417670726776123,\n",
       "   -0.10745565593242645,\n",
       "   0.35927724838256836,\n",
       "   -0.15789826214313507,\n",
       "   -0.17461121082305908,\n",
       "   0.8698920011520386,\n",
       "   -0.5964500308036804,\n",
       "   0.14330878853797913,\n",
       "   0.28962087631225586,\n",
       "   0.7230536341667175,\n",
       "   0.7663583159446716,\n",
       "   -0.5577402114868164,\n",
       "   0.053300641477108,\n",
       "   -0.030712202191352844,\n",
       "   0.6727603673934937,\n",
       "   -0.16660085320472717,\n",
       "   -0.261587530374527,\n",
       "   -0.3070259988307953,\n",
       "   0.1295422613620758,\n",
       "   -0.28914251923561096,\n",
       "   -0.4809771478176117,\n",
       "   -0.5625823736190796,\n",
       "   0.03524084389209747,\n",
       "   -0.25461384654045105,\n",
       "   -0.05724214017391205,\n",
       "   0.19068410992622375,\n",
       "   0.4596658945083618,\n",
       "   0.4611729085445404,\n",
       "   0.08117982000112534,\n",
       "   0.15363657474517822,\n",
       "   -0.5056493878364563,\n",
       "   0.40700647234916687,\n",
       "   0.37050238251686096,\n",
       "   0.3311355412006378,\n",
       "   0.06915444135665894,\n",
       "   0.12355269491672516,\n",
       "   -0.016459189355373383,\n",
       "   -0.7584171295166016,\n",
       "   0.8521796464920044,\n",
       "   -0.23866590857505798,\n",
       "   -0.05341365560889244,\n",
       "   0.06851769238710403,\n",
       "   0.257705420255661,\n",
       "   -0.7373693585395813,\n",
       "   -0.4314700961112976,\n",
       "   -0.4333480894565582,\n",
       "   -0.06878998875617981,\n",
       "   0.2768774628639221,\n",
       "   -0.19682595133781433,\n",
       "   -0.23521339893341064,\n",
       "   -0.3301166296005249,\n",
       "   0.45611557364463806,\n",
       "   -0.20388799905776978,\n",
       "   -0.50612872838974,\n",
       "   0.04002676159143448,\n",
       "   0.21375887095928192,\n",
       "   0.31357985734939575,\n",
       "   -0.18634270131587982,\n",
       "   -0.049788303673267365,\n",
       "   0.12759096920490265,\n",
       "   -0.17785799503326416,\n",
       "   0.4257466197013855,\n",
       "   -0.06504751741886139,\n",
       "   -0.38092008233070374,\n",
       "   -0.048675671219825745,\n",
       "   0.010608121752738953,\n",
       "   -0.3520110547542572,\n",
       "   -0.34941500425338745,\n",
       "   0.31888893246650696,\n",
       "   0.3235672116279602,\n",
       "   -0.12336844950914383,\n",
       "   -0.22542183101177216,\n",
       "   0.6800335645675659,\n",
       "   -0.1319979876279831,\n",
       "   0.006548833101987839,\n",
       "   0.30946478247642517,\n",
       "   0.17571921646595,\n",
       "   0.6871991753578186,\n",
       "   -0.2827436029911041,\n",
       "   -0.0011407015845179558,\n",
       "   -0.08693847060203552,\n",
       "   0.1284903585910797,\n",
       "   0.38395366072654724,\n",
       "   -0.06739351898431778,\n",
       "   0.11763076484203339,\n",
       "   -0.23676946759223938,\n",
       "   0.016441775485873222,\n",
       "   -0.3419000506401062,\n",
       "   -0.5088292360305786,\n",
       "   0.82160884141922,\n",
       "   -0.26131671667099,\n",
       "   0.02339847758412361,\n",
       "   -0.1817159503698349,\n",
       "   -0.3703576326370239,\n",
       "   -0.2436782270669937,\n",
       "   -0.666722297668457,\n",
       "   0.3446119427680969,\n",
       "   0.14198961853981018,\n",
       "   -0.15998460352420807,\n",
       "   0.13256627321243286,\n",
       "   0.31318187713623047,\n",
       "   -0.18832573294639587,\n",
       "   0.2680772542953491,\n",
       "   -0.6539038419723511,\n",
       "   -0.5699600577354431,\n",
       "   -0.3451805114746094,\n",
       "   -0.16998256742954254,\n",
       "   0.33232131600379944,\n",
       "   0.08067428320646286,\n",
       "   -0.0376250185072422,\n",
       "   0.13921944797039032,\n",
       "   -0.4240766763687134,\n",
       "   0.08202102780342102,\n",
       "   -0.6762623190879822,\n",
       "   0.017166122794151306,\n",
       "   -0.3324400782585144,\n",
       "   0.03994610533118248,\n",
       "   -0.48252955079078674,\n",
       "   -0.29169660806655884,\n",
       "   0.30447715520858765,\n",
       "   -0.05713436380028725,\n",
       "   -0.3549961745738983,\n",
       "   -0.2732445299625397,\n",
       "   0.15013942122459412,\n",
       "   -1.204211950302124,\n",
       "   0.33663123846054077,\n",
       "   -0.13777579367160797,\n",
       "   -0.47389575839042664,\n",
       "   0.023897945880889893,\n",
       "   -0.13221681118011475,\n",
       "   0.15704786777496338,\n",
       "   -0.02259809896349907,\n",
       "   0.0778321698307991,\n",
       "   0.0038883499801158905,\n",
       "   -0.44129613041877747,\n",
       "   0.06490421295166016,\n",
       "   -0.9982977509498596,\n",
       "   -0.3212212920188904,\n",
       "   -0.43442395329475403,\n",
       "   -0.34690138697624207,\n",
       "   0.829736053943634,\n",
       "   -0.6206561326980591,\n",
       "   0.22319090366363525,\n",
       "   0.34174948930740356,\n",
       "   -0.3077942132949829,\n",
       "   -0.15221388638019562,\n",
       "   -0.4883559048175812,\n",
       "   0.013284686952829361,\n",
       "   -0.20269745588302612,\n",
       "   -0.6792335510253906,\n",
       "   0.10940199345350266,\n",
       "   0.032769039273262024,\n",
       "   -0.8078984022140503,\n",
       "   0.2678818702697754,\n",
       "   -0.12501083314418793,\n",
       "   0.1519511342048645,\n",
       "   0.30835872888565063,\n",
       "   0.20644836127758026,\n",
       "   -0.07244105637073517,\n",
       "   0.052455827593803406,\n",
       "   0.06319208443164825,\n",
       "   0.6853457093238831,\n",
       "   -0.4086240231990814,\n",
       "   -0.04148987680673599,\n",
       "   0.00046218186616897583,\n",
       "   0.5262557864189148,\n",
       "   0.04322647303342819,\n",
       "   -0.2982703745365143,\n",
       "   0.07289597392082214,\n",
       "   0.2321583330631256,\n",
       "   -0.2013750970363617,\n",
       "   0.25198134779930115,\n",
       "   -0.27766627073287964,\n",
       "   -0.4477388858795166,\n",
       "   0.0008940678089857101,\n",
       "   0.17381882667541504,\n",
       "   0.03235623985528946,\n",
       "   -0.31729617714881897,\n",
       "   -0.09255464375019073,\n",
       "   0.10904207825660706,\n",
       "   0.8460724949836731,\n",
       "   0.11425445973873138,\n",
       "   -0.4089011251926422,\n",
       "   -0.31728002429008484,\n",
       "   0.8171079158782959,\n",
       "   0.6751699447631836,\n",
       "   0.14045946300029755,\n",
       "   0.37662819027900696,\n",
       "   0.10667623579502106,\n",
       "   1.0310312509536743,\n",
       "   0.08253583312034607,\n",
       "   0.5713662505149841,\n",
       "   -0.027846157550811768,\n",
       "   -0.8677539229393005,\n",
       "   -0.05598736181855202,\n",
       "   0.13619965314865112,\n",
       "   0.20724543929100037,\n",
       "   0.441190242767334,\n",
       "   0.5845298171043396,\n",
       "   0.545648992061615,\n",
       "   -0.2762911021709442,\n",
       "   0.31176498532295227,\n",
       "   0.38684922456741333,\n",
       "   0.4348619878292084,\n",
       "   -0.16569559276103973,\n",
       "   0.7046719193458557,\n",
       "   0.25058308243751526,\n",
       "   -0.7687785625457764,\n",
       "   -0.4278968274593353,\n",
       "   0.09786039590835571,\n",
       "   -0.6591994166374207,\n",
       "   0.02406729757785797,\n",
       "   0.11699758470058441,\n",
       "   0.24942618608474731,\n",
       "   -0.3761017322540283,\n",
       "   0.5603894591331482,\n",
       "   -0.007348762825131416,\n",
       "   0.4326169788837433,\n",
       "   0.6189433336257935,\n",
       "   -0.32912614941596985,\n",
       "   -0.12343958020210266,\n",
       "   -0.07815270125865936,\n",
       "   0.2546822130680084,\n",
       "   -0.2670329511165619,\n",
       "   0.2621169090270996,\n",
       "   -0.45307689905166626,\n",
       "   0.21490147709846497,\n",
       "   -0.35665568709373474,\n",
       "   -0.041543055325746536,\n",
       "   0.2884823977947235,\n",
       "   0.23220111429691315,\n",
       "   0.07418835908174515,\n",
       "   -0.35388845205307007,\n",
       "   -0.3687456250190735,\n",
       "   0.054073769599199295,\n",
       "   0.5483567118644714,\n",
       "   1.0942944288253784,\n",
       "   0.43269214034080505,\n",
       "   0.26558709144592285,\n",
       "   0.27211877703666687,\n",
       "   -0.18303468823432922,\n",
       "   0.23790496587753296,\n",
       "   0.5128011703491211,\n",
       "   0.4817548096179962,\n",
       "   0.6619019508361816,\n",
       "   -0.05900588631629944,\n",
       "   0.10104791074991226,\n",
       "   0.7453970909118652,\n",
       "   0.42825794219970703,\n",
       "   0.5799124240875244,\n",
       "   0.490508496761322,\n",
       "   -0.25376245379447937,\n",
       "   0.46371516585350037,\n",
       "   0.43652379512786865,\n",
       "   0.46173128485679626,\n",
       "   -0.20876580476760864,\n",
       "   -0.04917939752340317,\n",
       "   -0.4318625330924988,\n",
       "   0.43269461393356323,\n",
       "   0.1925593763589859,\n",
       "   -0.5356353521347046,\n",
       "   0.07060420513153076,\n",
       "   -0.053738243877887726,\n",
       "   0.23732876777648926,\n",
       "   -0.08601848036050797,\n",
       "   0.13260024785995483,\n",
       "   -0.4730086326599121,\n",
       "   -0.07302087545394897,\n",
       "   -0.020794296637177467,\n",
       "   -0.11646069586277008,\n",
       "   -0.6114739179611206,\n",
       "   -0.5014922618865967,\n",
       "   0.24609307944774628,\n",
       "   0.3274097442626953,\n",
       "   0.23994797468185425,\n",
       "   -0.49016043543815613,\n",
       "   -0.27850520610809326,\n",
       "   -0.12667188048362732,\n",
       "   -0.6419777274131775,\n",
       "   0.3507334589958191,\n",
       "   0.5376037359237671,\n",
       "   0.5396363139152527,\n",
       "   -0.09037557244300842,\n",
       "   0.2615460157394409,\n",
       "   -0.3295978009700775,\n",
       "   -0.22011983394622803,\n",
       "   -0.8408414721488953,\n",
       "   0.1884097009897232,\n",
       "   -0.4913857877254486,\n",
       "   0.06776869297027588,\n",
       "   0.11366568505764008,\n",
       "   0.5488318800926208,\n",
       "   -0.1085762232542038,\n",
       "   0.20779891312122345,\n",
       "   -0.013254297897219658,\n",
       "   -0.2828737497329712,\n",
       "   0.30156585574150085,\n",
       "   -0.6409001350402832,\n",
       "   0.4627644419670105,\n",
       "   -0.6305186748504639,\n",
       "   -0.42233508825302124,\n",
       "   -0.233681321144104,\n",
       "   -0.46547752618789673,\n",
       "   0.4351797103881836,\n",
       "   0.7193992137908936,\n",
       "   -0.45711398124694824,\n",
       "   -0.08518503606319427,\n",
       "   -0.5770199298858643,\n",
       "   -0.42419058084487915,\n",
       "   0.5654142498970032,\n",
       "   -0.08948780596256256,\n",
       "   -0.26928186416625977,\n",
       "   0.708621621131897,\n",
       "   0.15785282850265503,\n",
       "   -0.5864728689193726,\n",
       "   -0.251326322555542,\n",
       "   0.35585054755210876,\n",
       "   0.3338765799999237,\n",
       "   -0.7187834978103638,\n",
       "   0.03780238330364227,\n",
       "   0.33937859535217285,\n",
       "   -0.12367551028728485,\n",
       "   -0.4121396243572235,\n",
       "   -0.05676950514316559,\n",
       "   0.01297091506421566,\n",
       "   0.2012377232313156,\n",
       "   -0.24504341185092926,\n",
       "   -0.45535847544670105,\n",
       "   -0.39374464750289917,\n",
       "   -0.3019559681415558,\n",
       "   -0.07434416562318802,\n",
       "   -0.401420533657074,\n",
       "   -0.7350883483886719,\n",
       "   0.06346353888511658,\n",
       "   0.5233606696128845,\n",
       "   0.05179464444518089,\n",
       "   0.10694368183612823,\n",
       "   0.7230949997901917,\n",
       "   -0.23364800214767456,\n",
       "   -0.4610220789909363,\n",
       "   -0.673103928565979,\n",
       "   0.47191470861434937,\n",
       "   -0.10124721378087997,\n",
       "   -0.18559494614601135,\n",
       "   0.3563861548900604,\n",
       "   0.13323408365249634,\n",
       "   -0.6187852621078491,\n",
       "   -0.04267578572034836,\n",
       "   0.15937651693820953,\n",
       "   -0.3185492157936096,\n",
       "   -0.03752003610134125,\n",
       "   0.4483322203159332,\n",
       "   -0.12102657556533813],\n",
       "  [0.10822261869907379,\n",
       "   0.36769479513168335,\n",
       "   0.38162994384765625,\n",
       "   0.3400748074054718,\n",
       "   0.5704489350318909,\n",
       "   -0.4571008086204529,\n",
       "   0.03417113050818443,\n",
       "   0.5260568261146545,\n",
       "   -0.7456548810005188,\n",
       "   -0.01796361804008484,\n",
       "   0.427207887172699,\n",
       "   -0.40563008189201355,\n",
       "   -0.1030997708439827,\n",
       "   0.6342586278915405,\n",
       "   0.07721160352230072,\n",
       "   0.5243241190910339,\n",
       "   0.28384262323379517,\n",
       "   0.04031137377023697,\n",
       "   -0.05752643570303917,\n",
       "   0.29385411739349365,\n",
       "   -0.12390720844268799,\n",
       "   0.18559059500694275,\n",
       "   -0.14192497730255127,\n",
       "   0.36783286929130554,\n",
       "   0.24335360527038574,\n",
       "   -0.4593339264392853,\n",
       "   -0.19825336337089539,\n",
       "   -0.07123152911663055,\n",
       "   -0.23402023315429688,\n",
       "   -0.15226005017757416,\n",
       "   -0.07864614576101303,\n",
       "   0.134632870554924,\n",
       "   0.0432705283164978,\n",
       "   0.22614240646362305,\n",
       "   -0.4439508318901062,\n",
       "   0.055330973118543625,\n",
       "   -0.14400550723075867,\n",
       "   0.2103707194328308,\n",
       "   -0.3634001612663269,\n",
       "   0.06441424041986465,\n",
       "   -0.09937065839767456,\n",
       "   -0.004648037254810333,\n",
       "   0.11375996470451355,\n",
       "   0.24362903833389282,\n",
       "   -0.28362876176834106,\n",
       "   -0.12921851873397827,\n",
       "   0.09834440052509308,\n",
       "   0.03072645142674446,\n",
       "   0.24796052277088165,\n",
       "   -0.5636886954307556,\n",
       "   -0.3482986092567444,\n",
       "   0.46660658717155457,\n",
       "   0.21878130733966827,\n",
       "   -0.016652319580316544,\n",
       "   -0.2693568766117096,\n",
       "   0.679929792881012,\n",
       "   0.1720731556415558,\n",
       "   -0.6308464407920837,\n",
       "   -0.11675603687763214,\n",
       "   -0.20827822387218475,\n",
       "   0.40802067518234253,\n",
       "   -0.03630425035953522,\n",
       "   0.0246766097843647,\n",
       "   -0.330252081155777,\n",
       "   0.10576169937849045,\n",
       "   0.09050920605659485,\n",
       "   -0.19534257054328918,\n",
       "   0.0298555139452219,\n",
       "   0.5229143500328064,\n",
       "   -0.11842159181833267,\n",
       "   0.17299140989780426,\n",
       "   0.1834103763103485,\n",
       "   -0.38562145829200745,\n",
       "   0.05491878464818001,\n",
       "   -0.28734228014945984,\n",
       "   0.0952288955450058,\n",
       "   0.272081583738327,\n",
       "   0.318780779838562,\n",
       "   -0.06423908472061157,\n",
       "   0.2857151925563812,\n",
       "   0.060438528656959534,\n",
       "   0.560704231262207,\n",
       "   -0.5499852299690247,\n",
       "   0.2915562093257904,\n",
       "   0.08296185731887817,\n",
       "   0.24283698201179504,\n",
       "   -0.3836303651332855,\n",
       "   0.015342596918344498,\n",
       "   0.14195236563682556,\n",
       "   0.08860822767019272,\n",
       "   0.21623077988624573,\n",
       "   0.000818304717540741,\n",
       "   0.11519589275121689,\n",
       "   0.2836981415748596,\n",
       "   -0.03425000235438347,\n",
       "   -0.1360081136226654,\n",
       "   -0.4549778401851654,\n",
       "   0.21700629591941833,\n",
       "   -0.16012689471244812,\n",
       "   0.27836236357688904,\n",
       "   -0.024188833311200142,\n",
       "   -0.4138885736465454,\n",
       "   0.06192823499441147,\n",
       "   0.28992146253585815,\n",
       "   0.2645993232727051,\n",
       "   0.16529029607772827,\n",
       "   0.03853600099682808,\n",
       "   0.023380156606435776,\n",
       "   -0.2140749841928482,\n",
       "   0.007341229356825352,\n",
       "   0.0045751407742500305,\n",
       "   -0.15461188554763794,\n",
       "   0.11036548763513565,\n",
       "   -0.20156382024288177,\n",
       "   0.04107647389173508,\n",
       "   -0.009712142869830132,\n",
       "   0.4735860228538513,\n",
       "   -0.458676815032959,\n",
       "   0.15246345102787018,\n",
       "   0.012728114612400532,\n",
       "   -0.0963730737566948,\n",
       "   -0.07474899291992188,\n",
       "   -0.1776498407125473,\n",
       "   0.5206038951873779,\n",
       "   -0.06656193733215332,\n",
       "   -0.4632609188556671,\n",
       "   0.02803172916173935,\n",
       "   -0.1380137801170349,\n",
       "   0.3017391562461853,\n",
       "   -0.10053903609514236,\n",
       "   0.5050787329673767,\n",
       "   0.22435685992240906,\n",
       "   0.51861172914505,\n",
       "   -0.3097281754016876,\n",
       "   0.01801731064915657,\n",
       "   -0.15376560389995575,\n",
       "   0.09670348465442657,\n",
       "   -0.3108420968055725,\n",
       "   -0.45744234323501587,\n",
       "   0.09056398272514343,\n",
       "   0.16261981427669525,\n",
       "   -0.034348562359809875,\n",
       "   0.6132699847221375,\n",
       "   0.09096314013004303,\n",
       "   -0.03572515398263931,\n",
       "   0.023070581257343292,\n",
       "   -0.47685185074806213,\n",
       "   -0.09716277569532394,\n",
       "   -0.10400830209255219,\n",
       "   -0.18318399786949158,\n",
       "   -0.025562796741724014,\n",
       "   0.1638445109128952,\n",
       "   -0.23778000473976135,\n",
       "   -0.3063428997993469,\n",
       "   -0.20351022481918335,\n",
       "   -0.3245328366756439,\n",
       "   -0.463780015707016,\n",
       "   -0.30681294202804565,\n",
       "   0.15687638521194458,\n",
       "   -0.10071109235286713,\n",
       "   0.5144075155258179,\n",
       "   -0.22166375815868378,\n",
       "   -0.09136045724153519,\n",
       "   -0.06125814840197563,\n",
       "   0.22916601598262787,\n",
       "   -0.18008671700954437,\n",
       "   0.13838350772857666,\n",
       "   0.6051840782165527,\n",
       "   -0.06746619939804077,\n",
       "   0.032203834503889084,\n",
       "   -0.20059917867183685,\n",
       "   0.4379826784133911,\n",
       "   0.704304575920105,\n",
       "   -0.3112505376338959,\n",
       "   -0.6768108010292053,\n",
       "   0.018541384488344193,\n",
       "   0.27697116136550903,\n",
       "   -0.07346441596746445,\n",
       "   0.21456773579120636,\n",
       "   0.29193252325057983,\n",
       "   -0.10822144150733948,\n",
       "   -0.12276990711688995,\n",
       "   0.04966622218489647,\n",
       "   0.026075277477502823,\n",
       "   -0.036447975784540176,\n",
       "   -0.016916867345571518,\n",
       "   -0.0313975065946579,\n",
       "   0.31253674626350403,\n",
       "   -0.15725892782211304,\n",
       "   -0.1663549393415451,\n",
       "   -0.07994989305734634,\n",
       "   0.27246037125587463,\n",
       "   -0.18533995747566223,\n",
       "   -0.2959446310997009,\n",
       "   0.17980509996414185,\n",
       "   0.10880205035209656,\n",
       "   3.5393983125686646e-05,\n",
       "   -0.34923991560935974,\n",
       "   -0.06875889748334885,\n",
       "   -0.20644298195838928,\n",
       "   0.03253064304590225,\n",
       "   0.18436971306800842,\n",
       "   -0.026761066168546677,\n",
       "   0.2096518576145172,\n",
       "   -0.07805898785591125,\n",
       "   -0.08826059103012085,\n",
       "   0.03236762434244156,\n",
       "   -0.21549373865127563,\n",
       "   -0.17408014833927155,\n",
       "   0.23429729044437408,\n",
       "   -0.6592987775802612,\n",
       "   0.3130744993686676,\n",
       "   -0.05990687012672424,\n",
       "   0.27860334515571594,\n",
       "   -0.33554330468177795,\n",
       "   0.2124692052602768,\n",
       "   -0.13003847002983093,\n",
       "   -0.010731961578130722,\n",
       "   -0.5098029375076294,\n",
       "   0.14042288064956665,\n",
       "   0.03282427042722702,\n",
       "   -0.26454803347587585,\n",
       "   -0.26036351919174194,\n",
       "   0.48338472843170166,\n",
       "   -0.10146989673376083,\n",
       "   0.3358154892921448,\n",
       "   0.36412057280540466,\n",
       "   -0.22543203830718994,\n",
       "   0.12821541726589203,\n",
       "   0.027400003746151924,\n",
       "   -0.1313631534576416,\n",
       "   -0.2381742149591446,\n",
       "   0.44871294498443604,\n",
       "   -0.6035412549972534,\n",
       "   0.09367360919713974,\n",
       "   0.2574818730354309,\n",
       "   -0.3029656708240509,\n",
       "   -0.07069987803697586,\n",
       "   0.14971306920051575,\n",
       "   0.1954089254140854,\n",
       "   -0.4034140408039093,\n",
       "   -0.1661970317363739,\n",
       "   0.03644143044948578,\n",
       "   0.32292842864990234,\n",
       "   0.2501239776611328,\n",
       "   0.08713676035404205,\n",
       "   -0.2207641899585724,\n",
       "   0.19001349806785583,\n",
       "   -0.11417219787836075,\n",
       "   -0.11865121126174927,\n",
       "   -0.5672252774238586,\n",
       "   -0.2760753631591797,\n",
       "   -0.19313424825668335,\n",
       "   -0.27757176756858826,\n",
       "   0.04528321325778961,\n",
       "   -0.007949844002723694,\n",
       "   0.03278447315096855,\n",
       "   0.11659248173236847,\n",
       "   0.023929571732878685,\n",
       "   0.39912521839141846,\n",
       "   -0.003788735717535019,\n",
       "   -0.28136444091796875,\n",
       "   0.1074235662817955,\n",
       "   -0.1644955277442932,\n",
       "   -0.14209547638893127,\n",
       "   -0.5805293321609497,\n",
       "   0.21090306341648102,\n",
       "   -0.14604534208774567,\n",
       "   0.3881276249885559,\n",
       "   0.01663137599825859,\n",
       "   0.24998021125793457,\n",
       "   0.16688796877861023,\n",
       "   0.1597602367401123,\n",
       "   0.9217046499252319,\n",
       "   -0.7140799164772034,\n",
       "   0.059318944811820984,\n",
       "   -0.0306786447763443,\n",
       "   -0.4125523567199707,\n",
       "   0.24929532408714294,\n",
       "   -0.5024687051773071,\n",
       "   0.20171238481998444,\n",
       "   0.3479137420654297,\n",
       "   -0.34476298093795776,\n",
       "   0.2314404845237732,\n",
       "   0.1547463834285736,\n",
       "   -0.4927256405353546,\n",
       "   0.4981340169906616,\n",
       "   -0.2661266326904297,\n",
       "   -0.11123059689998627,\n",
       "   -0.1443282663822174,\n",
       "   0.12024427950382233,\n",
       "   0.30743709206581116,\n",
       "   -0.28352630138397217,\n",
       "   -0.33169054985046387,\n",
       "   0.44810113310813904,\n",
       "   0.10339604318141937,\n",
       "   0.28269103169441223,\n",
       "   -0.13596104085445404,\n",
       "   -0.05534398555755615,\n",
       "   -0.2845519781112671,\n",
       "   -0.3916667699813843,\n",
       "   -0.17148831486701965,\n",
       "   0.26808151602745056,\n",
       "   0.34332937002182007,\n",
       "   -0.019154280424118042,\n",
       "   0.3160592317581177,\n",
       "   -0.3137548863887787,\n",
       "   -0.5745528936386108,\n",
       "   -4.902274131774902,\n",
       "   0.0824836790561676,\n",
       "   -0.4283354878425598,\n",
       "   0.15698480606079102,\n",
       "   -0.07820679247379303,\n",
       "   0.2739611566066742,\n",
       "   -0.13939602673053741,\n",
       "   -0.05882090702652931,\n",
       "   -0.5840915441513062,\n",
       "   -0.23349525034427643,\n",
       "   -0.28873491287231445,\n",
       "   0.1734345406293869,\n",
       "   0.29345420002937317,\n",
       "   0.44514068961143494,\n",
       "   0.17129340767860413,\n",
       "   -0.03797867149114609,\n",
       "   0.22915346920490265,\n",
       "   0.24998292326927185,\n",
       "   -0.12382012605667114,\n",
       "   0.19570648670196533,\n",
       "   -0.16602379083633423,\n",
       "   -0.36482328176498413,\n",
       "   0.06632470339536667,\n",
       "   0.07169043272733688,\n",
       "   0.2973101735115051,\n",
       "   0.3104071319103241,\n",
       "   -0.3005383610725403,\n",
       "   0.2688882052898407,\n",
       "   0.06664226204156876,\n",
       "   0.04629744589328766,\n",
       "   0.30505844950675964,\n",
       "   -0.4589972198009491,\n",
       "   -0.24757587909698486,\n",
       "   0.11013665795326233,\n",
       "   -0.054183557629585266,\n",
       "   0.32467174530029297,\n",
       "   -0.12413281202316284,\n",
       "   0.06770924478769302,\n",
       "   0.04135055094957352,\n",
       "   -0.18834388256072998,\n",
       "   0.006434628739953041,\n",
       "   -0.645560085773468,\n",
       "   -0.23374643921852112,\n",
       "   0.08414986729621887,\n",
       "   0.4378035068511963,\n",
       "   -0.4861951470375061,\n",
       "   0.13185089826583862,\n",
       "   -0.3390163779258728,\n",
       "   -0.0060187773779034615,\n",
       "   -0.2727659046649933,\n",
       "   0.09820836782455444,\n",
       "   0.03534547984600067,\n",
       "   0.11200636625289917,\n",
       "   -0.1897619366645813,\n",
       "   -0.4876624047756195,\n",
       "   -0.3684316575527191,\n",
       "   0.636368989944458,\n",
       "   0.4490084648132324,\n",
       "   -0.16372910141944885,\n",
       "   -0.3674187660217285,\n",
       "   0.035944774746894836,\n",
       "   -0.2505636513233185,\n",
       "   -0.6977381110191345,\n",
       "   -0.02685486525297165,\n",
       "   -0.2117559164762497,\n",
       "   -0.14390814304351807,\n",
       "   -0.12633243203163147,\n",
       "   -0.4329012334346771,\n",
       "   0.23887279629707336,\n",
       "   0.38982799649238586,\n",
       "   -0.07404658943414688,\n",
       "   0.2477637529373169,\n",
       "   0.004297688603401184,\n",
       "   -0.8729058504104614,\n",
       "   -0.12931232154369354,\n",
       "   0.1968085914850235,\n",
       "   0.226338729262352,\n",
       "   -0.0748152881860733,\n",
       "   0.3168743848800659,\n",
       "   -0.2987268269062042,\n",
       "   -0.6090585589408875,\n",
       "   -0.629599392414093,\n",
       "   -0.10357089340686798,\n",
       "   -0.08715679496526718,\n",
       "   -0.32199764251708984,\n",
       "   -0.6552782654762268,\n",
       "   -0.13226760923862457,\n",
       "   0.16882599890232086,\n",
       "   -0.5492245554924011,\n",
       "   -0.21060603857040405,\n",
       "   0.14713597297668457,\n",
       "   0.16110508143901825,\n",
       "   0.05486492067575455,\n",
       "   0.0760471522808075,\n",
       "   0.13690146803855896,\n",
       "   0.4479856789112091,\n",
       "   -0.17797011137008667,\n",
       "   0.09284725040197372,\n",
       "   0.34229350090026855,\n",
       "   -0.24245977401733398,\n",
       "   0.4981710910797119,\n",
       "   -0.04480074346065521,\n",
       "   0.64485102891922,\n",
       "   0.18091078102588654,\n",
       "   -0.4165593385696411,\n",
       "   -0.07283014059066772,\n",
       "   -0.2943672239780426,\n",
       "   -0.11754709482192993,\n",
       "   0.37621596455574036,\n",
       "   0.19994701445102692,\n",
       "   -0.30259817838668823,\n",
       "   0.35307595133781433,\n",
       "   0.4917569160461426,\n",
       "   -0.2355160415172577,\n",
       "   0.06649568676948547,\n",
       "   -0.10444657504558563,\n",
       "   -0.03901650011539459,\n",
       "   0.6015670299530029,\n",
       "   -0.024339709430933,\n",
       "   0.09592346101999283,\n",
       "   -0.031756628304719925,\n",
       "   0.3743683397769928,\n",
       "   -0.36840304732322693,\n",
       "   -0.274025559425354,\n",
       "   0.38718879222869873,\n",
       "   -0.36526647210121155,\n",
       "   -0.08850977569818497,\n",
       "   -0.32417410612106323,\n",
       "   0.24163725972175598,\n",
       "   0.09551025182008743,\n",
       "   0.07505692541599274,\n",
       "   -0.1895434558391571,\n",
       "   0.262630820274353,\n",
       "   0.33015963435173035,\n",
       "   0.21755211055278778,\n",
       "   -0.10570643842220306,\n",
       "   -0.14295528829097748,\n",
       "   -0.05399104580283165,\n",
       "   0.24101752042770386,\n",
       "   0.15393713116645813,\n",
       "   0.2957460284233093,\n",
       "   0.2364557981491089,\n",
       "   0.47153034806251526,\n",
       "   0.21032491326332092,\n",
       "   -0.23450958728790283,\n",
       "   0.26076582074165344,\n",
       "   0.19964438676834106,\n",
       "   0.07254005968570709,\n",
       "   -0.49846112728118896,\n",
       "   0.5257843136787415,\n",
       "   -0.4841076731681824,\n",
       "   -0.38571497797966003,\n",
       "   -0.06763676553964615,\n",
       "   -0.0670606940984726,\n",
       "   0.1367977112531662,\n",
       "   0.11691343784332275,\n",
       "   0.42982736229896545,\n",
       "   -0.5058113932609558,\n",
       "   0.24948136508464813,\n",
       "   0.003612350206822157,\n",
       "   -0.13270165026187897,\n",
       "   -0.09381826221942902,\n",
       "   0.7849200367927551,\n",
       "   0.23443250358104706,\n",
       "   -0.2154473066329956,\n",
       "   0.4654352366924286,\n",
       "   -0.07669074833393097,\n",
       "   0.06106313690543175,\n",
       "   -0.06096716225147247,\n",
       "   -0.15361207723617554,\n",
       "   -0.3170415759086609,\n",
       "   -0.07273322343826294,\n",
       "   0.24033188819885254,\n",
       "   -0.15698949992656708,\n",
       "   -0.3661912977695465,\n",
       "   0.32849347591400146,\n",
       "   0.06749972701072693,\n",
       "   -0.042151063680648804,\n",
       "   -0.26145339012145996,\n",
       "   0.5205950140953064,\n",
       "   -0.3196125328540802,\n",
       "   -0.20043545961380005,\n",
       "   -0.36327704787254333,\n",
       "   -0.090202197432518,\n",
       "   0.31405511498451233,\n",
       "   0.050629355013370514,\n",
       "   -0.013222087174654007,\n",
       "   -0.018835056573152542,\n",
       "   0.2673697769641876,\n",
       "   0.16435450315475464,\n",
       "   -0.32287609577178955,\n",
       "   0.3099028170108795,\n",
       "   -0.12043887376785278,\n",
       "   -0.19789175689220428,\n",
       "   -0.1857774257659912,\n",
       "   -0.19579941034317017,\n",
       "   0.7786409258842468,\n",
       "   0.12586356699466705,\n",
       "   -0.20645825564861298,\n",
       "   -0.04393320530653,\n",
       "   -0.17150186002254486,\n",
       "   -0.31621235609054565,\n",
       "   -0.007795052602887154,\n",
       "   0.15164165198802948,\n",
       "   -0.21186713874340057,\n",
       "   -0.17596353590488434,\n",
       "   -0.0263565294444561,\n",
       "   -0.04642356559634209,\n",
       "   -0.03693618252873421,\n",
       "   -0.12951192259788513,\n",
       "   0.06166552007198334,\n",
       "   -0.32966047525405884,\n",
       "   -0.24359367787837982,\n",
       "   -0.09149900078773499,\n",
       "   0.2935093641281128,\n",
       "   0.43653061985969543,\n",
       "   -0.24055077135562897,\n",
       "   0.0003984980285167694,\n",
       "   -0.19648121297359467,\n",
       "   0.24873152375221252,\n",
       "   -0.00857781246304512,\n",
       "   0.2735486328601837,\n",
       "   0.12407245486974716,\n",
       "   0.1364455670118332,\n",
       "   -0.09462259709835052,\n",
       "   -0.07354050874710083,\n",
       "   0.1880079060792923,\n",
       "   0.3303833603858948,\n",
       "   -0.23664626479148865,\n",
       "   0.4484025835990906,\n",
       "   -0.012894129380583763,\n",
       "   -0.5966552495956421,\n",
       "   0.01726789027452469,\n",
       "   -0.245609849691391,\n",
       "   -0.07268968224525452,\n",
       "   0.22175262868404388,\n",
       "   -0.3994845151901245,\n",
       "   -0.02951918914914131,\n",
       "   0.11739708483219147,\n",
       "   -0.051432862877845764,\n",
       "   -0.39621785283088684,\n",
       "   -0.5279015302658081,\n",
       "   -0.20527279376983643,\n",
       "   -0.40771299600601196,\n",
       "   0.04850495234131813,\n",
       "   -0.1542232483625412,\n",
       "   -0.0791604071855545,\n",
       "   0.4232412576675415,\n",
       "   -0.6880722045898438,\n",
       "   -0.17030024528503418,\n",
       "   0.49837374687194824,\n",
       "   -0.2173781394958496,\n",
       "   0.07314278185367584,\n",
       "   -0.26641547679901123,\n",
       "   0.13145193457603455,\n",
       "   -0.01985977590084076,\n",
       "   -0.5973698496818542,\n",
       "   0.2347576916217804,\n",
       "   -0.20553719997406006,\n",
       "   -0.31357768177986145,\n",
       "   0.08702345192432404,\n",
       "   -0.12737880647182465,\n",
       "   -0.29105889797210693,\n",
       "   0.1809411644935608,\n",
       "   0.15251773595809937,\n",
       "   -0.3394639790058136,\n",
       "   -0.003283753991127014,\n",
       "   0.5157599449157715,\n",
       "   0.19125019013881683,\n",
       "   0.06692138314247131,\n",
       "   0.1100844144821167,\n",
       "   0.17479301989078522,\n",
       "   0.3349161744117737,\n",
       "   0.15356385707855225,\n",
       "   -0.36623814702033997,\n",
       "   0.21169671416282654,\n",
       "   -0.14894506335258484,\n",
       "   -0.23649005591869354,\n",
       "   -0.04670247808098793,\n",
       "   -0.34256711602211,\n",
       "   -0.2896735966205597,\n",
       "   0.3510361909866333,\n",
       "   0.04815278202295303,\n",
       "   0.138082355260849,\n",
       "   -0.18022842705249786,\n",
       "   -0.012823669239878654,\n",
       "   -0.08734382688999176,\n",
       "   0.31999436020851135,\n",
       "   0.10950617492198944,\n",
       "   0.09656526148319244,\n",
       "   -0.17859554290771484,\n",
       "   0.3028116822242737,\n",
       "   -0.06589384377002716,\n",
       "   0.3287278711795807,\n",
       "   0.029763616621494293,\n",
       "   0.38231223821640015,\n",
       "   0.48967042565345764,\n",
       "   -0.0066963667050004005,\n",
       "   0.5508279800415039,\n",
       "   -0.019866876304149628,\n",
       "   -0.5544083714485168,\n",
       "   0.22245725989341736,\n",
       "   0.31847915053367615,\n",
       "   0.027952849864959717,\n",
       "   0.21078038215637207,\n",
       "   0.4167430102825165,\n",
       "   0.2316621094942093,\n",
       "   0.13024353981018066,\n",
       "   0.02755562588572502,\n",
       "   -0.5487793684005737,\n",
       "   -0.06179219111800194,\n",
       "   -0.08499482274055481,\n",
       "   0.18165847659111023,\n",
       "   0.3299444913864136,\n",
       "   -0.47719648480415344,\n",
       "   -0.4794147312641144,\n",
       "   0.28491246700286865,\n",
       "   -0.44078585505485535,\n",
       "   -0.039493802934885025,\n",
       "   0.4485768675804138,\n",
       "   0.10741352289915085,\n",
       "   -0.06003975495696068,\n",
       "   0.14748108386993408,\n",
       "   -0.052592672407627106,\n",
       "   -0.2656720280647278,\n",
       "   0.06411092728376389,\n",
       "   0.016364924609661102,\n",
       "   0.019227975979447365,\n",
       "   0.29812511801719666,\n",
       "   -0.05549316853284836,\n",
       "   -0.09370975941419601,\n",
       "   0.185184508562088,\n",
       "   -0.3041013181209564,\n",
       "   0.13422894477844238,\n",
       "   -0.5603768229484558,\n",
       "   -0.2926832139492035,\n",
       "   0.6108521819114685,\n",
       "   -0.1299152672290802,\n",
       "   0.05710940808057785,\n",
       "   -0.09735129773616791,\n",
       "   0.023582950234413147,\n",
       "   0.15639695525169373,\n",
       "   -0.5189739465713501,\n",
       "   0.3709911108016968,\n",
       "   -0.2635822594165802,\n",
       "   0.1473374366760254,\n",
       "   0.036945316940546036,\n",
       "   0.0660046711564064,\n",
       "   -0.0922027975320816,\n",
       "   -0.030535265803337097,\n",
       "   0.05420878157019615,\n",
       "   0.28903713822364807,\n",
       "   -0.2456217259168625,\n",
       "   0.011694621294736862,\n",
       "   -0.12265567481517792,\n",
       "   -0.13808919489383698,\n",
       "   0.3996002972126007,\n",
       "   0.4274960160255432,\n",
       "   0.059275072067976,\n",
       "   0.362598180770874,\n",
       "   0.2518388032913208,\n",
       "   0.4034212827682495,\n",
       "   -0.0209816824644804,\n",
       "   -0.19527427852153778,\n",
       "   0.22695380449295044,\n",
       "   0.13719499111175537,\n",
       "   0.21626827120780945,\n",
       "   -0.2537022531032562,\n",
       "   0.42121633887290955,\n",
       "   -0.09850165992975235,\n",
       "   -0.036934126168489456,\n",
       "   -0.2626531720161438,\n",
       "   -0.1619178056716919,\n",
       "   -0.5226810574531555,\n",
       "   0.08216378837823868,\n",
       "   0.026925144717097282,\n",
       "   -0.2699986696243286,\n",
       "   -0.04497833177447319,\n",
       "   -0.2875884473323822,\n",
       "   -0.02241811528801918,\n",
       "   0.5280250906944275,\n",
       "   0.10628775507211685,\n",
       "   -0.5160394906997681,\n",
       "   -0.44975191354751587,\n",
       "   -0.021543828770518303,\n",
       "   -0.1546163260936737,\n",
       "   0.31386417150497437,\n",
       "   0.5342569947242737,\n",
       "   0.32295697927474976,\n",
       "   -0.15244151651859283,\n",
       "   0.07609187066555023,\n",
       "   -0.04176501929759979,\n",
       "   -0.061461351811885834,\n",
       "   -0.4112294912338257,\n",
       "   0.0788060873746872,\n",
       "   0.007215492427349091,\n",
       "   0.14492449164390564,\n",
       "   -0.19401204586029053,\n",
       "   0.6963881254196167,\n",
       "   0.18923692405223846,\n",
       "   -0.31507930159568787,\n",
       "   -0.18650294840335846,\n",
       "   -0.1306152641773224,\n",
       "   0.27322688698768616,\n",
       "   -0.020993433892726898,\n",
       "   0.17670470476150513,\n",
       "   -0.2226787507534027,\n",
       "   0.06062886118888855,\n",
       "   -0.47666582465171814,\n",
       "   -0.28199848532676697,\n",
       "   -0.2412661910057068,\n",
       "   0.4553089141845703,\n",
       "   -0.23010438680648804,\n",
       "   0.005359271541237831,\n",
       "   0.057072948664426804,\n",
       "   -0.40734145045280457,\n",
       "   0.006304804235696793,\n",
       "   0.04140602797269821,\n",
       "   0.36259111762046814,\n",
       "   0.07070418447256088,\n",
       "   -0.11390968412160873,\n",
       "   -0.4336759150028229,\n",
       "   -0.11289763450622559,\n",
       "   0.36681994795799255,\n",
       "   0.00650598481297493,\n",
       "   0.12353523820638657,\n",
       "   0.029634989798069,\n",
       "   0.2175639569759369,\n",
       "   -0.03619761019945145,\n",
       "   -0.08388087898492813,\n",
       "   -0.3525962829589844,\n",
       "   0.24439841508865356,\n",
       "   -0.2236074060201645,\n",
       "   -0.03555474430322647,\n",
       "   0.14415046572685242,\n",
       "   -0.3436913788318634,\n",
       "   -0.6241346597671509,\n",
       "   0.23759452998638153,\n",
       "   0.012330221012234688,\n",
       "   -0.38931071758270264,\n",
       "   0.05434441566467285,\n",
       "   0.046847425401210785,\n",
       "   0.7573748230934143,\n",
       "   -0.1386905461549759,\n",
       "   0.36423540115356445,\n",
       "   0.1372440904378891,\n",
       "   0.11880876123905182,\n",
       "   0.01665446348488331,\n",
       "   -0.2656038999557495,\n",
       "   -0.2050953507423401,\n",
       "   -0.16625083982944489,\n",
       "   0.3460484445095062,\n",
       "   -0.04535964876413345,\n",
       "   -0.454027384519577,\n",
       "   0.07509388029575348,\n",
       "   -0.34082266688346863,\n",
       "   0.3441620171070099,\n",
       "   -0.12939110398292542,\n",
       "   0.2737342417240143,\n",
       "   0.1326223760843277],\n",
       "  [0.1854715347290039,\n",
       "   -0.030213842168450356,\n",
       "   0.01718926802277565,\n",
       "   0.21096043288707733,\n",
       "   1.0941613912582397,\n",
       "   -0.16310426592826843,\n",
       "   0.1862516701221466,\n",
       "   0.42453959584236145,\n",
       "   -0.4336850643157959,\n",
       "   0.011902183294296265,\n",
       "   0.22860375046730042,\n",
       "   -0.29938581585884094,\n",
       "   -0.18280406296253204,\n",
       "   0.44110536575317383,\n",
       "   -0.436968058347702,\n",
       "   0.37837937474250793,\n",
       "   0.18918348848819733,\n",
       "   0.04656768590211868,\n",
       "   0.2760730981826782,\n",
       "   0.41116052865982056,\n",
       "   -0.14233794808387756,\n",
       "   0.10094340890645981,\n",
       "   -0.14185987412929535,\n",
       "   0.2120632529258728,\n",
       "   0.1061936765909195,\n",
       "   -0.1699664145708084,\n",
       "   -0.3303048610687256,\n",
       "   -0.0451807901263237,\n",
       "   -0.5196564197540283,\n",
       "   -0.37221333384513855,\n",
       "   0.0737491250038147,\n",
       "   0.3649682104587555,\n",
       "   -0.2869064211845398,\n",
       "   0.09835314005613327,\n",
       "   0.005728144198656082,\n",
       "   -0.02631448023021221,\n",
       "   -0.3828909695148468,\n",
       "   0.24947959184646606,\n",
       "   -0.25933679938316345,\n",
       "   0.04711441695690155,\n",
       "   -0.3308441936969757,\n",
       "   -0.4463798403739929,\n",
       "   -0.18818853795528412,\n",
       "   0.25865596532821655,\n",
       "   -0.2193131148815155,\n",
       "   0.10735605657100677,\n",
       "   -0.21276211738586426,\n",
       "   0.3415931165218353,\n",
       "   0.013765648007392883,\n",
       "   0.08393686264753342,\n",
       "   -0.6415160894393921,\n",
       "   0.10235743224620819,\n",
       "   -0.46268609166145325,\n",
       "   -0.14176586270332336,\n",
       "   -0.2684381306171417,\n",
       "   0.716585636138916,\n",
       "   0.24942584335803986,\n",
       "   -0.40824422240257263,\n",
       "   -0.051987893879413605,\n",
       "   -0.1498674750328064,\n",
       "   0.6489888429641724,\n",
       "   -0.0958356261253357,\n",
       "   -0.0906851589679718,\n",
       "   -0.10358215868473053,\n",
       "   0.3207568824291229,\n",
       "   0.20563572645187378,\n",
       "   -0.035918258130550385,\n",
       "   0.17378036677837372,\n",
       "   -0.11627955734729767,\n",
       "   0.23118412494659424,\n",
       "   -0.20588377118110657,\n",
       "   0.20668925344944,\n",
       "   -0.4072365164756775,\n",
       "   -0.03257055953145027,\n",
       "   -0.26573270559310913,\n",
       "   0.1763196736574173,\n",
       "   0.24571514129638672,\n",
       "   0.44558292627334595,\n",
       "   0.16252219676971436,\n",
       "   0.20905038714408875,\n",
       "   -0.32378339767456055,\n",
       "   0.3568243384361267,\n",
       "   -0.5358205437660217,\n",
       "   0.4139646887779236,\n",
       "   0.14899785816669464,\n",
       "   -0.06034208834171295,\n",
       "   -0.4549323618412018,\n",
       "   -0.29571664333343506,\n",
       "   -0.3510957658290863,\n",
       "   0.6003930568695068,\n",
       "   -0.06494498252868652,\n",
       "   -0.023341946303844452,\n",
       "   0.4349992871284485,\n",
       "   0.2656653821468353,\n",
       "   0.14022181928157806,\n",
       "   -0.28997382521629333,\n",
       "   -0.1465628743171692,\n",
       "   0.14467142522335052,\n",
       "   -0.10724020004272461,\n",
       "   0.2953869700431824,\n",
       "   0.06652092933654785,\n",
       "   -0.9483302235603333,\n",
       "   -0.10358952730894089,\n",
       "   0.48816826939582825,\n",
       "   0.07271123677492142,\n",
       "   -0.02025340497493744,\n",
       "   -0.3613433241844177,\n",
       "   -0.10106997191905975,\n",
       "   -0.10498781502246857,\n",
       "   0.26450252532958984,\n",
       "   -0.39083564281463623,\n",
       "   0.08309871703386307,\n",
       "   -0.024732276797294617,\n",
       "   -0.40089619159698486,\n",
       "   -0.3782711625099182,\n",
       "   -0.051980651915073395,\n",
       "   0.19962328672409058,\n",
       "   0.13839267194271088,\n",
       "   -0.13639283180236816,\n",
       "   -0.012006251141428947,\n",
       "   0.01433572731912136,\n",
       "   0.17896102368831635,\n",
       "   0.06909345090389252,\n",
       "   0.6790556311607361,\n",
       "   0.18292716145515442,\n",
       "   0.12414239346981049,\n",
       "   0.3233753740787506,\n",
       "   -0.017171936109662056,\n",
       "   0.33339545130729675,\n",
       "   -0.23884299397468567,\n",
       "   0.06040787696838379,\n",
       "   0.3373170793056488,\n",
       "   0.4527466297149658,\n",
       "   -0.33362630009651184,\n",
       "   0.17323650419712067,\n",
       "   -0.1116507351398468,\n",
       "   -0.04412760213017464,\n",
       "   0.15581375360488892,\n",
       "   -0.5556073784828186,\n",
       "   0.2027149200439453,\n",
       "   0.49846336245536804,\n",
       "   0.15964017808437347,\n",
       "   0.6741584539413452,\n",
       "   0.35878700017929077,\n",
       "   -0.07625696808099747,\n",
       "   0.09391053020954132,\n",
       "   -0.3535347282886505,\n",
       "   -0.2924122214317322,\n",
       "   -0.32975995540618896,\n",
       "   0.16715635359287262,\n",
       "   0.023147176951169968,\n",
       "   0.2643219530582428,\n",
       "   0.07832270860671997,\n",
       "   -0.27007752656936646,\n",
       "   0.024799294769763947,\n",
       "   0.08476061373949051,\n",
       "   -0.43341535329818726,\n",
       "   0.16603679955005646,\n",
       "   0.09247022122144699,\n",
       "   -0.18488837778568268,\n",
       "   0.7276542782783508,\n",
       "   0.191648468375206,\n",
       "   0.10591135174036026,\n",
       "   0.13360470533370972,\n",
       "   0.15319882333278656,\n",
       "   -0.2754635810852051,\n",
       "   0.6463804244995117,\n",
       "   0.4808783531188965,\n",
       "   -0.0570770725607872,\n",
       "   0.2888893187046051,\n",
       "   0.03382333368062973,\n",
       "   0.43225136399269104,\n",
       "   0.5777460932731628,\n",
       "   0.12473667412996292,\n",
       "   0.33701276779174805,\n",
       "   0.015143129974603653,\n",
       "   0.22203581035137177,\n",
       "   0.13261060416698456,\n",
       "   0.16781821846961975,\n",
       "   0.21963554620742798,\n",
       "   0.07142171263694763,\n",
       "   -0.16588260233402252,\n",
       "   0.41106802225112915,\n",
       "   -0.22488811612129211,\n",
       "   0.018160827457904816,\n",
       "   -0.20399129390716553,\n",
       "   0.9719831347465515,\n",
       "   -0.1687963306903839,\n",
       "   -0.05324908345937729,\n",
       "   -0.03354167938232422,\n",
       "   -0.3300023376941681,\n",
       "   -0.26457732915878296,\n",
       "   -0.11747601628303528,\n",
       "   -0.21505075693130493,\n",
       "   0.014281373471021652,\n",
       "   -0.5892946124076843,\n",
       "   0.2980576157569885,\n",
       "   -0.15986770391464233,\n",
       "   -0.3077128827571869,\n",
       "   -0.21441999077796936,\n",
       "   0.21656586229801178,\n",
       "   0.2956973612308502,\n",
       "   0.14750978350639343,\n",
       "   -0.02567208558320999,\n",
       "   -0.4720781147480011,\n",
       "   -0.06798602640628815,\n",
       "   0.1769384890794754,\n",
       "   -0.30052661895751953,\n",
       "   -0.33272600173950195,\n",
       "   -0.311338871717453,\n",
       "   -0.2408187985420227,\n",
       "   0.3073902428150177,\n",
       "   -0.0362236388027668,\n",
       "   0.0653357058763504,\n",
       "   -0.4911254942417145,\n",
       "   0.03296155110001564,\n",
       "   -0.11239330470561981,\n",
       "   -0.4215506315231323,\n",
       "   -0.013496765866875648,\n",
       "   0.36759012937545776,\n",
       "   0.11421607434749603,\n",
       "   0.09667426347732544,\n",
       "   -0.057021304965019226,\n",
       "   0.45117029547691345,\n",
       "   0.16222929954528809,\n",
       "   0.8312503099441528,\n",
       "   0.5669649243354797,\n",
       "   -0.24977846443653107,\n",
       "   -0.03936944901943207,\n",
       "   0.3446462154388428,\n",
       "   -0.14860980212688446,\n",
       "   -0.33623287081718445,\n",
       "   0.462563693523407,\n",
       "   -0.32054057717323303,\n",
       "   0.08437845855951309,\n",
       "   -0.09831103682518005,\n",
       "   0.0036186985671520233,\n",
       "   -0.17516052722930908,\n",
       "   0.26909589767456055,\n",
       "   0.01910894364118576,\n",
       "   -0.09980203211307526,\n",
       "   -0.22338107228279114,\n",
       "   0.6372348666191101,\n",
       "   0.18823854625225067,\n",
       "   0.17156927287578583,\n",
       "   -0.08880455791950226,\n",
       "   0.11175379157066345,\n",
       "   -0.21695372462272644,\n",
       "   -0.1766628473997116,\n",
       "   -0.2775542438030243,\n",
       "   -0.08924174308776855,\n",
       "   -0.09742686152458191,\n",
       "   -0.03229818493127823,\n",
       "   -0.3188377320766449,\n",
       "   -0.0717475563287735,\n",
       "   -0.32853084802627563,\n",
       "   -0.02926228567957878,\n",
       "   0.10979051887989044,\n",
       "   -0.1704159677028656,\n",
       "   0.42147037386894226,\n",
       "   0.6986713409423828,\n",
       "   -0.07298783957958221,\n",
       "   -0.1510075330734253,\n",
       "   -0.34920546412467957,\n",
       "   -0.19090181589126587,\n",
       "   -1.0275189876556396,\n",
       "   -0.030109643936157227,\n",
       "   -0.2009630799293518,\n",
       "   0.440792053937912,\n",
       "   0.21507008373737335,\n",
       "   0.07724819332361221,\n",
       "   -0.38511762022972107,\n",
       "   0.4258378744125366,\n",
       "   0.5425785779953003,\n",
       "   -0.7403644323348999,\n",
       "   -0.8130043148994446,\n",
       "   0.1395920217037201,\n",
       "   -0.08971825242042542,\n",
       "   0.17074871063232422,\n",
       "   0.03623199462890625,\n",
       "   0.38908013701438904,\n",
       "   0.45379847288131714,\n",
       "   -0.48315978050231934,\n",
       "   -0.0030075013637542725,\n",
       "   -0.21761944890022278,\n",
       "   -0.4953555166721344,\n",
       "   0.3210221827030182,\n",
       "   1.093946099281311,\n",
       "   -0.20844018459320068,\n",
       "   -0.2492562085390091,\n",
       "   0.05083780363202095,\n",
       "   0.4184217154979706,\n",
       "   -0.5524792075157166,\n",
       "   -0.5285785794258118,\n",
       "   0.3948495388031006,\n",
       "   0.14849576354026794,\n",
       "   0.13819874823093414,\n",
       "   -0.07856658101081848,\n",
       "   -0.4671749770641327,\n",
       "   0.3385101556777954,\n",
       "   -0.18456055223941803,\n",
       "   0.29384344816207886,\n",
       "   0.15427692234516144,\n",
       "   0.1441444456577301,\n",
       "   -0.43742382526397705,\n",
       "   0.05412252992391586,\n",
       "   -0.29406675696372986,\n",
       "   -0.4926418960094452,\n",
       "   -4.805070877075195,\n",
       "   0.15626834332942963,\n",
       "   -0.2967164218425751,\n",
       "   -0.2669163644313812,\n",
       "   -0.1667896956205368,\n",
       "   -0.187437504529953,\n",
       "   0.18161022663116455,\n",
       "   0.06457588076591492,\n",
       "   -0.3012036979198456,\n",
       "   -0.6144147515296936,\n",
       "   -0.3308400511741638,\n",
       "   -0.03728902339935303,\n",
       "   -0.12027403712272644,\n",
       "   0.31280359625816345,\n",
       "   0.4104815423488617,\n",
       "   0.039465226233005524,\n",
       "   0.3613135814666748,\n",
       "   0.050478655844926834,\n",
       "   -0.09764650464057922,\n",
       "   0.6126904487609863,\n",
       "   -0.2701006829738617,\n",
       "   -0.44742441177368164,\n",
       "   0.08659513294696808,\n",
       "   0.08826786279678345,\n",
       "   0.33280134201049805,\n",
       "   -0.11688714474439621,\n",
       "   -0.29603540897369385,\n",
       "   0.19296662509441376,\n",
       "   -0.3578483760356903,\n",
       "   0.04506988078355789,\n",
       "   -0.47054460644721985,\n",
       "   -0.4649275243282318,\n",
       "   -0.26298636198043823,\n",
       "   0.4121796190738678,\n",
       "   -0.3271074593067169,\n",
       "   -0.154931902885437,\n",
       "   -0.2295030653476715,\n",
       "   -0.08181233704090118,\n",
       "   0.0279406551271677,\n",
       "   -0.017025919631123543,\n",
       "   -0.3422183394432068,\n",
       "   -0.25747907161712646,\n",
       "   -0.09086034446954727,\n",
       "   0.013703322038054466,\n",
       "   0.6796700358390808,\n",
       "   -0.059421271085739136,\n",
       "   -0.02899027243256569,\n",
       "   0.08491656929254532,\n",
       "   -0.04106678068637848,\n",
       "   -0.03878378868103027,\n",
       "   0.14018626511096954,\n",
       "   0.046575360000133514,\n",
       "   -0.16137588024139404,\n",
       "   -0.28562143445014954,\n",
       "   -0.43734869360923767,\n",
       "   -0.19672055542469025,\n",
       "   0.7078647613525391,\n",
       "   0.29378801584243774,\n",
       "   -0.3070327043533325,\n",
       "   -0.11596160382032394,\n",
       "   0.34896746277809143,\n",
       "   -0.3741598427295685,\n",
       "   -0.023477789014577866,\n",
       "   -0.3200122117996216,\n",
       "   0.10872397571802139,\n",
       "   -0.17910341918468475,\n",
       "   -0.5708670616149902,\n",
       "   -0.31778794527053833,\n",
       "   0.24735835194587708,\n",
       "   0.20792478322982788,\n",
       "   0.0554528534412384,\n",
       "   -0.07479920983314514,\n",
       "   -0.4758109152317047,\n",
       "   -1.2884289026260376,\n",
       "   -0.16596642136573792,\n",
       "   -0.09078626334667206,\n",
       "   0.436994731426239,\n",
       "   0.16866201162338257,\n",
       "   0.1351267397403717,\n",
       "   0.10679304599761963,\n",
       "   -0.1364487111568451,\n",
       "   -0.5551813244819641,\n",
       "   0.2614066004753113,\n",
       "   0.10361051559448242,\n",
       "   -0.2657979726791382,\n",
       "   -0.5063919425010681,\n",
       "   -0.43082910776138306,\n",
       "   0.33818966150283813,\n",
       "   -0.5126027464866638,\n",
       "   -0.5406520962715149,\n",
       "   -0.0010405667126178741,\n",
       "   -0.279178261756897,\n",
       "   0.47391194105148315,\n",
       "   0.10185940563678741,\n",
       "   0.692015528678894,\n",
       "   0.1862947940826416,\n",
       "   0.34185153245925903,\n",
       "   -0.292687326669693,\n",
       "   0.16034242510795593,\n",
       "   -0.36140871047973633,\n",
       "   -0.03397054970264435,\n",
       "   -0.49865487217903137,\n",
       "   0.4301382303237915,\n",
       "   -0.17993706464767456,\n",
       "   -0.5052857398986816,\n",
       "   0.19759492576122284,\n",
       "   -0.2253524512052536,\n",
       "   0.23531459271907806,\n",
       "   0.12845373153686523,\n",
       "   -0.18992173671722412,\n",
       "   0.32124003767967224,\n",
       "   -0.09447738528251648,\n",
       "   0.42828425765037537,\n",
       "   -0.4802395701408386,\n",
       "   -0.10867306590080261,\n",
       "   -0.08794808387756348,\n",
       "   0.06256300956010818,\n",
       "   0.5808246731758118,\n",
       "   -0.2609095871448517,\n",
       "   0.03430414944887161,\n",
       "   -0.06471199542284012,\n",
       "   0.4359656572341919,\n",
       "   -0.07080262899398804,\n",
       "   -0.1450054794549942,\n",
       "   -0.20450004935264587,\n",
       "   -0.0944909155368805,\n",
       "   -0.09746275842189789,\n",
       "   0.10899663716554642,\n",
       "   0.07580213248729706,\n",
       "   -0.23074853420257568,\n",
       "   0.08053991198539734,\n",
       "   -0.07231532782316208,\n",
       "   0.26432228088378906,\n",
       "   0.09419310092926025,\n",
       "   0.42626091837882996,\n",
       "   -0.0282948836684227,\n",
       "   0.32913124561309814,\n",
       "   -0.16988904774188995,\n",
       "   0.04597354680299759,\n",
       "   -0.1833050549030304,\n",
       "   0.0004238225519657135,\n",
       "   0.3058640956878662,\n",
       "   0.22492405772209167,\n",
       "   0.3241872787475586,\n",
       "   -0.49852994084358215,\n",
       "   0.3463146984577179,\n",
       "   -0.3364512324333191,\n",
       "   0.3431471884250641,\n",
       "   -0.15896108746528625,\n",
       "   0.2230847030878067,\n",
       "   -0.10527671128511429,\n",
       "   -0.4761413335800171,\n",
       "   0.07903850823640823,\n",
       "   0.21998995542526245,\n",
       "   0.31811779737472534,\n",
       "   0.13901616632938385,\n",
       "   0.43776220083236694,\n",
       "   -0.18638986349105835,\n",
       "   0.07113035768270493,\n",
       "   -0.7481593489646912,\n",
       "   -0.2932979464530945,\n",
       "   -0.08847267925739288,\n",
       "   0.28310877084732056,\n",
       "   0.24056188762187958,\n",
       "   -0.4117238521575928,\n",
       "   0.619560956954956,\n",
       "   0.057449642568826675,\n",
       "   -0.0551033578813076,\n",
       "   0.2005307376384735,\n",
       "   -0.01583421230316162,\n",
       "   -0.12366048991680145,\n",
       "   0.008163310587406158,\n",
       "   0.11773734539747238,\n",
       "   -0.11434931308031082,\n",
       "   -0.4259810149669647,\n",
       "   0.39083224534988403,\n",
       "   0.05301360785961151,\n",
       "   -0.19014619290828705,\n",
       "   -0.3934590816497803,\n",
       "   0.7932888269424438,\n",
       "   -0.08406797796487808,\n",
       "   0.13874462246894836,\n",
       "   -0.10215310752391815,\n",
       "   -0.02757927216589451,\n",
       "   0.0077013131231069565,\n",
       "   0.5442817211151123,\n",
       "   0.21347858011722565,\n",
       "   -0.15043579041957855,\n",
       "   0.06315431743860245,\n",
       "   0.35987111926078796,\n",
       "   -0.4209660589694977,\n",
       "   0.5354312658309937,\n",
       "   -0.3111207187175751,\n",
       "   -0.17428472638130188,\n",
       "   0.004626695066690445,\n",
       "   -0.22976431250572205,\n",
       "   0.629069447517395,\n",
       "   0.2001052349805832,\n",
       "   0.17052359879016876,\n",
       "   -0.35692277550697327,\n",
       "   -0.05176156759262085,\n",
       "   -0.500673770904541,\n",
       "   -0.25300776958465576,\n",
       "   0.16677527129650116,\n",
       "   -0.028579488396644592,\n",
       "   -0.24608147144317627,\n",
       "   0.3378899097442627,\n",
       "   0.3314582407474518,\n",
       "   -0.12751352787017822,\n",
       "   -0.10143040865659714,\n",
       "   -0.26109859347343445,\n",
       "   -0.48103010654449463,\n",
       "   -0.5316787958145142,\n",
       "   -0.2895643711090088,\n",
       "   0.2115171253681183,\n",
       "   0.1327805519104004,\n",
       "   -0.10004483163356781,\n",
       "   -0.4168369770050049,\n",
       "   -0.3485647737979889,\n",
       "   0.2995588779449463,\n",
       "   -0.0885487049818039,\n",
       "   0.37480396032333374,\n",
       "   0.13843917846679688,\n",
       "   -0.007490333169698715,\n",
       "   -0.1772393435239792,\n",
       "   -0.31355994939804077,\n",
       "   0.2770880162715912,\n",
       "   0.17562651634216309,\n",
       "   -0.5364570617675781,\n",
       "   0.06519639492034912,\n",
       "   0.023270664736628532,\n",
       "   -0.41955289244651794,\n",
       "   -0.09632247686386108,\n",
       "   -0.15570607781410217,\n",
       "   -0.03249156102538109,\n",
       "   0.17188139259815216,\n",
       "   -0.13608965277671814,\n",
       "   -0.08326438069343567,\n",
       "   -0.03220368176698685,\n",
       "   0.07511638849973679,\n",
       "   -0.29112693667411804,\n",
       "   -0.24471718072891235,\n",
       "   -0.14797194302082062,\n",
       "   -0.22551003098487854,\n",
       "   0.4264829456806183,\n",
       "   -0.07731381058692932,\n",
       "   -0.14000198245048523,\n",
       "   0.7847711443901062,\n",
       "   -0.2699253559112549,\n",
       "   -0.23924241960048676,\n",
       "   -0.19611988961696625,\n",
       "   -0.09858016669750214,\n",
       "   -0.2807585597038269,\n",
       "   0.06480099260807037,\n",
       "   0.07502645254135132,\n",
       "   -0.5937479734420776,\n",
       "   0.05919812619686127,\n",
       "   0.052642762660980225,\n",
       "   -0.21722224354743958,\n",
       "   0.07547108083963394,\n",
       "   0.3939996659755707,\n",
       "   -0.37888482213020325,\n",
       "   -0.040619857609272,\n",
       "   0.41872546076774597,\n",
       "   0.2642628848552704,\n",
       "   0.012268519029021263,\n",
       "   -0.27201420068740845,\n",
       "   0.25011441111564636,\n",
       "   0.35984155535697937,\n",
       "   -0.1817466765642166,\n",
       "   0.399888277053833,\n",
       "   -0.3024153411388397,\n",
       "   0.11734306812286377,\n",
       "   0.40928134322166443,\n",
       "   -0.5310896635055542,\n",
       "   -0.11611099541187286,\n",
       "   0.11132260411977768,\n",
       "   -0.12125962972640991,\n",
       "   0.3337530195713043,\n",
       "   -0.24808360636234283,\n",
       "   -0.43425530195236206,\n",
       "   0.3848363757133484,\n",
       "   0.058985598385334015,\n",
       "   -0.2278343141078949,\n",
       "   -0.4159053862094879,\n",
       "   0.22210989892482758,\n",
       "   -0.11247292160987854,\n",
       "   0.2708274722099304,\n",
       "   -0.028448505327105522,\n",
       "   -0.07203953713178635,\n",
       "   0.22572888433933258,\n",
       "   0.23643167316913605,\n",
       "   -0.18657411634922028,\n",
       "   -0.24611440300941467,\n",
       "   0.29751840233802795,\n",
       "   0.34290778636932373,\n",
       "   0.6108711957931519,\n",
       "   0.04013212025165558,\n",
       "   0.6172116994857788,\n",
       "   0.148927241563797,\n",
       "   0.052014730870723724,\n",
       "   0.2441139966249466,\n",
       "   0.27355068922042847,\n",
       "   -0.1487242579460144,\n",
       "   0.1056133508682251,\n",
       "   0.13794676959514618,\n",
       "   0.1361810714006424,\n",
       "   0.04676060378551483,\n",
       "   -0.11159893870353699,\n",
       "   0.15887919068336487,\n",
       "   -0.24366025626659393,\n",
       "   -0.07002238929271698,\n",
       "   0.4646970331668854,\n",
       "   0.27700042724609375,\n",
       "   -0.7438842058181763,\n",
       "   -0.047906629741191864,\n",
       "   0.36887407302856445,\n",
       "   -0.32863226532936096,\n",
       "   0.01796889305114746,\n",
       "   0.20033913850784302,\n",
       "   -0.2243255227804184,\n",
       "   0.036056868731975555,\n",
       "   0.12432520091533661,\n",
       "   -0.1351078450679779,\n",
       "   -0.22304698824882507,\n",
       "   0.14674149453639984,\n",
       "   0.23904019594192505,\n",
       "   0.004615152254700661,\n",
       "   -0.24849702417850494,\n",
       "   0.1627870500087738,\n",
       "   -0.10943135619163513,\n",
       "   0.5124331712722778,\n",
       "   -0.09719822555780411,\n",
       "   0.188375324010849,\n",
       "   -0.3992774784564972,\n",
       "   -0.22068679332733154,\n",
       "   -0.07246267795562744,\n",
       "   0.32530927658081055,\n",
       "   0.30918338894844055,\n",
       "   0.28846287727355957,\n",
       "   0.22651785612106323,\n",
       "   0.11025876551866531,\n",
       "   0.012953903526067734,\n",
       "   0.7847235798835754,\n",
       "   0.14214032888412476,\n",
       "   0.1958618462085724,\n",
       "   0.03427349776029587,\n",
       "   0.003254346549510956,\n",
       "   0.1084214299917221,\n",
       "   -0.060803964734077454,\n",
       "   0.08664480596780777,\n",
       "   0.34943538904190063,\n",
       "   0.18827387690544128,\n",
       "   -0.04882203787565231,\n",
       "   -0.11239747703075409,\n",
       "   -0.22449548542499542,\n",
       "   0.34552618861198425,\n",
       "   0.31130921840667725,\n",
       "   0.25064438581466675,\n",
       "   0.3239594101905823,\n",
       "   0.09191488474607468,\n",
       "   0.07028993964195251,\n",
       "   0.196829691529274,\n",
       "   -0.14500877261161804,\n",
       "   -0.10139317810535431,\n",
       "   0.664592444896698,\n",
       "   0.5479552149772644,\n",
       "   -0.33506178855895996,\n",
       "   0.04914240539073944,\n",
       "   -0.10748082399368286,\n",
       "   -0.37057510018348694,\n",
       "   -0.022220127284526825,\n",
       "   -0.5590572357177734,\n",
       "   -0.49518322944641113,\n",
       "   0.14051486551761627,\n",
       "   0.032458338886499405,\n",
       "   -0.3970301151275635,\n",
       "   -0.1802283525466919,\n",
       "   -0.08900398761034012,\n",
       "   0.1961486041545868,\n",
       "   0.25669577717781067,\n",
       "   0.4420989155769348,\n",
       "   -0.1669716089963913,\n",
       "   0.048855457454919815,\n",
       "   0.18539859354496002,\n",
       "   -0.5015202164649963,\n",
       "   0.09679675102233887,\n",
       "   0.26567110419273376,\n",
       "   0.5416439175605774,\n",
       "   -0.45098331570625305,\n",
       "   0.15976031124591827,\n",
       "   -0.02442741021513939,\n",
       "   -0.2419658899307251,\n",
       "   -0.17520534992218018,\n",
       "   -0.23875802755355835,\n",
       "   -0.01974642649292946,\n",
       "   0.26240938901901245,\n",
       "   -0.034183237701654434,\n",
       "   0.5429505705833435,\n",
       "   0.04438366740942001,\n",
       "   -0.21477246284484863,\n",
       "   -0.37515783309936523,\n",
       "   -0.09240711480379105,\n",
       "   -0.22423619031906128,\n",
       "   -0.49707525968551636,\n",
       "   0.04070238023996353,\n",
       "   -0.29016149044036865,\n",
       "   0.0400867722928524,\n",
       "   -0.19139468669891357,\n",
       "   -0.27319371700286865,\n",
       "   -0.03696698322892189,\n",
       "   0.24253815412521362,\n",
       "   -0.28769025206565857,\n",
       "   0.25784701108932495,\n",
       "   -0.10416701436042786,\n",
       "   -0.1687631905078888,\n",
       "   0.26232898235321045,\n",
       "   -0.2779538631439209,\n",
       "   -0.09026787430047989,\n",
       "   0.41442179679870605,\n",
       "   -0.4095613658428192,\n",
       "   -0.4962463676929474,\n",
       "   0.18956957757472992,\n",
       "   0.14348362386226654,\n",
       "   -0.07589519768953323,\n",
       "   -0.34873852133750916,\n",
       "   -0.14962372183799744,\n",
       "   0.09856890141963959,\n",
       "   -0.002620002254843712,\n",
       "   -0.222089022397995,\n",
       "   0.046554915606975555,\n",
       "   0.2442915439605713,\n",
       "   -0.19759996235370636,\n",
       "   -0.504565417766571,\n",
       "   0.22566092014312744,\n",
       "   -0.12096993625164032,\n",
       "   -0.3737715482711792,\n",
       "   0.23047380149364471,\n",
       "   -0.04328755661845207,\n",
       "   -0.1539241075515747,\n",
       "   0.05688067525625229,\n",
       "   0.25038906931877136,\n",
       "   -0.2939645051956177,\n",
       "   -0.20093552768230438,\n",
       "   0.22953681647777557,\n",
       "   -0.1826322376728058,\n",
       "   0.004085080232471228,\n",
       "   -0.4833643436431885,\n",
       "   -0.4613800048828125,\n",
       "   -0.16380780935287476,\n",
       "   -0.2596699595451355,\n",
       "   0.45287033915519714,\n",
       "   -0.05841755494475365,\n",
       "   -0.2118210643529892,\n",
       "   -0.13981229066848755,\n",
       "   0.014645159244537354,\n",
       "   0.1710767149925232,\n",
       "   -0.28100648522377014,\n",
       "   0.1600068211555481,\n",
       "   0.0018582222983241081],\n",
       "  [-0.31077703833580017,\n",
       "   -0.11755560338497162,\n",
       "   0.7746284604072571,\n",
       "   0.46346554160118103,\n",
       "   0.24455446004867554,\n",
       "   -0.6843847632408142,\n",
       "   -0.1335335373878479,\n",
       "   1.638596534729004,\n",
       "   -0.8579138517379761,\n",
       "   0.09603923559188843,\n",
       "   0.2309531271457672,\n",
       "   -0.6414260864257812,\n",
       "   -0.5440453886985779,\n",
       "   0.5782439112663269,\n",
       "   0.08573350310325623,\n",
       "   -0.017449773848056793,\n",
       "   0.5882048010826111,\n",
       "   0.10966011136770248,\n",
       "   -0.01172451302409172,\n",
       "   -0.13614007830619812,\n",
       "   0.45041990280151367,\n",
       "   -0.14587584137916565,\n",
       "   -0.20730014145374298,\n",
       "   0.51261967420578,\n",
       "   0.33761101961135864,\n",
       "   -0.4722736179828644,\n",
       "   -0.3485010266304016,\n",
       "   0.10237853974103928,\n",
       "   -0.23033002018928528,\n",
       "   -0.18393166363239288,\n",
       "   -0.08887511491775513,\n",
       "   0.08234446495771408,\n",
       "   -1.221634864807129,\n",
       "   -0.7771688103675842,\n",
       "   -0.5161808729171753,\n",
       "   -0.4821060597896576,\n",
       "   0.06053653731942177,\n",
       "   -0.1187935471534729,\n",
       "   -0.3082751929759979,\n",
       "   0.30373522639274597,\n",
       "   -0.49822431802749634,\n",
       "   -0.4857594966888428,\n",
       "   -0.2435690313577652,\n",
       "   -0.40598490834236145,\n",
       "   -0.0383218377828598,\n",
       "   -0.2937251627445221,\n",
       "   0.957339882850647,\n",
       "   0.0645623430609703,\n",
       "   0.7592741250991821,\n",
       "   -0.4775984585285187,\n",
       "   -0.6886272430419922,\n",
       "   -0.12284083664417267,\n",
       "   0.5536782741546631,\n",
       "   0.02253834903240204,\n",
       "   -0.03749407082796097,\n",
       "   1.0430628061294556,\n",
       "   -0.08525009453296661,\n",
       "   -0.5471941232681274,\n",
       "   -0.5215845108032227,\n",
       "   0.33088529109954834,\n",
       "   0.5562869310379028,\n",
       "   -0.3902706205844879,\n",
       "   -0.10472201555967331,\n",
       "   -0.5169776678085327,\n",
       "   0.4210994839668274,\n",
       "   0.3484537601470947,\n",
       "   0.08737644553184509,\n",
       "   0.28961294889450073,\n",
       "   0.20991723239421844,\n",
       "   -0.033424001187086105,\n",
       "   -0.7138399481773376,\n",
       "   -0.2430637925863266,\n",
       "   -0.3060709834098816,\n",
       "   0.022145230323076248,\n",
       "   -0.39221861958503723,\n",
       "   -0.30341464281082153,\n",
       "   0.15252946317195892,\n",
       "   -0.03714003413915634,\n",
       "   0.07754439115524292,\n",
       "   0.43753090500831604,\n",
       "   0.03732271492481232,\n",
       "   1.2096226215362549,\n",
       "   -0.9253276586532593,\n",
       "   0.8307056427001953,\n",
       "   -0.13601310551166534,\n",
       "   0.2750299274921417,\n",
       "   -0.7193790674209595,\n",
       "   -0.5592150688171387,\n",
       "   0.28988930583000183,\n",
       "   0.45080116391181946,\n",
       "   0.31318914890289307,\n",
       "   -0.15859588980674744,\n",
       "   0.498060405254364,\n",
       "   0.3604189455509186,\n",
       "   0.10654197633266449,\n",
       "   -0.3641420304775238,\n",
       "   -0.326386958360672,\n",
       "   0.5691200494766235,\n",
       "   0.268984854221344,\n",
       "   0.789539098739624,\n",
       "   -0.03368256986141205,\n",
       "   -0.5743579268455505,\n",
       "   0.5175069570541382,\n",
       "   0.4895143210887909,\n",
       "   0.4635128378868103,\n",
       "   -0.028031663969159126,\n",
       "   0.4487115144729614,\n",
       "   0.07352825999259949,\n",
       "   0.2689039409160614,\n",
       "   0.45963823795318604,\n",
       "   -0.00811658427119255,\n",
       "   -0.7935659885406494,\n",
       "   -0.424390971660614,\n",
       "   -0.08103463798761368,\n",
       "   0.4015095829963684,\n",
       "   0.2801695764064789,\n",
       "   0.05263008922338486,\n",
       "   -0.5914799571037292,\n",
       "   -0.1795283555984497,\n",
       "   0.1497194617986679,\n",
       "   -0.45558232069015503,\n",
       "   -0.21303829550743103,\n",
       "   0.18148262798786163,\n",
       "   0.7198630571365356,\n",
       "   0.3332271873950958,\n",
       "   -0.08315537869930267,\n",
       "   -0.8167648315429688,\n",
       "   -0.07442359626293182,\n",
       "   -0.03256279602646828,\n",
       "   -0.6498284339904785,\n",
       "   0.7302212715148926,\n",
       "   0.7274429798126221,\n",
       "   0.6790797710418701,\n",
       "   -0.7479855418205261,\n",
       "   0.12000519037246704,\n",
       "   0.23448476195335388,\n",
       "   0.3558424115180969,\n",
       "   -0.2551255226135254,\n",
       "   -0.49562034010887146,\n",
       "   0.4149496555328369,\n",
       "   -0.05856311321258545,\n",
       "   -0.10193821787834167,\n",
       "   0.4967498183250427,\n",
       "   0.2634577751159668,\n",
       "   0.017347881570458412,\n",
       "   -0.26066887378692627,\n",
       "   0.3378394544124603,\n",
       "   -0.5611252188682556,\n",
       "   0.03896018862724304,\n",
       "   0.0466679148375988,\n",
       "   0.05669444054365158,\n",
       "   -0.7578395009040833,\n",
       "   -0.11841930449008942,\n",
       "   0.033705901354551315,\n",
       "   -0.08928375691175461,\n",
       "   0.026955220848321915,\n",
       "   -0.6977605223655701,\n",
       "   -0.3579981327056885,\n",
       "   0.2925073206424713,\n",
       "   -0.3238348960876465,\n",
       "   0.22464978694915771,\n",
       "   -0.3371390104293823,\n",
       "   0.2646244764328003,\n",
       "   0.5703897476196289,\n",
       "   -0.06364259868860245,\n",
       "   0.2925409972667694,\n",
       "   0.35265791416168213,\n",
       "   0.451768696308136,\n",
       "   0.1589801162481308,\n",
       "   0.30207812786102295,\n",
       "   -0.11667940765619278,\n",
       "   0.4643689692020416,\n",
       "   0.9938846230506897,\n",
       "   -0.6138912439346313,\n",
       "   -0.12193162739276886,\n",
       "   0.03578854352235794,\n",
       "   0.4176478981971741,\n",
       "   0.23022150993347168,\n",
       "   0.2602528929710388,\n",
       "   0.15693603456020355,\n",
       "   -0.5608525276184082,\n",
       "   0.337905615568161,\n",
       "   -0.263114869594574,\n",
       "   -0.11847945302724838,\n",
       "   0.19657324254512787,\n",
       "   -0.07657288759946823,\n",
       "   0.00335712730884552,\n",
       "   0.07537927478551865,\n",
       "   -0.2655981779098511,\n",
       "   0.2941378355026245,\n",
       "   0.29003381729125977,\n",
       "   0.3949756324291229,\n",
       "   -0.5646121501922607,\n",
       "   -0.26739490032196045,\n",
       "   0.3938268721103668,\n",
       "   -0.7087834477424622,\n",
       "   -0.5645325183868408,\n",
       "   -0.7762150764465332,\n",
       "   -0.2658824622631073,\n",
       "   -4.983413964509964e-05,\n",
       "   0.438283234834671,\n",
       "   -0.08727087080478668,\n",
       "   0.4360775947570801,\n",
       "   -0.27963826060295105,\n",
       "   -0.4290398359298706,\n",
       "   -0.22526703774929047,\n",
       "   -0.08461543917655945,\n",
       "   -0.06457006186246872,\n",
       "   -0.376080721616745,\n",
       "   0.4758370518684387,\n",
       "   -0.324779748916626,\n",
       "   1.0125805139541626,\n",
       "   0.12829267978668213,\n",
       "   0.031794413924217224,\n",
       "   -0.2806283235549927,\n",
       "   -0.21715416014194489,\n",
       "   0.7863131165504456,\n",
       "   0.32787829637527466,\n",
       "   -0.41513821482658386,\n",
       "   -0.11509107798337936,\n",
       "   -0.07066650688648224,\n",
       "   0.24354630708694458,\n",
       "   -0.6319507360458374,\n",
       "   0.9848798513412476,\n",
       "   -0.03166575729846954,\n",
       "   0.7068045139312744,\n",
       "   0.07661326229572296,\n",
       "   -0.3040640950202942,\n",
       "   -0.4382181167602539,\n",
       "   0.632925271987915,\n",
       "   -0.18072861433029175,\n",
       "   -0.3516833782196045,\n",
       "   0.3051309883594513,\n",
       "   0.08403809368610382,\n",
       "   0.03720146790146828,\n",
       "   -0.46769973635673523,\n",
       "   -0.19516250491142273,\n",
       "   0.260046124458313,\n",
       "   0.16124680638313293,\n",
       "   -0.34074583649635315,\n",
       "   -0.12259975075721741,\n",
       "   0.39829567074775696,\n",
       "   0.9473170638084412,\n",
       "   -0.30638185143470764,\n",
       "   0.5275200605392456,\n",
       "   0.4628005921840668,\n",
       "   -0.05022750794887543,\n",
       "   0.13650065660476685,\n",
       "   -0.5692898035049438,\n",
       "   -0.348014235496521,\n",
       "   -0.18034061789512634,\n",
       "   -1.5324724912643433,\n",
       "   0.3378938138484955,\n",
       "   -1.1350977420806885,\n",
       "   -0.47560039162635803,\n",
       "   -0.9975695610046387,\n",
       "   -0.2652323544025421,\n",
       "   -0.2840849459171295,\n",
       "   -0.2579311728477478,\n",
       "   0.5557870864868164,\n",
       "   0.15257422626018524,\n",
       "   -0.4797423481941223,\n",
       "   -0.17876604199409485,\n",
       "   -0.2386014759540558,\n",
       "   -0.3874345123767853,\n",
       "   -0.7759411334991455,\n",
       "   0.3335636258125305,\n",
       "   0.5309457182884216,\n",
       "   0.18199840188026428,\n",
       "   0.08616695553064346,\n",
       "   0.26444950699806213,\n",
       "   -0.20313876867294312,\n",
       "   0.17964324355125427,\n",
       "   1.0915274620056152,\n",
       "   -0.3078095018863678,\n",
       "   -0.4960050880908966,\n",
       "   -0.10517340898513794,\n",
       "   0.1015729233622551,\n",
       "   -0.5777710676193237,\n",
       "   -0.34493765234947205,\n",
       "   0.4129827618598938,\n",
       "   1.0531789064407349,\n",
       "   -0.28865084052085876,\n",
       "   0.31730687618255615,\n",
       "   -0.21888300776481628,\n",
       "   -0.45665261149406433,\n",
       "   0.6147240996360779,\n",
       "   0.5529573559761047,\n",
       "   -0.4579336643218994,\n",
       "   0.038910940289497375,\n",
       "   -0.24798016250133514,\n",
       "   0.3962095081806183,\n",
       "   -0.5427607297897339,\n",
       "   -0.5053920745849609,\n",
       "   0.29010263085365295,\n",
       "   -0.2089134156703949,\n",
       "   0.1290443390607834,\n",
       "   -0.5132870674133301,\n",
       "   -0.4419541656970978,\n",
       "   -0.4009651839733124,\n",
       "   -0.3887430429458618,\n",
       "   -0.49346283078193665,\n",
       "   -0.2773042321205139,\n",
       "   0.5735945701599121,\n",
       "   -0.17311395704746246,\n",
       "   0.024707697331905365,\n",
       "   -0.24506278336048126,\n",
       "   -1.0660319328308105,\n",
       "   -3.6381852626800537,\n",
       "   0.09362980723381042,\n",
       "   -0.18005050718784332,\n",
       "   -0.15145201981067657,\n",
       "   0.11044764518737793,\n",
       "   0.016346978023648262,\n",
       "   0.19523388147354126,\n",
       "   -0.28182533383369446,\n",
       "   -1.2925446033477783,\n",
       "   -0.37197113037109375,\n",
       "   -0.6161850094795227,\n",
       "   -0.10946989059448242,\n",
       "   0.8260509371757507,\n",
       "   0.6179834008216858,\n",
       "   0.8863745331764221,\n",
       "   -0.19358208775520325,\n",
       "   0.0854978859424591,\n",
       "   0.4016280174255371,\n",
       "   -0.1291961967945099,\n",
       "   0.9982874989509583,\n",
       "   0.14194782078266144,\n",
       "   -0.37128639221191406,\n",
       "   -0.19992747902870178,\n",
       "   -0.15219831466674805,\n",
       "   0.7037853002548218,\n",
       "   0.30833297967910767,\n",
       "   0.2646418511867523,\n",
       "   0.03357122093439102,\n",
       "   -0.40821191668510437,\n",
       "   0.30428093671798706,\n",
       "   -0.04942365363240242,\n",
       "   -0.3520044982433319,\n",
       "   -0.17357130348682404,\n",
       "   -0.026921413838863373,\n",
       "   -0.010305818170309067,\n",
       "   -0.006294779479503632,\n",
       "   0.15449362993240356,\n",
       "   -0.3687778413295746,\n",
       "   -0.12442953139543533,\n",
       "   0.5233830809593201,\n",
       "   -0.3866307735443115,\n",
       "   -0.8194968700408936,\n",
       "   -0.30073827505111694,\n",
       "   0.1840701699256897,\n",
       "   0.5843326449394226,\n",
       "   -0.11327175796031952,\n",
       "   0.20365352928638458,\n",
       "   -0.6661554574966431,\n",
       "   0.2746953070163727,\n",
       "   -0.03837551921606064,\n",
       "   0.2761036455631256,\n",
       "   -0.28282585740089417,\n",
       "   -0.18996503949165344,\n",
       "   -0.39489248394966125,\n",
       "   -0.5662198066711426,\n",
       "   -0.26965463161468506,\n",
       "   1.0462884902954102,\n",
       "   0.3370780944824219,\n",
       "   -0.4617047607898712,\n",
       "   -0.8034270405769348,\n",
       "   0.31348928809165955,\n",
       "   -0.303968608379364,\n",
       "   -0.8649020195007324,\n",
       "   -0.09038128703832626,\n",
       "   0.2013099193572998,\n",
       "   -0.09932933747768402,\n",
       "   -0.028784245252609253,\n",
       "   -0.10120680928230286,\n",
       "   0.15417622029781342,\n",
       "   0.5228809118270874,\n",
       "   0.08506287634372711,\n",
       "   0.054715562611818314,\n",
       "   -0.6826476454734802,\n",
       "   -0.9763069152832031,\n",
       "   -0.16604551672935486,\n",
       "   0.2869538366794586,\n",
       "   -0.18143518269062042,\n",
       "   -0.20334511995315552,\n",
       "   0.10296174883842468,\n",
       "   0.3012511134147644,\n",
       "   -1.0841314792633057,\n",
       "   -0.7240369915962219,\n",
       "   -0.40359944105148315,\n",
       "   -0.5291233062744141,\n",
       "   0.4841254949569702,\n",
       "   -1.4230072498321533,\n",
       "   -0.43678897619247437,\n",
       "   -0.5878726243972778,\n",
       "   -0.09149348735809326,\n",
       "   -0.6201652884483337,\n",
       "   0.26154637336730957,\n",
       "   0.16637255251407623,\n",
       "   0.16522762179374695,\n",
       "   -0.1672779768705368,\n",
       "   0.21114535629749298,\n",
       "   0.304951012134552,\n",
       "   0.22541069984436035,\n",
       "   -0.4959943890571594,\n",
       "   0.4628697335720062,\n",
       "   -0.5982125997543335,\n",
       "   0.5420790910720825,\n",
       "   -0.0842292308807373,\n",
       "   1.2438533306121826,\n",
       "   -0.002828005701303482,\n",
       "   0.011113235726952553,\n",
       "   -0.4407320022583008,\n",
       "   0.07177649438381195,\n",
       "   -0.3486274480819702,\n",
       "   -0.3054415285587311,\n",
       "   0.43318837881088257,\n",
       "   0.42399439215660095,\n",
       "   -0.16868649423122406,\n",
       "   1.1811635494232178,\n",
       "   -0.441389799118042,\n",
       "   -0.031500719487667084,\n",
       "   -0.3044690191745758,\n",
       "   0.3982897400856018,\n",
       "   1.1205425262451172,\n",
       "   -0.2977759540081024,\n",
       "   0.062269993126392365,\n",
       "   -0.4062815010547638,\n",
       "   0.9769349098205566,\n",
       "   -0.2993413209915161,\n",
       "   -0.6917769908905029,\n",
       "   -0.39398688077926636,\n",
       "   0.0007585491985082626,\n",
       "   -0.45529279112815857,\n",
       "   -1.369032382965088,\n",
       "   -0.02274993807077408,\n",
       "   0.40846315026283264,\n",
       "   -0.8466687798500061,\n",
       "   -0.29027530550956726,\n",
       "   0.2668053209781647,\n",
       "   0.021867282688617706,\n",
       "   0.49252063035964966,\n",
       "   0.06861526519060135,\n",
       "   0.1739659607410431,\n",
       "   -0.667790949344635,\n",
       "   0.07130391150712967,\n",
       "   0.33017775416374207,\n",
       "   0.1300642192363739,\n",
       "   0.5054255127906799,\n",
       "   0.01614326983690262,\n",
       "   -0.28968772292137146,\n",
       "   -0.355868399143219,\n",
       "   0.9265486001968384,\n",
       "   0.5316134095191956,\n",
       "   -0.19075852632522583,\n",
       "   -0.2446889579296112,\n",
       "   0.6460633873939514,\n",
       "   -0.27895399928092957,\n",
       "   -0.7601655125617981,\n",
       "   -0.3001636266708374,\n",
       "   -0.28611400723457336,\n",
       "   0.46922624111175537,\n",
       "   0.08412978053092957,\n",
       "   0.6921231150627136,\n",
       "   -0.29991021752357483,\n",
       "   -0.05946831405162811,\n",
       "   -0.39518460631370544,\n",
       "   -0.41896313428878784,\n",
       "   -0.011804774403572083,\n",
       "   0.8456015586853027,\n",
       "   0.5138698816299438,\n",
       "   0.2569253742694855,\n",
       "   0.09417173266410828,\n",
       "   -0.369427353143692,\n",
       "   -0.043654970824718475,\n",
       "   0.3584216833114624,\n",
       "   0.1470615267753601,\n",
       "   -0.16267868876457214,\n",
       "   -0.33498290181159973,\n",
       "   0.27510228753089905,\n",
       "   -0.12158098816871643,\n",
       "   -0.9458433985710144,\n",
       "   0.9070742130279541,\n",
       "   0.5046346783638,\n",
       "   -0.11773581057786942,\n",
       "   -0.7058053612709045,\n",
       "   0.595158040523529,\n",
       "   -0.30804333090782166,\n",
       "   0.11021538823843002,\n",
       "   0.30075085163116455,\n",
       "   -0.20869211852550507,\n",
       "   0.8148145079612732,\n",
       "   0.4301043152809143,\n",
       "   0.5349464416503906,\n",
       "   -0.0027594882994890213,\n",
       "   0.019534677267074585,\n",
       "   0.20686982572078705,\n",
       "   -0.117671899497509,\n",
       "   0.08532501757144928,\n",
       "   -0.16286906599998474,\n",
       "   -0.5385986566543579,\n",
       "   -0.24120613932609558,\n",
       "   -0.33580827713012695,\n",
       "   1.0925935506820679,\n",
       "   0.2878775894641876,\n",
       "   0.0026745109353214502,\n",
       "   0.03036857396364212,\n",
       "   -0.1130397766828537,\n",
       "   -0.9106401205062866,\n",
       "   -0.32332849502563477,\n",
       "   -0.14586594700813293,\n",
       "   0.2965276837348938,\n",
       "   -0.7916385531425476,\n",
       "   0.4477826654911041,\n",
       "   0.2720787823200226,\n",
       "   0.3913118839263916,\n",
       "   0.3752172589302063,\n",
       "   -0.27166998386383057,\n",
       "   -0.48181381821632385,\n",
       "   -0.2049119621515274,\n",
       "   -0.3620012104511261,\n",
       "   0.4733237028121948,\n",
       "   -0.279984712600708,\n",
       "   -0.04147467762231827,\n",
       "   -0.22112557291984558,\n",
       "   -0.4470160901546478,\n",
       "   0.028875410556793213,\n",
       "   -0.4917829632759094,\n",
       "   0.36024412512779236,\n",
       "   -0.36838361620903015,\n",
       "   0.15595078468322754,\n",
       "   -0.8340954184532166,\n",
       "   -0.4707367420196533,\n",
       "   0.258282333612442,\n",
       "   -0.0885939672589302,\n",
       "   -0.7348703145980835,\n",
       "   -0.14013367891311646,\n",
       "   0.26809853315353394,\n",
       "   -1.0111439228057861,\n",
       "   0.02619938552379608,\n",
       "   0.2949967384338379,\n",
       "   -0.39615654945373535,\n",
       "   0.061050526797771454,\n",
       "   -0.18947428464889526,\n",
       "   0.0001732315868139267,\n",
       "   -0.3532980680465698,\n",
       "   0.08081922680139542,\n",
       "   -0.4236653745174408,\n",
       "   -0.5340657830238342,\n",
       "   -0.10573117434978485,\n",
       "   -0.4651523530483246,\n",
       "   0.18469175696372986,\n",
       "   -0.17482209205627441,\n",
       "   -0.14626933634281158,\n",
       "   0.8746039867401123,\n",
       "   -0.7665289640426636,\n",
       "   0.11333298683166504,\n",
       "   0.417388379573822,\n",
       "   -0.11526434123516083,\n",
       "   0.15613491833209991,\n",
       "   -0.5426101684570312,\n",
       "   0.07435482740402222,\n",
       "   -0.039835043251514435,\n",
       "   -0.5112216472625732,\n",
       "   0.10256413370370865,\n",
       "   0.16894260048866272,\n",
       "   -0.02698848396539688,\n",
       "   -0.3201362192630768,\n",
       "   -0.47975412011146545,\n",
       "   -0.5336804986000061,\n",
       "   0.19016551971435547,\n",
       "   0.30468887090682983,\n",
       "   0.2879174053668976,\n",
       "   -0.054184868931770325,\n",
       "   0.83137047290802,\n",
       "   -0.019007209688425064,\n",
       "   -0.21910248696804047,\n",
       "   0.5852165818214417,\n",
       "   -0.058588266372680664,\n",
       "   0.37006643414497375,\n",
       "   -0.2739480435848236,\n",
       "   0.20712190866470337,\n",
       "   0.0920611247420311,\n",
       "   -0.09284932911396027,\n",
       "   -0.3493744432926178,\n",
       "   0.4594334363937378,\n",
       "   -0.11565219610929489,\n",
       "   -0.18413645029067993,\n",
       "   0.057641737163066864,\n",
       "   0.48632004857063293,\n",
       "   -0.2721436619758606,\n",
       "   0.026905786246061325,\n",
       "   -0.010095801204442978,\n",
       "   0.30009883642196655,\n",
       "   1.0998585224151611,\n",
       "   0.43069660663604736,\n",
       "   -0.15614311397075653,\n",
       "   0.26109322905540466,\n",
       "   0.6036434173583984,\n",
       "   0.41147565841674805,\n",
       "   0.2066018283367157,\n",
       "   -0.12174327671527863,\n",
       "   0.14584116637706757,\n",
       "   0.6681696176528931,\n",
       "   0.3070647716522217,\n",
       "   -0.03813070058822632,\n",
       "   -0.19729416072368622,\n",
       "   -0.5301448702812195,\n",
       "   -0.12286625802516937,\n",
       "   0.42739689350128174,\n",
       "   0.6804860830307007,\n",
       "   -0.44710350036621094,\n",
       "   0.4508213996887207,\n",
       "   0.4375813901424408,\n",
       "   -0.2875751256942749,\n",
       "   0.31431636214256287,\n",
       "   0.5186235308647156,\n",
       "   0.08052835613489151,\n",
       "   -0.6205043792724609,\n",
       "   1.0836941003799438,\n",
       "   0.9041217565536499,\n",
       "   -0.900031566619873,\n",
       "   -0.6415662169456482,\n",
       "   0.005183938890695572,\n",
       "   0.2015022337436676,\n",
       "   0.4383438229560852,\n",
       "   0.34048596024513245,\n",
       "   0.4283688962459564,\n",
       "   -0.28379568457603455,\n",
       "   0.3104478418827057,\n",
       "   0.045588117092847824,\n",
       "   0.017819207161664963,\n",
       "   0.6164401769638062,\n",
       "   0.025295965373516083,\n",
       "   -0.4268134832382202,\n",
       "   0.2882148325443268,\n",
       "   0.3338482975959778,\n",
       "   -0.4937897026538849,\n",
       "   -0.12007346004247665,\n",
       "   -0.7027686238288879,\n",
       "   0.41569027304649353,\n",
       "   -0.2673914432525635,\n",
       "   -0.26151275634765625,\n",
       "   -0.1095147430896759,\n",
       "   0.33302751183509827,\n",
       "   0.36041149497032166,\n",
       "   -0.3297090530395508,\n",
       "   0.020542100071907043,\n",
       "   0.5654988288879395,\n",
       "   0.7332455515861511,\n",
       "   1.138504147529602,\n",
       "   0.4213056266307831,\n",
       "   0.4384719133377075,\n",
       "   0.3883588910102844,\n",
       "   -0.652841329574585,\n",
       "   0.8523522019386292,\n",
       "   0.4052050709724426,\n",
       "   -0.04725175350904465,\n",
       "   0.6539427042007446,\n",
       "   -0.005770199000835419,\n",
       "   -0.18917140364646912,\n",
       "   0.48581787943840027,\n",
       "   -0.4788723886013031,\n",
       "   0.29083341360092163,\n",
       "   0.9159522652626038,\n",
       "   -0.019607361406087875,\n",
       "   0.5811404585838318,\n",
       "   0.5971382260322571,\n",
       "   0.4946800172328949,\n",
       "   0.02567492425441742,\n",
       "   -0.7052813172340393,\n",
       "   0.014390520751476288,\n",
       "   0.43620067834854126,\n",
       "   0.8540461659431458,\n",
       "   -0.3593250513076782,\n",
       "   -0.16270536184310913,\n",
       "   0.2395576536655426,\n",
       "   -0.29485785961151123,\n",
       "   -0.13559982180595398,\n",
       "   -0.11510969698429108,\n",
       "   -0.699428379535675,\n",
       "   -0.2133122682571411,\n",
       "   0.12084753811359406,\n",
       "   -0.1734207719564438,\n",
       "   -0.45576223731040955,\n",
       "   -0.20075787603855133,\n",
       "   0.7148732542991638,\n",
       "   0.8104689121246338,\n",
       "   0.1808566153049469,\n",
       "   -0.3709661662578583,\n",
       "   -0.35976919531822205,\n",
       "   -0.5941430926322937,\n",
       "   -0.7878499031066895,\n",
       "   -0.017360690981149673,\n",
       "   -0.3050954341888428,\n",
       "   0.1757902354001999,\n",
       "   -0.06462928652763367,\n",
       "   0.2418128401041031,\n",
       "   -0.24537694454193115,\n",
       "   -0.39453598856925964,\n",
       "   -0.7962619066238403,\n",
       "   0.14242270588874817,\n",
       "   -0.6708375811576843,\n",
       "   0.22046351432800293,\n",
       "   0.3480849862098694,\n",
       "   0.6628510355949402,\n",
       "   -0.24069301784038544,\n",
       "   0.09466178715229034,\n",
       "   0.21085846424102783,\n",
       "   -0.18491612374782562,\n",
       "   -0.07784794270992279,\n",
       "   -0.3016917407512665,\n",
       "   0.06629820168018341,\n",
       "   -0.5595465898513794,\n",
       "   0.581382691860199,\n",
       "   -0.4590427875518799,\n",
       "   0.03798767551779747,\n",
       "   0.017124302685260773,\n",
       "   0.7891266942024231,\n",
       "   -0.4296365976333618,\n",
       "   0.20514240860939026,\n",
       "   -0.4520050287246704,\n",
       "   -0.2989116907119751,\n",
       "   0.5468009114265442,\n",
       "   -0.12245960533618927,\n",
       "   -0.2282591462135315,\n",
       "   0.7038831114768982,\n",
       "   0.3192179799079895,\n",
       "   -0.27798721194267273,\n",
       "   -0.14287400245666504,\n",
       "   0.7525046467781067,\n",
       "   0.15934701263904572,\n",
       "   -0.128866046667099,\n",
       "   0.1418929547071457,\n",
       "   0.5808617472648621,\n",
       "   0.2314796894788742,\n",
       "   -0.6166960597038269,\n",
       "   -0.26317673921585083,\n",
       "   0.27594736218452454,\n",
       "   0.26030847430229187,\n",
       "   -0.3238130807876587,\n",
       "   -0.3819983899593353,\n",
       "   -0.3055461049079895,\n",
       "   -0.6412560939788818,\n",
       "   -0.019520413130521774,\n",
       "   -0.5700310468673706,\n",
       "   -0.5657910108566284,\n",
       "   0.2688309848308563,\n",
       "   0.06522685289382935,\n",
       "   0.2753332853317261,\n",
       "   0.16287687420845032,\n",
       "   1.0249488353729248,\n",
       "   -0.6806690692901611,\n",
       "   -0.4375722408294678,\n",
       "   -0.7855051755905151,\n",
       "   0.47984766960144043,\n",
       "   -0.326057106256485,\n",
       "   -0.05309445783495903,\n",
       "   -0.060998156666755676,\n",
       "   0.2591182589530945,\n",
       "   -0.722008228302002,\n",
       "   -0.1307036429643631,\n",
       "   0.3988012671470642,\n",
       "   -0.08384457975625992,\n",
       "   -0.31313756108283997,\n",
       "   0.31877589225769043,\n",
       "   0.11651688814163208],\n",
       "  [0.042680710554122925,\n",
       "   -0.013645492494106293,\n",
       "   0.4714743494987488,\n",
       "   0.2892722189426422,\n",
       "   0.4132937490940094,\n",
       "   -1.0063233375549316,\n",
       "   0.28293269872665405,\n",
       "   0.7238180041313171,\n",
       "   -0.6014285683631897,\n",
       "   -0.5218937397003174,\n",
       "   0.12050895392894745,\n",
       "   -0.2776886224746704,\n",
       "   -0.41629016399383545,\n",
       "   0.5429711937904358,\n",
       "   -0.050031132996082306,\n",
       "   0.6390937566757202,\n",
       "   0.36779847741127014,\n",
       "   -0.04751221090555191,\n",
       "   0.27212846279144287,\n",
       "   -0.3743770718574524,\n",
       "   -0.11923132091760635,\n",
       "   -0.5220564007759094,\n",
       "   -0.07724087685346603,\n",
       "   0.7303982973098755,\n",
       "   0.26144129037857056,\n",
       "   0.6467391848564148,\n",
       "   -0.13687372207641602,\n",
       "   0.2968359887599945,\n",
       "   -0.11716045439243317,\n",
       "   -0.08884614706039429,\n",
       "   0.021838996559381485,\n",
       "   -0.06425289809703827,\n",
       "   -0.6194949150085449,\n",
       "   -0.25372716784477234,\n",
       "   -0.2103140652179718,\n",
       "   -0.26729002594947815,\n",
       "   -0.12450611591339111,\n",
       "   -0.07453354448080063,\n",
       "   -0.035114482045173645,\n",
       "   0.2788963317871094,\n",
       "   -0.7224371433258057,\n",
       "   -0.77479088306427,\n",
       "   -0.2312461882829666,\n",
       "   -0.07808809727430344,\n",
       "   0.1574491262435913,\n",
       "   0.27727505564689636,\n",
       "   1.0702900886535645,\n",
       "   0.3822368383407593,\n",
       "   0.12951114773750305,\n",
       "   -0.07881127297878265,\n",
       "   0.0027532726526260376,\n",
       "   0.3468492329120636,\n",
       "   -0.33170175552368164,\n",
       "   -0.38500550389289856,\n",
       "   0.011045701801776886,\n",
       "   0.9336796402931213,\n",
       "   -0.20719102025032043,\n",
       "   -0.8470925688743591,\n",
       "   -0.5201619863510132,\n",
       "   0.35226571559906006,\n",
       "   0.2918662428855896,\n",
       "   -0.5353130102157593,\n",
       "   -0.2732459008693695,\n",
       "   -0.18358373641967773,\n",
       "   0.4131152331829071,\n",
       "   0.22866275906562805,\n",
       "   0.04974258318543434,\n",
       "   -0.46626415848731995,\n",
       "   -0.40198373794555664,\n",
       "   0.3849113881587982,\n",
       "   -0.8695036768913269,\n",
       "   -0.4330141246318817,\n",
       "   0.14158496260643005,\n",
       "   0.35780131816864014,\n",
       "   -0.7638834118843079,\n",
       "   0.05084548890590668,\n",
       "   0.35196730494499207,\n",
       "   0.12534266710281372,\n",
       "   0.1737348735332489,\n",
       "   0.20277410745620728,\n",
       "   -0.42775991559028625,\n",
       "   0.4347236752510071,\n",
       "   0.3825898766517639,\n",
       "   0.2859538793563843,\n",
       "   0.008272448554635048,\n",
       "   -0.0018698833882808685,\n",
       "   -0.7880271077156067,\n",
       "   -0.4960062503814697,\n",
       "   -0.035419780761003494,\n",
       "   0.8137213587760925,\n",
       "   -0.150580495595932,\n",
       "   -0.005445398390293121,\n",
       "   0.14806684851646423,\n",
       "   -0.05002906918525696,\n",
       "   0.14786610007286072,\n",
       "   -0.3941245973110199,\n",
       "   -0.17866505682468414,\n",
       "   0.26170849800109863,\n",
       "   0.03992537036538124,\n",
       "   0.5170596837997437,\n",
       "   0.07219253480434418,\n",
       "   -0.23700816929340363,\n",
       "   0.05377025157213211,\n",
       "   -0.18542078137397766,\n",
       "   0.5646750330924988,\n",
       "   -0.29892823100090027,\n",
       "   0.8661999702453613,\n",
       "   -0.2775188684463501,\n",
       "   0.042802002280950546,\n",
       "   0.2943672835826874,\n",
       "   -0.44992634654045105,\n",
       "   -0.36166948080062866,\n",
       "   -0.2783571481704712,\n",
       "   0.08270177990198135,\n",
       "   0.1749444305896759,\n",
       "   0.3784429132938385,\n",
       "   0.27433493733406067,\n",
       "   -0.903954267501831,\n",
       "   -0.2170485258102417,\n",
       "   -0.44477471709251404,\n",
       "   -0.24773219227790833,\n",
       "   0.24979136884212494,\n",
       "   0.5662674903869629,\n",
       "   0.8046910762786865,\n",
       "   -0.05531208589673042,\n",
       "   0.2064073383808136,\n",
       "   -0.2698822319507599,\n",
       "   -0.2080436497926712,\n",
       "   -0.06709334999322891,\n",
       "   -0.42027199268341064,\n",
       "   0.7019689679145813,\n",
       "   0.6547714471817017,\n",
       "   0.7274819612503052,\n",
       "   -0.7051500082015991,\n",
       "   -0.261852890253067,\n",
       "   -0.05975857377052307,\n",
       "   0.38358163833618164,\n",
       "   -0.041538603603839874,\n",
       "   -0.3880420923233032,\n",
       "   0.27546122670173645,\n",
       "   -0.06371975690126419,\n",
       "   -0.09130766987800598,\n",
       "   0.7834654450416565,\n",
       "   0.47417253255844116,\n",
       "   0.06294388324022293,\n",
       "   0.0050686076283454895,\n",
       "   0.6525066494941711,\n",
       "   -0.30200350284576416,\n",
       "   -0.06341865658760071,\n",
       "   -0.13899590075016022,\n",
       "   0.02433302253484726,\n",
       "   -0.488813579082489,\n",
       "   -0.1518261581659317,\n",
       "   -0.263714462518692,\n",
       "   -0.15684053301811218,\n",
       "   -0.19280636310577393,\n",
       "   -0.4483667016029358,\n",
       "   -0.009371133521199226,\n",
       "   -0.20768281817436218,\n",
       "   0.0298604853451252,\n",
       "   0.46811795234680176,\n",
       "   -0.1494709551334381,\n",
       "   -0.01575111784040928,\n",
       "   0.3925420939922333,\n",
       "   0.2413736879825592,\n",
       "   -0.02433030679821968,\n",
       "   0.046015482395887375,\n",
       "   -0.0057872384786605835,\n",
       "   0.035897187888622284,\n",
       "   -0.10269252210855484,\n",
       "   -0.5922180414199829,\n",
       "   -0.6101382374763489,\n",
       "   0.8936704993247986,\n",
       "   -0.1456141322851181,\n",
       "   0.15838980674743652,\n",
       "   0.2982149124145508,\n",
       "   -0.08133181929588318,\n",
       "   0.2710196077823639,\n",
       "   0.3501744866371155,\n",
       "   0.2607214152812958,\n",
       "   -0.08218497037887573,\n",
       "   0.12669146060943604,\n",
       "   0.4841841161251068,\n",
       "   0.26037919521331787,\n",
       "   0.3384929895401001,\n",
       "   0.034291647374629974,\n",
       "   0.9826279282569885,\n",
       "   -0.4113101065158844,\n",
       "   -0.27786383032798767,\n",
       "   0.20202231407165527,\n",
       "   -0.6541011929512024,\n",
       "   -0.9051728844642639,\n",
       "   -0.22841568291187286,\n",
       "   0.13722161948680878,\n",
       "   -0.06815632432699203,\n",
       "   -1.0261927843093872,\n",
       "   -0.4431460499763489,\n",
       "   -0.3775373697280884,\n",
       "   -0.16120977699756622,\n",
       "   -0.300962895154953,\n",
       "   0.13655439019203186,\n",
       "   -0.1281440258026123,\n",
       "   0.37182414531707764,\n",
       "   -0.16614434123039246,\n",
       "   -0.19237808883190155,\n",
       "   0.06754390895366669,\n",
       "   -0.09346291422843933,\n",
       "   -0.1335335671901703,\n",
       "   -0.20138932764530182,\n",
       "   -0.1562555879354477,\n",
       "   -0.507301390171051,\n",
       "   0.14156688749790192,\n",
       "   0.1875935196876526,\n",
       "   0.3379461169242859,\n",
       "   -0.06903941929340363,\n",
       "   0.1340973973274231,\n",
       "   0.4670961797237396,\n",
       "   -0.023254549130797386,\n",
       "   0.0033573112450540066,\n",
       "   0.034358181059360504,\n",
       "   -0.44698700308799744,\n",
       "   0.3145246207714081,\n",
       "   -0.6670449376106262,\n",
       "   0.6937427520751953,\n",
       "   0.18104183673858643,\n",
       "   1.0062475204467773,\n",
       "   0.44348597526550293,\n",
       "   -0.3663843274116516,\n",
       "   -0.1387476772069931,\n",
       "   0.022963671013712883,\n",
       "   -0.00812038779258728,\n",
       "   -0.3339173197746277,\n",
       "   0.2781641483306885,\n",
       "   0.5361886620521545,\n",
       "   0.40048813819885254,\n",
       "   -0.4572402834892273,\n",
       "   -0.19159194827079773,\n",
       "   0.07558944076299667,\n",
       "   0.713816225528717,\n",
       "   -0.21804364025592804,\n",
       "   -0.22920477390289307,\n",
       "   0.32927781343460083,\n",
       "   1.0918647050857544,\n",
       "   0.017601152881979942,\n",
       "   0.2162584364414215,\n",
       "   0.19416137039661407,\n",
       "   -0.17650659382343292,\n",
       "   0.16182497143745422,\n",
       "   0.02796047180891037,\n",
       "   -0.34500986337661743,\n",
       "   -0.20748230814933777,\n",
       "   -0.2729297876358032,\n",
       "   0.017393428832292557,\n",
       "   -0.740406334400177,\n",
       "   -0.7612661719322205,\n",
       "   -0.9104903340339661,\n",
       "   -0.02032182179391384,\n",
       "   0.0472889207303524,\n",
       "   -0.05270453169941902,\n",
       "   0.6564405560493469,\n",
       "   -0.6454752087593079,\n",
       "   0.09368813037872314,\n",
       "   -0.6073344349861145,\n",
       "   -0.24503710865974426,\n",
       "   -0.38505929708480835,\n",
       "   -0.4699462652206421,\n",
       "   -0.36183273792266846,\n",
       "   0.721772313117981,\n",
       "   0.2390921264886856,\n",
       "   0.17936578392982483,\n",
       "   0.33013784885406494,\n",
       "   -0.12016811221837997,\n",
       "   0.44407418370246887,\n",
       "   0.8953613638877869,\n",
       "   -0.17585071921348572,\n",
       "   -1.0876463651657104,\n",
       "   -0.00739143043756485,\n",
       "   -0.011787109076976776,\n",
       "   -0.22040842473506927,\n",
       "   -0.14638666808605194,\n",
       "   0.34237274527549744,\n",
       "   0.5798710584640503,\n",
       "   0.04509081691503525,\n",
       "   0.015342757105827332,\n",
       "   -0.20166316628456116,\n",
       "   -0.6156066060066223,\n",
       "   0.3746306002140045,\n",
       "   0.32800668478012085,\n",
       "   -0.3686142861843109,\n",
       "   0.13886351883411407,\n",
       "   -0.12961575388908386,\n",
       "   -0.16059735417366028,\n",
       "   -0.743224024772644,\n",
       "   0.05041170120239258,\n",
       "   0.4061775207519531,\n",
       "   -0.05705484375357628,\n",
       "   0.32639947533607483,\n",
       "   -0.519729733467102,\n",
       "   -0.12808716297149658,\n",
       "   -0.3988698124885559,\n",
       "   0.7308667898178101,\n",
       "   -0.11059268563985825,\n",
       "   0.6358399391174316,\n",
       "   0.5221715569496155,\n",
       "   -0.28612107038497925,\n",
       "   -0.1352226287126541,\n",
       "   -0.018045522272586823,\n",
       "   -0.6399437189102173,\n",
       "   -4.0148701667785645,\n",
       "   0.06657104194164276,\n",
       "   -0.36167311668395996,\n",
       "   0.12614285945892334,\n",
       "   0.4244597852230072,\n",
       "   -0.027204181998968124,\n",
       "   0.17741405963897705,\n",
       "   -0.16177783906459808,\n",
       "   -0.8322889804840088,\n",
       "   -0.3852570056915283,\n",
       "   -0.31242236495018005,\n",
       "   0.042749300599098206,\n",
       "   0.20812836289405823,\n",
       "   0.5032177567481995,\n",
       "   0.3406561613082886,\n",
       "   -0.5776548385620117,\n",
       "   -0.40021127462387085,\n",
       "   0.3377588391304016,\n",
       "   -0.011139385402202606,\n",
       "   1.2346986532211304,\n",
       "   0.15131442248821259,\n",
       "   -0.15637710690498352,\n",
       "   0.26867201924324036,\n",
       "   0.029753046110272408,\n",
       "   0.5828562378883362,\n",
       "   -0.3055431544780731,\n",
       "   0.41096818447113037,\n",
       "   -0.089053213596344,\n",
       "   -0.3947497010231018,\n",
       "   0.34875547885894775,\n",
       "   -0.4058750569820404,\n",
       "   -0.7032780051231384,\n",
       "   -0.2642786204814911,\n",
       "   -0.371906042098999,\n",
       "   0.4440072774887085,\n",
       "   -0.2705983817577362,\n",
       "   0.2683551609516144,\n",
       "   -0.07468513399362564,\n",
       "   0.17923814058303833,\n",
       "   0.3712225556373596,\n",
       "   -0.20097316801548004,\n",
       "   -1.2206401824951172,\n",
       "   -0.11687462031841278,\n",
       "   0.5375788807868958,\n",
       "   0.5229473114013672,\n",
       "   0.014613978564739227,\n",
       "   -0.5775269269943237,\n",
       "   -0.6615517139434814,\n",
       "   0.11186499148607254,\n",
       "   0.12684281170368195,\n",
       "   0.4824318289756775,\n",
       "   0.17504829168319702,\n",
       "   0.2309914082288742,\n",
       "   -0.7006744742393494,\n",
       "   -0.5408232808113098,\n",
       "   -0.3670210838317871,\n",
       "   0.901160717010498,\n",
       "   0.3451937139034271,\n",
       "   -0.48083749413490295,\n",
       "   -0.39108186960220337,\n",
       "   0.041643090546131134,\n",
       "   -0.32752668857574463,\n",
       "   -0.17659670114517212,\n",
       "   -0.7412896156311035,\n",
       "   0.5839054584503174,\n",
       "   0.14215563237667084,\n",
       "   -0.4735795855522156,\n",
       "   -0.03558354452252388,\n",
       "   -0.24604380130767822,\n",
       "   0.5648849606513977,\n",
       "   0.20101970434188843,\n",
       "   0.172178253531456,\n",
       "   -0.3811706304550171,\n",
       "   -0.9508833885192871,\n",
       "   0.15568965673446655,\n",
       "   0.2044500857591629,\n",
       "   0.15661059319972992,\n",
       "   0.1666908860206604,\n",
       "   0.46083149313926697,\n",
       "   0.5555481314659119,\n",
       "   -0.5963501334190369,\n",
       "   -0.7167907357215881,\n",
       "   -0.23923467099666595,\n",
       "   -0.5302293300628662,\n",
       "   0.13002508878707886,\n",
       "   -0.7941461205482483,\n",
       "   -0.24543868005275726,\n",
       "   -0.28565508127212524,\n",
       "   0.07781429588794708,\n",
       "   -0.26795443892478943,\n",
       "   0.3290548324584961,\n",
       "   0.3824802041053772,\n",
       "   0.6493337750434875,\n",
       "   0.16983000934123993,\n",
       "   0.661942720413208,\n",
       "   0.2521618604660034,\n",
       "   0.18146410584449768,\n",
       "   -0.1770249307155609,\n",
       "   -0.04373469203710556,\n",
       "   -0.36348703503608704,\n",
       "   -0.1463753581047058,\n",
       "   -0.2703856825828552,\n",
       "   1.0198551416397095,\n",
       "   -0.43872231245040894,\n",
       "   0.023977311328053474,\n",
       "   -0.031020110473036766,\n",
       "   -0.35270896553993225,\n",
       "   0.18323099613189697,\n",
       "   -0.1707058697938919,\n",
       "   0.3108068108558655,\n",
       "   0.2645485997200012,\n",
       "   -0.03171626105904579,\n",
       "   0.8554067015647888,\n",
       "   -0.31720274686813354,\n",
       "   -0.13636595010757446,\n",
       "   -0.20045462250709534,\n",
       "   0.6677411198616028,\n",
       "   0.6693429350852966,\n",
       "   -0.12712815403938293,\n",
       "   -0.24051770567893982,\n",
       "   -0.39111751317977905,\n",
       "   0.3392980992794037,\n",
       "   -0.06339085102081299,\n",
       "   -0.6325386166572571,\n",
       "   -0.9056249260902405,\n",
       "   0.04641558974981308,\n",
       "   -0.45720750093460083,\n",
       "   -0.8054441213607788,\n",
       "   0.1793307363986969,\n",
       "   0.15573951601982117,\n",
       "   -0.690044105052948,\n",
       "   -0.8646297454833984,\n",
       "   0.017726732417941093,\n",
       "   0.4495229721069336,\n",
       "   0.1290213167667389,\n",
       "   0.02941494807600975,\n",
       "   -0.41788849234580994,\n",
       "   -0.9289348721504211,\n",
       "   -0.101957768201828,\n",
       "   0.6084110736846924,\n",
       "   0.432125449180603,\n",
       "   0.929113507270813,\n",
       "   0.2065196931362152,\n",
       "   -0.3832795023918152,\n",
       "   -0.4256152808666229,\n",
       "   0.36687445640563965,\n",
       "   0.2117030918598175,\n",
       "   -0.32189449667930603,\n",
       "   -0.06801055371761322,\n",
       "   0.816749095916748,\n",
       "   -0.8004109263420105,\n",
       "   -0.4417020082473755,\n",
       "   0.10943325608968735,\n",
       "   0.4414340555667877,\n",
       "   0.027043893933296204,\n",
       "   0.2870956063270569,\n",
       "   0.6720619201660156,\n",
       "   -0.3309503197669983,\n",
       "   -0.13923095166683197,\n",
       "   -0.17923924326896667,\n",
       "   -0.20718447864055634,\n",
       "   -0.593424379825592,\n",
       "   0.39826253056526184,\n",
       "   0.34034639596939087,\n",
       "   0.37109875679016113,\n",
       "   0.5869454741477966,\n",
       "   -0.25033727288246155,\n",
       "   -0.045658178627491,\n",
       "   0.2943035662174225,\n",
       "   -0.042825501412153244,\n",
       "   0.08487336337566376,\n",
       "   0.0033758655190467834,\n",
       "   -0.5816295146942139,\n",
       "   -0.4255847632884979,\n",
       "   -0.8120573163032532,\n",
       "   0.368143767118454,\n",
       "   0.19108764827251434,\n",
       "   -0.11617852747440338,\n",
       "   0.07442275434732437,\n",
       "   0.7113636136054993,\n",
       "   0.02057773619890213,\n",
       "   0.10173349827528,\n",
       "   -0.25851720571517944,\n",
       "   -0.27524495124816895,\n",
       "   0.7057340145111084,\n",
       "   -0.16671222448349,\n",
       "   0.7026982307434082,\n",
       "   0.24384014308452606,\n",
       "   0.22864937782287598,\n",
       "   0.4956298768520355,\n",
       "   0.03412812575697899,\n",
       "   0.2661135196685791,\n",
       "   -0.8581228852272034,\n",
       "   -0.598128616809845,\n",
       "   -0.16396836936473846,\n",
       "   -0.7556723356246948,\n",
       "   1.1436423063278198,\n",
       "   0.6421601176261902,\n",
       "   -0.14176638424396515,\n",
       "   0.3296540677547455,\n",
       "   -0.13548128306865692,\n",
       "   0.1995747983455658,\n",
       "   -0.5034221410751343,\n",
       "   0.053520768880844116,\n",
       "   0.01763051562011242,\n",
       "   -0.3596130311489105,\n",
       "   0.664592981338501,\n",
       "   0.2530266344547272,\n",
       "   0.06915070861577988,\n",
       "   0.011064525693655014,\n",
       "   -0.537877082824707,\n",
       "   -0.1893230676651001,\n",
       "   -0.617563009262085,\n",
       "   -0.46692582964897156,\n",
       "   -0.19377501308918,\n",
       "   -0.149568110704422,\n",
       "   0.5020915269851685,\n",
       "   -0.05263768881559372,\n",
       "   -0.2801874279975891,\n",
       "   0.012996217235922813,\n",
       "   -0.32456690073013306,\n",
       "   0.400369256734848,\n",
       "   -0.40532946586608887,\n",
       "   0.2950291037559509,\n",
       "   -0.49430710077285767,\n",
       "   -0.5423139929771423,\n",
       "   0.22408755123615265,\n",
       "   0.11603904515504837,\n",
       "   -0.5689136981964111,\n",
       "   -0.01866840198636055,\n",
       "   0.38807451725006104,\n",
       "   -0.936180830001831,\n",
       "   -0.10599876940250397,\n",
       "   0.059381045401096344,\n",
       "   -0.2967402935028076,\n",
       "   0.004020454362034798,\n",
       "   -0.20537905395030975,\n",
       "   0.016712484881281853,\n",
       "   -0.15540973842144012,\n",
       "   0.39719483256340027,\n",
       "   0.18512816727161407,\n",
       "   0.1493317037820816,\n",
       "   0.057577285915613174,\n",
       "   -0.28765708208084106,\n",
       "   0.008051348850131035,\n",
       "   0.027041852474212646,\n",
       "   -0.005632784217596054,\n",
       "   0.1800694316625595,\n",
       "   -0.2556428611278534,\n",
       "   0.3062494397163391,\n",
       "   0.36296433210372925,\n",
       "   -0.16387347877025604,\n",
       "   -0.4133525490760803,\n",
       "   -0.4740705192089081,\n",
       "   0.10429821908473969,\n",
       "   -1.0614465475082397,\n",
       "   -0.1726626306772232,\n",
       "   0.5136646032333374,\n",
       "   -0.2619130611419678,\n",
       "   -0.19541755318641663,\n",
       "   -0.41080108284950256,\n",
       "   -0.44588127732276917,\n",
       "   -0.5067089796066284,\n",
       "   -0.11363214999437332,\n",
       "   0.20825599133968353,\n",
       "   0.45370638370513916,\n",
       "   0.0608300119638443,\n",
       "   0.4465947449207306,\n",
       "   -0.21335692703723907,\n",
       "   -0.10864055156707764,\n",
       "   0.3098311722278595,\n",
       "   -0.25895801186561584,\n",
       "   -0.08539601415395737,\n",
       "   -0.2889077961444855,\n",
       "   -0.23519107699394226,\n",
       "   0.2667591869831085,\n",
       "   0.0400092750787735,\n",
       "   -0.2449893206357956,\n",
       "   0.5467660427093506,\n",
       "   -0.6734578609466553,\n",
       "   0.052415620535612106,\n",
       "   0.014710014685988426,\n",
       "   0.735084056854248,\n",
       "   -0.022676412016153336,\n",
       "   0.6968940496444702,\n",
       "   -0.3963639736175537,\n",
       "   0.18063250184059143,\n",
       "   0.3011068105697632,\n",
       "   -0.1602669507265091,\n",
       "   0.11609099805355072,\n",
       "   0.5715015530586243,\n",
       "   0.5019259452819824,\n",
       "   0.197291761636734,\n",
       "   -0.059395089745521545,\n",
       "   -0.018326178193092346,\n",
       "   0.441751092672348,\n",
       "   1.211625576019287,\n",
       "   -0.217563658952713,\n",
       "   -0.26283693313598633,\n",
       "   -0.014537877403199673,\n",
       "   -0.24284908175468445,\n",
       "   0.04795234277844429,\n",
       "   0.29019832611083984,\n",
       "   0.5726795792579651,\n",
       "   -0.06537160277366638,\n",
       "   0.3040163516998291,\n",
       "   0.2442750781774521,\n",
       "   -0.48233047127723694,\n",
       "   0.44525957107543945,\n",
       "   0.2958154082298279,\n",
       "   0.17658838629722595,\n",
       "   -0.4986926317214966,\n",
       "   0.5181302428245544,\n",
       "   0.7352660298347473,\n",
       "   -1.1309130191802979,\n",
       "   -0.3840610682964325,\n",
       "   0.15500736236572266,\n",
       "   -0.15105117857456207,\n",
       "   0.36084169149398804,\n",
       "   0.06563346087932587,\n",
       "   0.34567517042160034,\n",
       "   0.19846883416175842,\n",
       "   0.227636456489563,\n",
       "   0.24700482189655304,\n",
       "   0.23642152547836304,\n",
       "   0.7152195572853088,\n",
       "   -0.04190099239349365,\n",
       "   0.07639189809560776,\n",
       "   0.07780705392360687,\n",
       "   0.42665785551071167,\n",
       "   -0.2673599421977997,\n",
       "   0.5906210541725159,\n",
       "   -0.44363918900489807,\n",
       "   -0.03898131474852562,\n",
       "   -0.19994159042835236,\n",
       "   -0.11708729714155197,\n",
       "   -0.5476467609405518,\n",
       "   0.40558722615242004,\n",
       "   0.5102976560592651,\n",
       "   -0.7016052603721619,\n",
       "   0.5713556408882141,\n",
       "   0.42322662472724915,\n",
       "   0.889711856842041,\n",
       "   1.1133767366409302,\n",
       "   0.6145329475402832,\n",
       "   0.30903586745262146,\n",
       "   0.125810906291008,\n",
       "   -0.1406499743461609,\n",
       "   0.6489725708961487,\n",
       "   0.30116432905197144,\n",
       "   0.02331439033150673,\n",
       "   0.48735514283180237,\n",
       "   -0.366152822971344,\n",
       "   -0.04659776762127876,\n",
       "   0.1930113285779953,\n",
       "   0.4896157383918762,\n",
       "   -0.2950446605682373,\n",
       "   0.453525185585022,\n",
       "   -0.5274980664253235,\n",
       "   0.6943792700767517,\n",
       "   0.6554934978485107,\n",
       "   0.3074730634689331,\n",
       "   0.3254911005496979,\n",
       "   -0.8065142035484314,\n",
       "   0.4044750928878784,\n",
       "   0.3512543737888336,\n",
       "   0.29720577597618103,\n",
       "   -0.31371891498565674,\n",
       "   -0.027178291231393814,\n",
       "   -0.0585591197013855,\n",
       "   0.14376699924468994,\n",
       "   0.1059778556227684,\n",
       "   0.3922487795352936,\n",
       "   -0.5466864109039307,\n",
       "   -0.4395630359649658,\n",
       "   -0.022378798574209213,\n",
       "   -0.29356276988983154,\n",
       "   -0.5430235862731934,\n",
       "   0.07031422108411789,\n",
       "   0.4255984127521515,\n",
       "   -0.19828614592552185,\n",
       "   -0.1625438630580902,\n",
       "   -0.3310619592666626,\n",
       "   -0.3379283547401428,\n",
       "   -0.344658762216568,\n",
       "   0.0933493971824646,\n",
       "   0.19034694135189056,\n",
       "   0.061006516218185425,\n",
       "   -0.22282247245311737,\n",
       "   0.34969231486320496,\n",
       "   -0.04752063378691673,\n",
       "   -0.2516229748725891,\n",
       "   -0.4822014272212982,\n",
       "   -0.8326678276062012,\n",
       "   0.057095713913440704,\n",
       "   -0.3578113317489624,\n",
       "   -0.16456884145736694,\n",
       "   0.48294997215270996,\n",
       "   0.599619448184967,\n",
       "   -0.0494426004588604,\n",
       "   -0.02185642719268799,\n",
       "   -0.641651451587677,\n",
       "   -0.12273482978343964,\n",
       "   0.09375963360071182,\n",
       "   -0.2964692711830139,\n",
       "   -0.14332889020442963,\n",
       "   -0.5130797028541565,\n",
       "   0.16409087181091309,\n",
       "   -0.5142015218734741,\n",
       "   -0.14494964480400085,\n",
       "   -0.012086272239685059,\n",
       "   0.4028058648109436,\n",
       "   -0.42504867911338806,\n",
       "   0.46296319365501404,\n",
       "   -0.010473750531673431,\n",
       "   0.06221144646406174,\n",
       "   0.290118545293808,\n",
       "   -0.464030385017395,\n",
       "   -0.17370069026947021,\n",
       "   -0.03886650502681732,\n",
       "   0.6201505661010742,\n",
       "   -0.4298231303691864,\n",
       "   -0.31763947010040283,\n",
       "   0.1061384528875351,\n",
       "   -0.008710470050573349,\n",
       "   -1.2643464803695679,\n",
       "   -0.11668167263269424,\n",
       "   0.21385109424591064,\n",
       "   -0.5942903757095337,\n",
       "   -0.3230690360069275,\n",
       "   -0.2536657452583313,\n",
       "   0.3809940218925476,\n",
       "   0.20046575367450714,\n",
       "   -0.7745881080627441,\n",
       "   0.26333269476890564,\n",
       "   -0.18171821534633636,\n",
       "   -0.3130057752132416,\n",
       "   0.2653304934501648,\n",
       "   -0.11808626353740692,\n",
       "   -0.7036099433898926,\n",
       "   1.0348535776138306,\n",
       "   0.019630691036581993,\n",
       "   -0.32053595781326294,\n",
       "   0.26400256156921387,\n",
       "   0.5325738787651062,\n",
       "   -0.6883054971694946,\n",
       "   -0.4853827655315399,\n",
       "   -0.4567992091178894,\n",
       "   -0.022025711834430695,\n",
       "   -0.26386016607284546,\n",
       "   0.7046657204627991,\n",
       "   -0.21757659316062927,\n",
       "   0.06321946531534195,\n",
       "   -0.47394710779190063,\n",
       "   0.0871988907456398,\n",
       "   0.34013718366622925,\n",
       "   -0.31850939989089966,\n",
       "   -0.35024961829185486,\n",
       "   0.20919355750083923,\n",
       "   -0.44007548689842224],\n",
       "  [0.3317318558692932,\n",
       "   -0.14760231971740723,\n",
       "   0.2917342483997345,\n",
       "   0.015207907184958458,\n",
       "   0.31718260049819946,\n",
       "   -0.43235278129577637,\n",
       "   0.048156484961509705,\n",
       "   0.7011218070983887,\n",
       "   -0.32496246695518494,\n",
       "   0.024659980088472366,\n",
       "   0.3044080138206482,\n",
       "   -0.4290599822998047,\n",
       "   -0.28853052854537964,\n",
       "   0.6533060073852539,\n",
       "   -0.2286054641008377,\n",
       "   0.016124850139021873,\n",
       "   0.4535824954509735,\n",
       "   -0.41308876872062683,\n",
       "   -0.1720113605260849,\n",
       "   -0.04811327904462814,\n",
       "   0.14809343218803406,\n",
       "   -0.06093769893050194,\n",
       "   -0.439167857170105,\n",
       "   0.27217230200767517,\n",
       "   0.15002265572547913,\n",
       "   -0.006484057754278183,\n",
       "   -0.4013180136680603,\n",
       "   -0.18100354075431824,\n",
       "   -0.43266016244888306,\n",
       "   -0.40442612767219543,\n",
       "   0.5849912762641907,\n",
       "   -0.4595264494419098,\n",
       "   -0.3561379611492157,\n",
       "   0.18827199935913086,\n",
       "   -0.16734695434570312,\n",
       "   -0.4936251938343048,\n",
       "   0.1492997258901596,\n",
       "   0.030356325209140778,\n",
       "   -0.4520319700241089,\n",
       "   0.3123199939727783,\n",
       "   0.3755984306335449,\n",
       "   -0.451762855052948,\n",
       "   0.16624926030635834,\n",
       "   -0.08257321268320084,\n",
       "   0.22494809329509735,\n",
       "   0.12973622977733612,\n",
       "   1.425905704498291,\n",
       "   0.13083988428115845,\n",
       "   -0.3146008551120758,\n",
       "   -0.08615860342979431,\n",
       "   -0.4093363881111145,\n",
       "   0.1652166098356247,\n",
       "   0.0817314088344574,\n",
       "   0.05931731313467026,\n",
       "   -0.04025529325008392,\n",
       "   0.6871639490127563,\n",
       "   0.43354716897010803,\n",
       "   -0.29358038306236267,\n",
       "   -0.6536504626274109,\n",
       "   0.05173487961292267,\n",
       "   0.27610132098197937,\n",
       "   -0.5079457759857178,\n",
       "   -0.23873403668403625,\n",
       "   -0.34958866238594055,\n",
       "   -0.1930488795042038,\n",
       "   -0.22722627222537994,\n",
       "   0.4596048593521118,\n",
       "   0.02022906206548214,\n",
       "   -0.31232085824012756,\n",
       "   0.14788289368152618,\n",
       "   -0.4620908498764038,\n",
       "   -0.16346469521522522,\n",
       "   0.23702511191368103,\n",
       "   0.1067693829536438,\n",
       "   -0.2800333499908447,\n",
       "   0.0826539546251297,\n",
       "   0.27650654315948486,\n",
       "   0.1821957230567932,\n",
       "   0.3315005898475647,\n",
       "   -0.030705805867910385,\n",
       "   0.05436711758375168,\n",
       "   1.0086755752563477,\n",
       "   -0.6759344339370728,\n",
       "   0.6779497861862183,\n",
       "   -0.019814802333712578,\n",
       "   -0.11085241287946701,\n",
       "   -0.5813220739364624,\n",
       "   -0.31388577818870544,\n",
       "   -0.09891842305660248,\n",
       "   0.8113218545913696,\n",
       "   -0.24499915540218353,\n",
       "   -0.1824658215045929,\n",
       "   0.043584711849689484,\n",
       "   0.2504883110523224,\n",
       "   -0.08567389100790024,\n",
       "   -0.493426650762558,\n",
       "   -0.28277623653411865,\n",
       "   0.28138500452041626,\n",
       "   0.10523150116205215,\n",
       "   0.6257506012916565,\n",
       "   -0.2091679722070694,\n",
       "   -0.6968843936920166,\n",
       "   0.3917941451072693,\n",
       "   0.4919678270816803,\n",
       "   0.2092665135860443,\n",
       "   0.12332652509212494,\n",
       "   0.2534359097480774,\n",
       "   0.056200794875621796,\n",
       "   0.12258988618850708,\n",
       "   0.256102055311203,\n",
       "   -0.1130916029214859,\n",
       "   -0.8602525591850281,\n",
       "   0.05205158889293671,\n",
       "   0.23080766201019287,\n",
       "   0.11325653642416,\n",
       "   0.33329612016677856,\n",
       "   -0.16560223698616028,\n",
       "   0.02842577174305916,\n",
       "   0.24168628454208374,\n",
       "   -0.15787237882614136,\n",
       "   -0.5899459719657898,\n",
       "   0.004944369196891785,\n",
       "   -0.07244222611188889,\n",
       "   0.6897001266479492,\n",
       "   -0.14732538163661957,\n",
       "   0.2385859489440918,\n",
       "   -0.8697158694267273,\n",
       "   -0.2704547643661499,\n",
       "   -0.3353561460971832,\n",
       "   -0.6275166273117065,\n",
       "   0.36643272638320923,\n",
       "   1.0614275932312012,\n",
       "   0.2339794784784317,\n",
       "   -0.44112733006477356,\n",
       "   -0.46262580156326294,\n",
       "   0.5962971448898315,\n",
       "   0.256439208984375,\n",
       "   -0.3823230564594269,\n",
       "   -0.37450283765792847,\n",
       "   -0.2784867286682129,\n",
       "   0.16376851499080658,\n",
       "   0.02675556391477585,\n",
       "   0.8475707173347473,\n",
       "   0.3130795955657959,\n",
       "   0.14655882120132446,\n",
       "   -0.38947588205337524,\n",
       "   -0.15951503813266754,\n",
       "   -0.6319993138313293,\n",
       "   0.03305257111787796,\n",
       "   -0.09828539937734604,\n",
       "   -0.4282074272632599,\n",
       "   0.05831949785351753,\n",
       "   -0.1418740302324295,\n",
       "   -0.19506919384002686,\n",
       "   -0.27826496958732605,\n",
       "   -0.18550124764442444,\n",
       "   -0.387568861246109,\n",
       "   0.011555388569831848,\n",
       "   0.6255830526351929,\n",
       "   0.13028618693351746,\n",
       "   0.5018248558044434,\n",
       "   -0.02209431305527687,\n",
       "   -0.32399559020996094,\n",
       "   0.9020145535469055,\n",
       "   -0.13053305447101593,\n",
       "   0.33745336532592773,\n",
       "   0.11871686577796936,\n",
       "   0.8785542249679565,\n",
       "   0.3701123595237732,\n",
       "   0.13187207281589508,\n",
       "   -0.40217357873916626,\n",
       "   0.237424835562706,\n",
       "   1.227391242980957,\n",
       "   -0.31429702043533325,\n",
       "   -1.0812016725540161,\n",
       "   0.40995901823043823,\n",
       "   0.19382432103157043,\n",
       "   -0.22096630930900574,\n",
       "   -0.0530695803463459,\n",
       "   0.23884330689907074,\n",
       "   -0.5156756639480591,\n",
       "   0.5546406507492065,\n",
       "   -0.03757485747337341,\n",
       "   -0.3408450186252594,\n",
       "   0.6781225204467773,\n",
       "   -0.22475846111774445,\n",
       "   0.6072321534156799,\n",
       "   -0.344142347574234,\n",
       "   -0.4555117189884186,\n",
       "   -0.08326844125986099,\n",
       "   -0.36196833848953247,\n",
       "   -0.3737996518611908,\n",
       "   -0.7415778636932373,\n",
       "   -0.32935357093811035,\n",
       "   -0.13454630970954895,\n",
       "   -0.7498573064804077,\n",
       "   -0.13282570242881775,\n",
       "   -0.03301641345024109,\n",
       "   -0.004978813696652651,\n",
       "   0.038393355906009674,\n",
       "   0.2529624402523041,\n",
       "   -0.13657265901565552,\n",
       "   0.25536876916885376,\n",
       "   0.018183458596467972,\n",
       "   -0.17552150785923004,\n",
       "   -0.02949068695306778,\n",
       "   0.23832370340824127,\n",
       "   0.006882555782794952,\n",
       "   -0.22608508169651031,\n",
       "   0.4671608805656433,\n",
       "   -0.8548489212989807,\n",
       "   0.6825327277183533,\n",
       "   -0.3757975399494171,\n",
       "   0.6965552568435669,\n",
       "   0.06906954944133759,\n",
       "   -0.2869580090045929,\n",
       "   0.4962531626224518,\n",
       "   0.5295525193214417,\n",
       "   -0.2443913370370865,\n",
       "   0.22830477356910706,\n",
       "   -0.028975194320082664,\n",
       "   -0.17765364050865173,\n",
       "   -0.3625631034374237,\n",
       "   0.6872934103012085,\n",
       "   -0.5099121332168579,\n",
       "   0.24987924098968506,\n",
       "   0.3443548381328583,\n",
       "   -0.7010412216186523,\n",
       "   0.05874002352356911,\n",
       "   0.5633983016014099,\n",
       "   0.3044058680534363,\n",
       "   -0.43352702260017395,\n",
       "   0.6160156726837158,\n",
       "   0.0429522730410099,\n",
       "   -0.10332375764846802,\n",
       "   0.5279540419578552,\n",
       "   -0.020213117823004723,\n",
       "   -0.030484125018119812,\n",
       "   -0.32307350635528564,\n",
       "   -0.3058355748653412,\n",
       "   -0.37680089473724365,\n",
       "   -0.05724669247865677,\n",
       "   1.2927467823028564,\n",
       "   0.07790790498256683,\n",
       "   0.5968144536018372,\n",
       "   0.6075120568275452,\n",
       "   0.41838550567626953,\n",
       "   0.07469669729471207,\n",
       "   -0.1473868489265442,\n",
       "   -0.43203404545783997,\n",
       "   0.01861179620027542,\n",
       "   -0.45798438787460327,\n",
       "   0.05269204080104828,\n",
       "   -0.7793026566505432,\n",
       "   -0.5357872247695923,\n",
       "   -0.7818389534950256,\n",
       "   -0.3216295540332794,\n",
       "   -0.565808117389679,\n",
       "   0.07102153450250626,\n",
       "   0.5780718326568604,\n",
       "   0.0031316354870796204,\n",
       "   0.014682766050100327,\n",
       "   0.46148014068603516,\n",
       "   -0.2851788103580475,\n",
       "   -0.3560577630996704,\n",
       "   -0.6382982730865479,\n",
       "   0.7701605558395386,\n",
       "   0.42253926396369934,\n",
       "   -0.10699264705181122,\n",
       "   0.12908636033535004,\n",
       "   0.22708386182785034,\n",
       "   -0.11591557413339615,\n",
       "   -0.037628475576639175,\n",
       "   0.9827037453651428,\n",
       "   -0.5540292263031006,\n",
       "   -0.5099261999130249,\n",
       "   0.13567575812339783,\n",
       "   0.23219598829746246,\n",
       "   -0.1296442747116089,\n",
       "   -0.2934624254703522,\n",
       "   0.46684372425079346,\n",
       "   0.6657198667526245,\n",
       "   -0.43521711230278015,\n",
       "   0.20016995072364807,\n",
       "   0.008180524222552776,\n",
       "   -0.34902361035346985,\n",
       "   0.09581127762794495,\n",
       "   -0.35003310441970825,\n",
       "   -0.4201149344444275,\n",
       "   -0.464263916015625,\n",
       "   -0.20012438297271729,\n",
       "   -0.03175917640328407,\n",
       "   -0.30329471826553345,\n",
       "   0.07934342324733734,\n",
       "   0.7642296552658081,\n",
       "   0.13091127574443817,\n",
       "   0.19259990751743317,\n",
       "   -0.22278845310211182,\n",
       "   -0.03625050187110901,\n",
       "   -0.34538331627845764,\n",
       "   -0.39649808406829834,\n",
       "   0.018105212599039078,\n",
       "   0.4067366421222687,\n",
       "   -0.08965884149074554,\n",
       "   0.19014035165309906,\n",
       "   0.04404691606760025,\n",
       "   0.09254449605941772,\n",
       "   -0.2298414260149002,\n",
       "   -3.978461503982544,\n",
       "   0.05238734185695648,\n",
       "   -0.44159358739852905,\n",
       "   -0.35640355944633484,\n",
       "   0.18972915410995483,\n",
       "   -0.32993584871292114,\n",
       "   -0.050437185913324356,\n",
       "   -0.11645415425300598,\n",
       "   -1.085274338722229,\n",
       "   -0.3536229729652405,\n",
       "   -0.2895049452781677,\n",
       "   0.06927567720413208,\n",
       "   0.7523030042648315,\n",
       "   0.9378073215484619,\n",
       "   0.618334174156189,\n",
       "   -0.6157343983650208,\n",
       "   0.001790158450603485,\n",
       "   -0.16094692051410675,\n",
       "   -0.4394761919975281,\n",
       "   0.744030773639679,\n",
       "   -0.15303342044353485,\n",
       "   -0.4264731705188751,\n",
       "   0.3895372748374939,\n",
       "   -0.0010912660509347916,\n",
       "   1.0822206735610962,\n",
       "   0.35108235478401184,\n",
       "   0.43457871675491333,\n",
       "   0.33419376611709595,\n",
       "   -0.17966891825199127,\n",
       "   -0.35851094126701355,\n",
       "   0.015608873218297958,\n",
       "   -0.44734707474708557,\n",
       "   0.12885572016239166,\n",
       "   0.44200393557548523,\n",
       "   0.3394230902194977,\n",
       "   0.373024046421051,\n",
       "   -0.1522870659828186,\n",
       "   -0.6959242224693298,\n",
       "   0.6788193583488464,\n",
       "   0.5361429452896118,\n",
       "   0.1950121968984604,\n",
       "   -0.5458524227142334,\n",
       "   -0.05353976786136627,\n",
       "   0.49630483984947205,\n",
       "   1.0376898050308228,\n",
       "   -0.41963523626327515,\n",
       "   0.030685298144817352,\n",
       "   -0.6197600364685059,\n",
       "   0.2689262330532074,\n",
       "   -0.042973924428224564,\n",
       "   1.01119065284729,\n",
       "   -0.03717400133609772,\n",
       "   -0.07365169376134872,\n",
       "   -0.5197334289550781,\n",
       "   -0.41414695978164673,\n",
       "   -0.48942747712135315,\n",
       "   0.2811424732208252,\n",
       "   0.9974077939987183,\n",
       "   -0.42490559816360474,\n",
       "   -0.6288697123527527,\n",
       "   0.31393441557884216,\n",
       "   -0.4852454662322998,\n",
       "   -0.4979391098022461,\n",
       "   0.06475374102592468,\n",
       "   -0.7388432025909424,\n",
       "   -0.006390556693077087,\n",
       "   -0.01901962049305439,\n",
       "   -0.40033772587776184,\n",
       "   0.16666577756404877,\n",
       "   0.4115447402000427,\n",
       "   0.30484551191329956,\n",
       "   0.5964621305465698,\n",
       "   -0.6261074542999268,\n",
       "   -0.9625833034515381,\n",
       "   -0.007687289267778397,\n",
       "   0.8915245532989502,\n",
       "   -0.5902165174484253,\n",
       "   -0.2560213804244995,\n",
       "   0.09073922038078308,\n",
       "   0.10352274775505066,\n",
       "   -0.2970298230648041,\n",
       "   -0.7842528820037842,\n",
       "   -0.39753013849258423,\n",
       "   0.05858919769525528,\n",
       "   0.1971621811389923,\n",
       "   -0.8326495289802551,\n",
       "   0.009805819019675255,\n",
       "   -1.1349250078201294,\n",
       "   0.14066344499588013,\n",
       "   0.15784426033496857,\n",
       "   -0.29177218675613403,\n",
       "   0.09527567028999329,\n",
       "   0.27686089277267456,\n",
       "   0.04850499704480171,\n",
       "   1.058138370513916,\n",
       "   -0.3004399538040161,\n",
       "   -0.006030302494764328,\n",
       "   -0.3371067941188812,\n",
       "   0.2473362684249878,\n",
       "   -0.5804904699325562,\n",
       "   0.2968946695327759,\n",
       "   -0.1119677945971489,\n",
       "   0.25409457087516785,\n",
       "   -0.09028121083974838,\n",
       "   0.05040084198117256,\n",
       "   -0.14374470710754395,\n",
       "   -0.4321698248386383,\n",
       "   0.27081841230392456,\n",
       "   -0.3556792736053467,\n",
       "   0.41988617181777954,\n",
       "   0.331110417842865,\n",
       "   0.32256487011909485,\n",
       "   0.8668009042739868,\n",
       "   0.026825115084648132,\n",
       "   -0.4661736786365509,\n",
       "   -0.4894815683364868,\n",
       "   0.3302694857120514,\n",
       "   0.7788205742835999,\n",
       "   -0.1854756474494934,\n",
       "   -0.16875144839286804,\n",
       "   -0.30021563172340393,\n",
       "   0.5456792712211609,\n",
       "   -0.5007171034812927,\n",
       "   -0.43736129999160767,\n",
       "   -0.31557589769363403,\n",
       "   -0.3080998957157135,\n",
       "   -0.5111977458000183,\n",
       "   -1.1245160102844238,\n",
       "   -0.29898884892463684,\n",
       "   0.1782861053943634,\n",
       "   -0.5061883330345154,\n",
       "   -0.10479749739170074,\n",
       "   0.31687667965888977,\n",
       "   0.0029343105852603912,\n",
       "   0.03970431536436081,\n",
       "   -0.4167097508907318,\n",
       "   0.23289412260055542,\n",
       "   -0.8156750202178955,\n",
       "   -0.17707300186157227,\n",
       "   0.8682206273078918,\n",
       "   0.4157797396183014,\n",
       "   0.7208544015884399,\n",
       "   0.2823023498058319,\n",
       "   -0.2012750506401062,\n",
       "   -0.5144230723381042,\n",
       "   1.0326666831970215,\n",
       "   -0.3538489043712616,\n",
       "   0.40709954500198364,\n",
       "   -0.4067366421222687,\n",
       "   0.9560572504997253,\n",
       "   -0.13959860801696777,\n",
       "   -0.4739132821559906,\n",
       "   -0.2471809834241867,\n",
       "   -0.053064145147800446,\n",
       "   0.3961836099624634,\n",
       "   -0.16888129711151123,\n",
       "   0.4156043827533722,\n",
       "   -0.4539104998111725,\n",
       "   0.17491373419761658,\n",
       "   -0.2712192237377167,\n",
       "   -0.1583278775215149,\n",
       "   -0.2514226734638214,\n",
       "   0.820317268371582,\n",
       "   0.5249963998794556,\n",
       "   -0.19367839395999908,\n",
       "   0.4325520098209381,\n",
       "   -0.29148632287979126,\n",
       "   0.1291026920080185,\n",
       "   -0.4116446077823639,\n",
       "   0.2944376766681671,\n",
       "   0.2068892866373062,\n",
       "   -0.02831442654132843,\n",
       "   -0.08459754288196564,\n",
       "   0.3089059293270111,\n",
       "   -0.598580002784729,\n",
       "   0.40525248646736145,\n",
       "   0.058920156210660934,\n",
       "   -0.5949394702911377,\n",
       "   -0.4005624055862427,\n",
       "   0.403268039226532,\n",
       "   0.1989118903875351,\n",
       "   -0.4492870569229126,\n",
       "   -0.029454709962010384,\n",
       "   -0.22458124160766602,\n",
       "   1.0067862272262573,\n",
       "   0.3275386393070221,\n",
       "   0.27472034096717834,\n",
       "   0.26557448506355286,\n",
       "   0.21857067942619324,\n",
       "   0.6680426001548767,\n",
       "   0.029219454154372215,\n",
       "   0.2619984745979309,\n",
       "   -0.3468133509159088,\n",
       "   -0.10145944356918335,\n",
       "   0.1819513887166977,\n",
       "   -0.073030985891819,\n",
       "   0.849355936050415,\n",
       "   0.034091271460056305,\n",
       "   0.18890535831451416,\n",
       "   0.07628960907459259,\n",
       "   0.09378299862146378,\n",
       "   -0.7042387127876282,\n",
       "   -0.21866530179977417,\n",
       "   -0.23867791891098022,\n",
       "   0.03335956484079361,\n",
       "   -0.1533338874578476,\n",
       "   0.07086178660392761,\n",
       "   0.5349070429801941,\n",
       "   -0.009611211717128754,\n",
       "   0.2237916737794876,\n",
       "   -0.172796830534935,\n",
       "   -0.4975901246070862,\n",
       "   -0.14359506964683533,\n",
       "   -0.5404967665672302,\n",
       "   -0.4666302800178528,\n",
       "   0.8337979912757874,\n",
       "   0.17911729216575623,\n",
       "   0.02827594429254532,\n",
       "   -0.12623447179794312,\n",
       "   -0.3449068069458008,\n",
       "   -0.08484505861997604,\n",
       "   -0.13099126517772675,\n",
       "   -0.12083142250776291,\n",
       "   0.07072514295578003,\n",
       "   -0.7770748734474182,\n",
       "   -0.2224072366952896,\n",
       "   -0.37593358755111694,\n",
       "   -0.5397971272468567,\n",
       "   -0.35382112860679626,\n",
       "   0.06356508284807205,\n",
       "   0.5783429741859436,\n",
       "   -0.9137290120124817,\n",
       "   -0.36328795552253723,\n",
       "   -0.05457562208175659,\n",
       "   -0.2355312705039978,\n",
       "   0.2389535754919052,\n",
       "   -0.500757098197937,\n",
       "   0.16330558061599731,\n",
       "   -0.013134157285094261,\n",
       "   -0.012819427996873856,\n",
       "   -0.5286372303962708,\n",
       "   -0.5129386782646179,\n",
       "   -0.5098450183868408,\n",
       "   -0.29139214754104614,\n",
       "   0.16917696595191956,\n",
       "   0.20367614924907684,\n",
       "   -0.42666932940483093,\n",
       "   0.5969705581665039,\n",
       "   -0.1509532481431961,\n",
       "   0.4820476472377777,\n",
       "   -0.10822628438472748,\n",
       "   0.19633817672729492,\n",
       "   -0.11340176314115524,\n",
       "   -0.29648885130882263,\n",
       "   -0.21059031784534454,\n",
       "   -0.32796645164489746,\n",
       "   -0.5821835994720459,\n",
       "   0.0067047178745269775,\n",
       "   0.011266611516475677,\n",
       "   -0.38715794682502747,\n",
       "   -0.11694206297397614,\n",
       "   0.2918761074542999,\n",
       "   -0.411124050617218,\n",
       "   0.14641115069389343,\n",
       "   0.15493175387382507,\n",
       "   0.6975361704826355,\n",
       "   -0.3818560838699341,\n",
       "   0.6227895021438599,\n",
       "   0.678913950920105,\n",
       "   0.09758304059505463,\n",
       "   -0.23878058791160583,\n",
       "   -0.2561790645122528,\n",
       "   -0.007019490003585815,\n",
       "   0.13322249054908752,\n",
       "   -0.2724810540676117,\n",
       "   -0.43844228982925415,\n",
       "   0.36762434244155884,\n",
       "   -0.8532986640930176,\n",
       "   0.39078763127326965,\n",
       "   0.1218360885977745,\n",
       "   -0.1440868228673935,\n",
       "   0.49657532572746277,\n",
       "   0.3750816583633423,\n",
       "   -0.14624792337417603,\n",
       "   -0.05547972768545151,\n",
       "   -0.36368000507354736,\n",
       "   0.01926271803677082,\n",
       "   0.2813430428504944,\n",
       "   0.11427243053913116,\n",
       "   -0.3610742390155792,\n",
       "   0.579328715801239,\n",
       "   0.5429686903953552,\n",
       "   -0.057895127683877945,\n",
       "   0.1810912787914276,\n",
       "   0.08164005726575851,\n",
       "   0.09205734729766846,\n",
       "   0.37802940607070923,\n",
       "   0.2264793962240219,\n",
       "   -0.3079533576965332,\n",
       "   0.009088458493351936,\n",
       "   -0.3540329933166504,\n",
       "   -0.47092360258102417,\n",
       "   0.42341411113739014,\n",
       "   -0.17401030659675598,\n",
       "   -0.09002389758825302,\n",
       "   0.46456876397132874,\n",
       "   0.25159499049186707,\n",
       "   -0.15534260869026184,\n",
       "   0.49708259105682373,\n",
       "   0.2894684672355652,\n",
       "   0.33452466130256653,\n",
       "   -0.5831875801086426,\n",
       "   0.37762516736984253,\n",
       "   1.2795000076293945,\n",
       "   -0.6121264100074768,\n",
       "   -0.44909724593162537,\n",
       "   -0.10910522937774658,\n",
       "   -0.1253519505262375,\n",
       "   0.07959979772567749,\n",
       "   0.5160841345787048,\n",
       "   0.43752992153167725,\n",
       "   -0.12753871083259583,\n",
       "   0.5795900225639343,\n",
       "   0.3091968595981598,\n",
       "   0.1546114683151245,\n",
       "   0.11622628569602966,\n",
       "   -0.07423999160528183,\n",
       "   -0.27059465646743774,\n",
       "   -0.05300283804535866,\n",
       "   0.1187405064702034,\n",
       "   -0.198867067694664,\n",
       "   -0.08480051904916763,\n",
       "   -0.5001444220542908,\n",
       "   0.04867985099554062,\n",
       "   0.42800578474998474,\n",
       "   -0.24241003394126892,\n",
       "   0.5409319400787354,\n",
       "   0.1230061948299408,\n",
       "   -0.09483549743890762,\n",
       "   -0.6389994621276855,\n",
       "   0.4031968116760254,\n",
       "   -0.07017336040735245,\n",
       "   0.7735742926597595,\n",
       "   0.6288004517555237,\n",
       "   0.17174707353115082,\n",
       "   0.30687087774276733,\n",
       "   -0.007844790816307068,\n",
       "   -0.5127319693565369,\n",
       "   0.5231642127037048,\n",
       "   0.985168993473053,\n",
       "   -0.05590539798140526,\n",
       "   0.23605704307556152,\n",
       "   0.04367527738213539,\n",
       "   -0.25503766536712646,\n",
       "   0.36142268776893616,\n",
       "   -0.9750217199325562,\n",
       "   0.3290994167327881,\n",
       "   0.3027457296848297,\n",
       "   -0.5609652996063232,\n",
       "   0.7853283286094666,\n",
       "   0.1896095722913742,\n",
       "   0.22181424498558044,\n",
       "   0.011510593816637993,\n",
       "   -0.6405981779098511,\n",
       "   -0.059358593076467514,\n",
       "   0.1359306126832962,\n",
       "   0.5337148308753967,\n",
       "   -0.534540057182312,\n",
       "   -0.15644843876361847,\n",
       "   -0.13447050750255585,\n",
       "   0.07632721215486526,\n",
       "   0.5966642498970032,\n",
       "   -0.31202420592308044,\n",
       "   -0.19813112914562225,\n",
       "   -0.10682164877653122,\n",
       "   -0.09586793929338455,\n",
       "   -0.4644310176372528,\n",
       "   0.1250225007534027,\n",
       "   -0.23038963973522186,\n",
       "   -0.3262402415275574,\n",
       "   0.3942582905292511,\n",
       "   0.35402730107307434,\n",
       "   -0.5268221497535706,\n",
       "   -0.012002874165773392,\n",
       "   0.3257617950439453,\n",
       "   -0.8368275761604309,\n",
       "   0.02859370969235897,\n",
       "   -0.3289143741130829,\n",
       "   0.2586776614189148,\n",
       "   -0.12636326253414154,\n",
       "   -0.010952692478895187,\n",
       "   -0.3205658495426178,\n",
       "   -0.8478936553001404,\n",
       "   -1.0994099378585815,\n",
       "   0.5464881062507629,\n",
       "   -0.3006657063961029,\n",
       "   -0.0019151940941810608,\n",
       "   0.05109532177448273,\n",
       "   0.691692590713501,\n",
       "   0.39934152364730835,\n",
       "   0.3180692493915558,\n",
       "   -0.9138911962509155,\n",
       "   0.3220108151435852,\n",
       "   0.01800818182528019,\n",
       "   -0.3650668263435364,\n",
       "   -0.047934629023075104,\n",
       "   -0.3057239055633545,\n",
       "   -0.017717808485031128,\n",
       "   -0.6262043714523315,\n",
       "   0.15438807010650635,\n",
       "   -0.3162233829498291,\n",
       "   0.9266977906227112,\n",
       "   -0.5050153732299805,\n",
       "   0.6012334823608398,\n",
       "   0.24367566406726837,\n",
       "   -0.05516532436013222,\n",
       "   0.14493902027606964,\n",
       "   -0.29675814509391785,\n",
       "   0.46639588475227356,\n",
       "   0.06996405869722366,\n",
       "   0.17178210616111755,\n",
       "   -0.14001978933811188,\n",
       "   -0.35145077109336853,\n",
       "   0.590992271900177,\n",
       "   -0.13572795689105988,\n",
       "   -0.5239264965057373,\n",
       "   -0.3197345435619354,\n",
       "   0.27767354249954224,\n",
       "   -0.019003769382834435,\n",
       "   0.051462672650814056,\n",
       "   -0.16235704720020294,\n",
       "   0.5413675308227539,\n",
       "   -0.3948077857494354,\n",
       "   -0.44149863719940186,\n",
       "   -0.2122604250907898,\n",
       "   0.169608935713768,\n",
       "   -0.23785564303398132,\n",
       "   -0.328805148601532,\n",
       "   -0.2579163610935211,\n",
       "   -0.6169048547744751,\n",
       "   0.1013762429356575,\n",
       "   0.11434152722358704,\n",
       "   0.15910597145557404,\n",
       "   -0.37865519523620605,\n",
       "   0.8348305821418762,\n",
       "   -0.47115737199783325,\n",
       "   -0.4560260772705078,\n",
       "   -0.1595674455165863,\n",
       "   0.05728592723608017,\n",
       "   -0.38224849104881287,\n",
       "   0.44615480303764343,\n",
       "   -0.09651751071214676,\n",
       "   0.013884030282497406,\n",
       "   -0.6688231229782104,\n",
       "   -0.09363418072462082,\n",
       "   -0.22884051501750946,\n",
       "   0.2478518784046173,\n",
       "   0.07431288063526154,\n",
       "   0.23877190053462982,\n",
       "   -0.20276455581188202],\n",
       "  [0.943461537361145,\n",
       "   0.11608611792325974,\n",
       "   -0.2994266748428345,\n",
       "   0.4918740391731262,\n",
       "   -0.23300287127494812,\n",
       "   -1.0280625820159912,\n",
       "   0.38709816336631775,\n",
       "   -0.22895342111587524,\n",
       "   0.3872263729572296,\n",
       "   -0.015509963035583496,\n",
       "   0.38548898696899414,\n",
       "   -0.09314706176519394,\n",
       "   -0.06949105113744736,\n",
       "   -0.23107808828353882,\n",
       "   -0.634285569190979,\n",
       "   -0.3611725866794586,\n",
       "   0.14673663675785065,\n",
       "   -0.1740371584892273,\n",
       "   0.3359517455101013,\n",
       "   0.14054521918296814,\n",
       "   0.5556771159172058,\n",
       "   -0.22225871682167053,\n",
       "   0.46925702691078186,\n",
       "   0.36480480432510376,\n",
       "   0.15960055589675903,\n",
       "   0.04045645520091057,\n",
       "   -0.37516582012176514,\n",
       "   -0.16948202252388,\n",
       "   -0.6006498336791992,\n",
       "   -0.5825848579406738,\n",
       "   -0.4953352212905884,\n",
       "   -0.3164556622505188,\n",
       "   -0.3951687514781952,\n",
       "   0.27290087938308716,\n",
       "   0.36867693066596985,\n",
       "   -0.1824922114610672,\n",
       "   0.34942078590393066,\n",
       "   -0.010029681026935577,\n",
       "   -0.3718984127044678,\n",
       "   -0.24208788573741913,\n",
       "   -0.4699947237968445,\n",
       "   0.3168238699436188,\n",
       "   -0.26832935214042664,\n",
       "   0.5779464840888977,\n",
       "   -0.16411742568016052,\n",
       "   -0.6103899478912354,\n",
       "   0.5361383557319641,\n",
       "   0.3860780596733093,\n",
       "   -0.2929719090461731,\n",
       "   0.6282216906547546,\n",
       "   0.13434430956840515,\n",
       "   0.4168674051761627,\n",
       "   -0.028579238802194595,\n",
       "   0.13786447048187256,\n",
       "   0.5319806337356567,\n",
       "   0.3949927091598511,\n",
       "   0.1558457911014557,\n",
       "   -0.7281001210212708,\n",
       "   0.13703006505966187,\n",
       "   0.22120974957942963,\n",
       "   0.20061269402503967,\n",
       "   0.6284506320953369,\n",
       "   -0.5340335965156555,\n",
       "   -0.4179953932762146,\n",
       "   0.2658272087574005,\n",
       "   0.19125796854496002,\n",
       "   -0.15720918774604797,\n",
       "   -0.3611920475959778,\n",
       "   -0.7756384611129761,\n",
       "   -0.3654683530330658,\n",
       "   -0.33499208092689514,\n",
       "   -0.8045902252197266,\n",
       "   0.6590431928634644,\n",
       "   0.27052995562553406,\n",
       "   0.15052253007888794,\n",
       "   0.6069876551628113,\n",
       "   -0.800435483455658,\n",
       "   0.6464406251907349,\n",
       "   0.2162020355463028,\n",
       "   0.43112900853157043,\n",
       "   0.23116102814674377,\n",
       "   0.3193066120147705,\n",
       "   -0.09496846795082092,\n",
       "   0.2759498953819275,\n",
       "   0.41032132506370544,\n",
       "   -0.2350785732269287,\n",
       "   -0.5718377828598022,\n",
       "   -0.24732476472854614,\n",
       "   -0.24602797627449036,\n",
       "   -0.10023725032806396,\n",
       "   0.2766475975513458,\n",
       "   0.27594640851020813,\n",
       "   0.34898310899734497,\n",
       "   -0.14443446695804596,\n",
       "   0.01048174686729908,\n",
       "   0.3996574580669403,\n",
       "   -0.14953836798667908,\n",
       "   0.0026801922358572483,\n",
       "   -0.19012080132961273,\n",
       "   0.11960157752037048,\n",
       "   0.2716744840145111,\n",
       "   -0.19547228515148163,\n",
       "   -0.025761350989341736,\n",
       "   1.166706919670105,\n",
       "   0.045124076306819916,\n",
       "   -0.20120152831077576,\n",
       "   0.14184817671775818,\n",
       "   0.32131701707839966,\n",
       "   0.41080334782600403,\n",
       "   1.1898133754730225,\n",
       "   0.7528562545776367,\n",
       "   -0.23754343390464783,\n",
       "   0.14640861749649048,\n",
       "   -0.14865531027317047,\n",
       "   -0.31838589906692505,\n",
       "   -0.5985737442970276,\n",
       "   0.3460594415664673,\n",
       "   0.024752847850322723,\n",
       "   0.34559187293052673,\n",
       "   -0.12335042655467987,\n",
       "   -0.7913087606430054,\n",
       "   -0.8252378702163696,\n",
       "   0.43924903869628906,\n",
       "   1.4061731100082397,\n",
       "   -0.1883515864610672,\n",
       "   0.07853573560714722,\n",
       "   -0.13369065523147583,\n",
       "   -0.7639078497886658,\n",
       "   -0.23336949944496155,\n",
       "   -0.797896683216095,\n",
       "   -0.6713739037513733,\n",
       "   0.501865565776825,\n",
       "   0.5001755952835083,\n",
       "   0.6203991174697876,\n",
       "   -0.3331546485424042,\n",
       "   0.3219620883464813,\n",
       "   0.04342564195394516,\n",
       "   0.12860648334026337,\n",
       "   -0.8621178269386292,\n",
       "   0.41548192501068115,\n",
       "   0.02386857196688652,\n",
       "   0.806086003780365,\n",
       "   0.4967600107192993,\n",
       "   -0.6280075311660767,\n",
       "   0.29963529109954834,\n",
       "   0.6138358116149902,\n",
       "   0.9387606978416443,\n",
       "   -0.13385140895843506,\n",
       "   0.4502496123313904,\n",
       "   -0.26917916536331177,\n",
       "   1.043113350868225,\n",
       "   -0.5042195916175842,\n",
       "   -0.37323689460754395,\n",
       "   -0.143290176987648,\n",
       "   -0.5022611618041992,\n",
       "   -0.06651722639799118,\n",
       "   -0.4064962565898895,\n",
       "   -0.28751781582832336,\n",
       "   0.6843509078025818,\n",
       "   0.9141200184822083,\n",
       "   0.2672286927700043,\n",
       "   0.14939120411872864,\n",
       "   0.03231595456600189,\n",
       "   0.34501907229423523,\n",
       "   -0.5542606711387634,\n",
       "   0.14886488020420074,\n",
       "   -0.5891343355178833,\n",
       "   0.15231993794441223,\n",
       "   0.19462674856185913,\n",
       "   0.45131659507751465,\n",
       "   -0.7416883707046509,\n",
       "   0.013751290738582611,\n",
       "   0.15084025263786316,\n",
       "   0.03181840479373932,\n",
       "   -0.29980626702308655,\n",
       "   0.17149262130260468,\n",
       "   0.036040663719177246,\n",
       "   0.002606468740850687,\n",
       "   -0.02854135073721409,\n",
       "   -0.5379797220230103,\n",
       "   -9.571796417236328,\n",
       "   -0.5343805551528931,\n",
       "   0.09435932338237762,\n",
       "   0.05685775354504585,\n",
       "   0.2577535808086395,\n",
       "   -0.2082631140947342,\n",
       "   -0.41678664088249207,\n",
       "   -0.21453851461410522,\n",
       "   -0.49451640248298645,\n",
       "   -0.8611323237419128,\n",
       "   -0.0007984787225723267,\n",
       "   -0.1921115517616272,\n",
       "   -0.490611732006073,\n",
       "   0.3236461281776428,\n",
       "   0.6615497469902039,\n",
       "   -0.3179340958595276,\n",
       "   -0.1218016967177391,\n",
       "   0.015011578798294067,\n",
       "   -0.40453943610191345,\n",
       "   0.07077424228191376,\n",
       "   -0.024288929998874664,\n",
       "   -0.11433674395084381,\n",
       "   0.1188850849866867,\n",
       "   0.5292394161224365,\n",
       "   -0.6012690663337708,\n",
       "   -1.5533350706100464,\n",
       "   0.2543477714061737,\n",
       "   -0.2648417353630066,\n",
       "   0.1154281347990036,\n",
       "   0.33077147603034973,\n",
       "   -1.2222652435302734,\n",
       "   0.10956397652626038,\n",
       "   0.0886305496096611,\n",
       "   -0.3705614507198334,\n",
       "   -0.07033427059650421,\n",
       "   -0.5390265583992004,\n",
       "   0.18480274081230164,\n",
       "   -0.43452516198158264,\n",
       "   -1.0446923971176147,\n",
       "   -0.3744191825389862,\n",
       "   -0.6172443628311157,\n",
       "   0.00579843670129776,\n",
       "   -0.46024367213249207,\n",
       "   0.08184297382831573,\n",
       "   0.5861852765083313,\n",
       "   -1.4738270044326782,\n",
       "   0.47439900040626526,\n",
       "   0.9363895058631897,\n",
       "   0.17175491154193878,\n",
       "   0.24829189479351044,\n",
       "   -0.0023233816027641296,\n",
       "   -0.27864405512809753,\n",
       "   0.780994176864624,\n",
       "   0.18452651798725128,\n",
       "   -0.3264133930206299,\n",
       "   -0.07695081830024719,\n",
       "   -0.05798766389489174,\n",
       "   -0.11705852299928665,\n",
       "   -0.22354397177696228,\n",
       "   -0.6745187640190125,\n",
       "   -0.22924083471298218,\n",
       "   0.21451205015182495,\n",
       "   0.15134361386299133,\n",
       "   -0.4703127443790436,\n",
       "   -0.20693327486515045,\n",
       "   -0.23325733840465546,\n",
       "   -0.027531420812010765,\n",
       "   0.8406782150268555,\n",
       "   0.5794864892959595,\n",
       "   -0.34281495213508606,\n",
       "   -0.22835326194763184,\n",
       "   -0.4019324779510498,\n",
       "   0.6164332032203674,\n",
       "   -0.6962845325469971,\n",
       "   0.5392215847969055,\n",
       "   0.4060319662094116,\n",
       "   -0.3814648389816284,\n",
       "   0.022874727845191956,\n",
       "   1.0194432735443115,\n",
       "   -0.4729076325893402,\n",
       "   0.5510009527206421,\n",
       "   0.7219228744506836,\n",
       "   0.584469735622406,\n",
       "   0.061157695949077606,\n",
       "   -0.5134475827217102,\n",
       "   0.4095781743526459,\n",
       "   0.15594519674777985,\n",
       "   0.1218532994389534,\n",
       "   -0.2902902066707611,\n",
       "   0.2630680799484253,\n",
       "   0.29503825306892395,\n",
       "   -0.2589190900325775,\n",
       "   -0.13393260538578033,\n",
       "   0.9539374709129333,\n",
       "   -0.2386144995689392,\n",
       "   -0.601905107498169,\n",
       "   0.3267338275909424,\n",
       "   -0.23567676544189453,\n",
       "   0.24930453300476074,\n",
       "   -0.41830509901046753,\n",
       "   -0.32537662982940674,\n",
       "   0.32492879033088684,\n",
       "   -0.31322839856147766,\n",
       "   0.6034572720527649,\n",
       "   0.5772023797035217,\n",
       "   -0.49843665957450867,\n",
       "   -0.7774080038070679,\n",
       "   0.21419192850589752,\n",
       "   0.2868141233921051,\n",
       "   -0.8806479573249817,\n",
       "   -0.14507010579109192,\n",
       "   -0.2110503613948822,\n",
       "   -0.11833028495311737,\n",
       "   0.19587944447994232,\n",
       "   -0.12938708066940308,\n",
       "   0.07728330790996552,\n",
       "   0.9541712999343872,\n",
       "   -0.4209290146827698,\n",
       "   -0.3470497727394104,\n",
       "   -0.08857995271682739,\n",
       "   0.3660867214202881,\n",
       "   -0.4592423737049103,\n",
       "   0.07845059037208557,\n",
       "   -0.18755017220973969,\n",
       "   -0.45574310421943665,\n",
       "   0.060755908489227295,\n",
       "   0.38136187195777893,\n",
       "   -0.011964496225118637,\n",
       "   1.625913381576538,\n",
       "   -0.10671637207269669,\n",
       "   0.28461670875549316,\n",
       "   -0.7607276439666748,\n",
       "   0.23678149282932281,\n",
       "   0.09028003364801407,\n",
       "   -0.1106041669845581,\n",
       "   -0.2599996030330658,\n",
       "   -0.34510350227355957,\n",
       "   -0.25834906101226807,\n",
       "   0.08483672887086868,\n",
       "   -0.5527206659317017,\n",
       "   0.415481299161911,\n",
       "   0.36615100502967834,\n",
       "   0.21164411306381226,\n",
       "   0.5960127115249634,\n",
       "   0.043756887316703796,\n",
       "   -0.3090304732322693,\n",
       "   -0.5931177139282227,\n",
       "   -0.4863990545272827,\n",
       "   -0.05024614930152893,\n",
       "   0.12378102540969849,\n",
       "   0.30104732513427734,\n",
       "   -0.1255342960357666,\n",
       "   0.9057586193084717,\n",
       "   -0.3519029915332794,\n",
       "   -0.6149168610572815,\n",
       "   0.03765833377838135,\n",
       "   0.24746599793434143,\n",
       "   0.21251028776168823,\n",
       "   -0.2514745593070984,\n",
       "   -0.650359034538269,\n",
       "   -0.4540751874446869,\n",
       "   -0.29423248767852783,\n",
       "   0.297881543636322,\n",
       "   -0.03008802980184555,\n",
       "   -0.1716986894607544,\n",
       "   0.34241798520088196,\n",
       "   -0.002030694857239723,\n",
       "   -0.3414081633090973,\n",
       "   0.06483323872089386,\n",
       "   0.39153382182121277,\n",
       "   -0.18084394931793213,\n",
       "   -0.3252399265766144,\n",
       "   -0.20474568009376526,\n",
       "   -0.06705489754676819,\n",
       "   -0.4213041365146637,\n",
       "   -0.5217097997665405,\n",
       "   0.008899830281734467,\n",
       "   0.4850391745567322,\n",
       "   0.5597354173660278,\n",
       "   -0.0021140240132808685,\n",
       "   -0.3470749855041504,\n",
       "   -0.06952574849128723,\n",
       "   -0.6634719371795654,\n",
       "   -0.7499748468399048,\n",
       "   0.2563254237174988,\n",
       "   0.39451515674591064,\n",
       "   -0.5548386573791504,\n",
       "   -0.48661088943481445,\n",
       "   0.3011961579322815,\n",
       "   -0.4116939902305603,\n",
       "   0.4341011941432953,\n",
       "   0.40959084033966064,\n",
       "   -0.188125342130661,\n",
       "   -0.056979939341545105,\n",
       "   0.10282329469919205,\n",
       "   0.293962299823761,\n",
       "   -0.3227469325065613,\n",
       "   0.1750410497188568,\n",
       "   -0.07179822027683258,\n",
       "   -0.27429160475730896,\n",
       "   -0.6904016733169556,\n",
       "   -0.7261763215065002,\n",
       "   -0.46144717931747437,\n",
       "   0.23041974008083344,\n",
       "   -0.40609121322631836,\n",
       "   0.18808531761169434,\n",
       "   0.7372353672981262,\n",
       "   0.19006389379501343,\n",
       "   0.5102959871292114,\n",
       "   0.10329313576221466,\n",
       "   0.18772432208061218,\n",
       "   0.1935277134180069,\n",
       "   -0.23655839264392853,\n",
       "   -0.4054945707321167,\n",
       "   -0.19685621559619904,\n",
       "   -0.016629232093691826,\n",
       "   0.20816627144813538,\n",
       "   -0.5790665149688721,\n",
       "   0.4234508275985718,\n",
       "   0.35552918910980225,\n",
       "   0.04147721827030182,\n",
       "   0.308067262172699,\n",
       "   0.0651477798819542,\n",
       "   0.3415977954864502,\n",
       "   0.2264527678489685,\n",
       "   0.020088955760002136,\n",
       "   0.2632139027118683,\n",
       "   0.20394223928451538,\n",
       "   -0.435621440410614,\n",
       "   -0.2757520079612732,\n",
       "   0.8378468155860901,\n",
       "   -0.05107398331165314,\n",
       "   -0.013256831094622612,\n",
       "   0.7378951907157898,\n",
       "   -0.6276909708976746,\n",
       "   -0.3736073970794678,\n",
       "   -0.5135192275047302,\n",
       "   -0.3096182346343994,\n",
       "   -0.16477112472057343,\n",
       "   -0.5634750723838806,\n",
       "   0.5713381767272949,\n",
       "   -0.007278516888618469,\n",
       "   -0.15560615062713623,\n",
       "   -0.5053879618644714,\n",
       "   0.3319140374660492,\n",
       "   0.8506290316581726,\n",
       "   -0.02423691749572754,\n",
       "   0.49406567215919495,\n",
       "   0.19848164916038513,\n",
       "   0.31044626235961914,\n",
       "   0.4008396565914154,\n",
       "   0.37654075026512146,\n",
       "   -0.09493882954120636,\n",
       "   -0.12570098042488098,\n",
       "   0.2667168378829956,\n",
       "   -0.4040551781654358,\n",
       "   0.3266381025314331,\n",
       "   -0.3085135817527771,\n",
       "   0.15955986082553864,\n",
       "   0.10990266501903534,\n",
       "   -0.133503258228302,\n",
       "   -0.33495190739631653,\n",
       "   -0.26974886655807495,\n",
       "   0.3694881200790405,\n",
       "   0.5141761302947998,\n",
       "   0.6628120541572571,\n",
       "   0.538782000541687,\n",
       "   0.6384680271148682,\n",
       "   0.4395464062690735,\n",
       "   0.34537604451179504,\n",
       "   -0.8598020076751709,\n",
       "   -0.23287677764892578,\n",
       "   0.008977549150586128,\n",
       "   0.8048461079597473,\n",
       "   -0.40863126516342163,\n",
       "   0.2598153054714203,\n",
       "   0.42759618163108826,\n",
       "   0.07758549600839615,\n",
       "   0.015397565439343452,\n",
       "   0.3783515989780426,\n",
       "   0.03593835234642029,\n",
       "   -1.09714937210083,\n",
       "   0.3328557014465332,\n",
       "   -0.3034067749977112,\n",
       "   0.12528157234191895,\n",
       "   -0.02341683954000473,\n",
       "   -0.7328169941902161,\n",
       "   0.2383163869380951,\n",
       "   -0.6166579723358154,\n",
       "   -0.06922834366559982,\n",
       "   0.48935016989707947,\n",
       "   0.04115504398941994,\n",
       "   -0.8252763748168945,\n",
       "   -0.7746362090110779,\n",
       "   0.2291126847267151,\n",
       "   -0.7444512248039246,\n",
       "   -0.309476763010025,\n",
       "   0.3557676374912262,\n",
       "   0.4016120135784149,\n",
       "   -0.0879509299993515,\n",
       "   0.4973888099193573,\n",
       "   -0.41045132279396057,\n",
       "   -0.5392852425575256,\n",
       "   0.6669894456863403,\n",
       "   -0.05615328252315521,\n",
       "   -0.43868714570999146,\n",
       "   -0.2695087194442749,\n",
       "   0.03678933531045914,\n",
       "   0.048920996487140656,\n",
       "   -1.0758845806121826,\n",
       "   -0.142574280500412,\n",
       "   0.0008809356950223446,\n",
       "   0.23383405804634094,\n",
       "   0.2881505489349365,\n",
       "   0.31030312180519104,\n",
       "   -0.7848048210144043,\n",
       "   0.5241737365722656,\n",
       "   0.007331035099923611,\n",
       "   0.3675425350666046,\n",
       "   -0.2893823981285095,\n",
       "   -0.7147204279899597,\n",
       "   0.2059556245803833,\n",
       "   -0.5120557546615601,\n",
       "   0.30794957280158997,\n",
       "   0.5539981126785278,\n",
       "   -0.03126220405101776,\n",
       "   0.6329977512359619,\n",
       "   0.055972374975681305,\n",
       "   0.5608537793159485,\n",
       "   0.18937107920646667,\n",
       "   -0.48027148842811584,\n",
       "   0.22806042432785034,\n",
       "   -0.2379644364118576,\n",
       "   -0.2729690372943878,\n",
       "   0.31237518787384033,\n",
       "   0.0384327694773674,\n",
       "   -0.39096516370773315,\n",
       "   -0.1977054327726364,\n",
       "   -0.1617528796195984,\n",
       "   -0.5260768532752991,\n",
       "   -0.4001326858997345,\n",
       "   -0.22657012939453125,\n",
       "   0.527247428894043,\n",
       "   0.40581753849983215,\n",
       "   0.3553791344165802,\n",
       "   0.17283841967582703,\n",
       "   1.1233521699905396,\n",
       "   -0.3269866406917572,\n",
       "   -0.9269788265228271,\n",
       "   -0.12641006708145142,\n",
       "   -0.0604894645512104,\n",
       "   0.11211393773555756,\n",
       "   -0.18099673092365265,\n",
       "   -0.910678505897522,\n",
       "   -0.6280980110168457,\n",
       "   0.47684144973754883,\n",
       "   -0.43030545115470886,\n",
       "   0.03291310369968414,\n",
       "   0.19460970163345337,\n",
       "   0.7703197002410889,\n",
       "   -0.4024622440338135,\n",
       "   0.0489090271294117,\n",
       "   0.6535012722015381,\n",
       "   0.14393135905265808,\n",
       "   -0.3538424074649811,\n",
       "   0.02600129134953022,\n",
       "   0.121209055185318,\n",
       "   -0.15634983777999878,\n",
       "   -0.38090407848358154,\n",
       "   -0.33035731315612793,\n",
       "   -0.08562842011451721,\n",
       "   -0.28961730003356934,\n",
       "   0.2727518677711487,\n",
       "   -0.24496881663799286,\n",
       "   0.09718535840511322,\n",
       "   1.4716057777404785,\n",
       "   -0.02716582641005516,\n",
       "   -0.8439750671386719,\n",
       "   0.03896278142929077,\n",
       "   -0.14705324172973633,\n",
       "   0.3179169297218323,\n",
       "   -0.06151551753282547,\n",
       "   -0.5719587802886963,\n",
       "   -0.4095684289932251,\n",
       "   -0.5289146900177002,\n",
       "   0.2641783654689789,\n",
       "   -0.05775686725974083,\n",
       "   -0.4608219265937805,\n",
       "   0.12524761259555817,\n",
       "   -0.07886619120836258,\n",
       "   0.8503168225288391,\n",
       "   -0.5728549957275391,\n",
       "   0.4814438819885254,\n",
       "   0.2307356297969818,\n",
       "   -0.25200191140174866,\n",
       "   0.29865795373916626,\n",
       "   0.16282162070274353,\n",
       "   0.08258047699928284,\n",
       "   0.062179647386074066,\n",
       "   0.6161579489707947,\n",
       "   -0.23473820090293884,\n",
       "   0.21739017963409424,\n",
       "   -0.8759071826934814,\n",
       "   0.08077746629714966,\n",
       "   0.2133166491985321,\n",
       "   -0.7242215871810913,\n",
       "   -0.49223780632019043,\n",
       "   -0.31209561228752136,\n",
       "   -0.13319168984889984,\n",
       "   0.226801797747612,\n",
       "   -0.27545931935310364,\n",
       "   -0.12353597581386566,\n",
       "   -0.08595072478055954,\n",
       "   -0.37079334259033203,\n",
       "   0.203082874417305,\n",
       "   0.44463348388671875,\n",
       "   -0.05158458650112152,\n",
       "   -0.3812909722328186,\n",
       "   0.7636991739273071,\n",
       "   0.3446894884109497,\n",
       "   -0.3971264958381653,\n",
       "   -0.014221405610442162,\n",
       "   -0.04470605403184891,\n",
       "   0.18045666813850403,\n",
       "   -0.11772339046001434,\n",
       "   0.3023925721645355,\n",
       "   0.09713801741600037,\n",
       "   0.11556408554315567,\n",
       "   -0.23912379145622253,\n",
       "   0.8631512522697449,\n",
       "   0.0022743642330169678,\n",
       "   0.10467014461755753,\n",
       "   0.07109759747982025,\n",
       "   0.1705249398946762,\n",
       "   0.17284703254699707,\n",
       "   0.17106357216835022,\n",
       "   0.19367501139640808,\n",
       "   0.35904309153556824,\n",
       "   -0.7170841693878174,\n",
       "   0.3071478009223938,\n",
       "   0.23697248101234436,\n",
       "   0.4162922501564026,\n",
       "   -1.4417517185211182,\n",
       "   0.04708500951528549,\n",
       "   -0.1532147079706192,\n",
       "   -0.4820965826511383,\n",
       "   -0.06609237194061279,\n",
       "   0.8310717940330505,\n",
       "   0.2402002066373825,\n",
       "   0.006900526583194733,\n",
       "   0.21457767486572266,\n",
       "   -0.26880186796188354,\n",
       "   0.062332503497600555,\n",
       "   0.1602771133184433,\n",
       "   -0.6738093495368958,\n",
       "   -0.16042378544807434,\n",
       "   -0.35625317692756653,\n",
       "   0.12297625839710236,\n",
       "   0.4556160271167755,\n",
       "   0.6740415692329407,\n",
       "   -0.18974348902702332,\n",
       "   0.4119672179222107,\n",
       "   0.22930817306041718,\n",
       "   -0.24322478473186493,\n",
       "   0.3898460268974304,\n",
       "   0.2590326964855194,\n",
       "   0.09137054532766342,\n",
       "   -0.6201467514038086,\n",
       "   0.38544341921806335,\n",
       "   -0.14586399495601654,\n",
       "   0.007876608520746231,\n",
       "   0.4836918115615845,\n",
       "   0.23787769675254822,\n",
       "   -0.004493257030844688,\n",
       "   0.06207715719938278,\n",
       "   -0.3850691318511963,\n",
       "   0.13075457513332367,\n",
       "   -0.3881698250770569,\n",
       "   0.33242112398147583,\n",
       "   0.08105313777923584,\n",
       "   -0.13707028329372406,\n",
       "   -0.07814286649227142,\n",
       "   -0.476593017578125,\n",
       "   -0.08815890550613403,\n",
       "   0.3307737410068512,\n",
       "   0.3739834427833557,\n",
       "   0.2154873013496399,\n",
       "   0.024205530062317848,\n",
       "   -0.13591820001602173,\n",
       "   -0.45265498757362366,\n",
       "   -0.813839852809906,\n",
       "   -0.513327956199646,\n",
       "   0.16836762428283691,\n",
       "   0.9885448813438416,\n",
       "   0.3959433436393738,\n",
       "   -0.45137786865234375,\n",
       "   -0.7706416249275208,\n",
       "   0.3422486484050751,\n",
       "   0.6341438889503479,\n",
       "   0.6710312366485596,\n",
       "   -0.17201249301433563,\n",
       "   -0.6651148200035095,\n",
       "   0.20736843347549438,\n",
       "   0.6013907194137573,\n",
       "   -0.4109293222427368,\n",
       "   0.20893317461013794,\n",
       "   -0.6514403820037842,\n",
       "   0.2970825731754303,\n",
       "   0.6129932403564453,\n",
       "   0.16757914423942566,\n",
       "   -0.5578663349151611,\n",
       "   -0.07074141502380371,\n",
       "   0.14674346148967743,\n",
       "   -0.42044055461883545,\n",
       "   -0.43477699160575867,\n",
       "   -0.38599371910095215,\n",
       "   0.20442451536655426,\n",
       "   -0.0555976927280426,\n",
       "   0.14291486144065857,\n",
       "   -0.8296904563903809,\n",
       "   0.21421918272972107,\n",
       "   -0.3033286929130554,\n",
       "   0.6046149730682373,\n",
       "   -0.09804386645555496,\n",
       "   0.567949652671814,\n",
       "   0.25544220209121704,\n",
       "   0.4772583246231079,\n",
       "   0.4927389621734619,\n",
       "   0.781806230545044,\n",
       "   -0.6183950304985046,\n",
       "   -0.7850154638290405,\n",
       "   0.3945702016353607,\n",
       "   0.2474549561738968,\n",
       "   0.043236758559942245,\n",
       "   1.0713375806808472,\n",
       "   -0.3124527931213379,\n",
       "   0.4849752187728882,\n",
       "   -0.507655918598175,\n",
       "   -0.7171792984008789,\n",
       "   -0.21141259372234344,\n",
       "   -3.864788770675659,\n",
       "   0.20202985405921936,\n",
       "   -0.11934494972229004,\n",
       "   0.1480226218700409,\n",
       "   -0.18709518015384674,\n",
       "   0.16104097664356232,\n",
       "   -0.00722835399210453,\n",
       "   -0.16359713673591614,\n",
       "   -0.044711414724588394,\n",
       "   -0.21686974167823792,\n",
       "   0.37449491024017334,\n",
       "   0.20179316401481628,\n",
       "   -0.5887545943260193,\n",
       "   0.45288965106010437,\n",
       "   0.22183968126773834,\n",
       "   0.3691897690296173,\n",
       "   -0.015823950991034508,\n",
       "   -0.5068501234054565,\n",
       "   0.16424383223056793,\n",
       "   0.12869489192962646,\n",
       "   0.32227063179016113,\n",
       "   0.08087821304798126,\n",
       "   0.4227875769138336,\n",
       "   -0.33552801609039307,\n",
       "   -0.35731494426727295,\n",
       "   0.32056182622909546,\n",
       "   -0.45396164059638977,\n",
       "   -0.6271904706954956,\n",
       "   -0.030040431767702103,\n",
       "   -0.2442196011543274,\n",
       "   0.23223745822906494,\n",
       "   -0.13658051192760468,\n",
       "   0.72829669713974,\n",
       "   -0.40536633133888245,\n",
       "   0.7596620917320251,\n",
       "   -0.12480605393648148,\n",
       "   0.1751156747341156,\n",
       "   -0.1704704761505127,\n",
       "   -0.056012626737356186,\n",
       "   0.031436748802661896,\n",
       "   -0.2980784475803375,\n",
       "   -0.8914085626602173,\n",
       "   0.16090014576911926,\n",
       "   -0.816338062286377,\n",
       "   0.04070854187011719,\n",
       "   0.03408954292535782,\n",
       "   -0.33937209844589233,\n",
       "   -0.5623223781585693]]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring with My corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_corpus = pd.read_csv(\"../week-6/1990_2011_coca_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_corpus.tokenized_text.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005075 Life  The T.V ' . s on , it 's blari...</td>\n",
       "      <td>['Life', 'The', 'T.V', 's', 'on', 'it', \"'s\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005076 Shelly and the Great Purple Hairstre...</td>\n",
       "      <td>['Shelly', 'and', 'the', 'Great', 'Purple', 'H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005101 MANNY DUBINSKY had been 50 years in ...</td>\n",
       "      <td>['MANNY', 'DUBINSKY', 'had', 'been', '50', 'ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005102 No man can resist the charms of stun...</td>\n",
       "      <td>['No', 'man', 'can', 'resist', 'the', 'charms'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005103 Interweaving Health With Tradition  ...</td>\n",
       "      <td>['Interweaving', 'Health', 'With', 'Tradition'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year genre                                               text  \\\n",
       "0           0  1998   fic  ##1005075 Life  The T.V ' . s on , it 's blari...   \n",
       "1           1  1998   fic  ##1005076 Shelly and the Great Purple Hairstre...   \n",
       "2           2  1998   fic  ##1005101 MANNY DUBINSKY had been 50 years in ...   \n",
       "3           3  1998   fic  ##1005102 No man can resist the charms of stun...   \n",
       "4           4  1998   fic  ##1005103 Interweaving Health With Tradition  ...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  ['Life', 'The', 'T.V', 's', 'on', 'it', \"'s\", ...  \n",
       "1  ['Shelly', 'and', 'the', 'Great', 'Purple', 'H...  \n",
       "2  ['MANNY', 'DUBINSKY', 'had', 'been', '50', 'ye...  \n",
       "3  ['No', 'man', 'can', 'resist', 'the', 'charms'...  \n",
       "4  ['Interweaving', 'Health', 'With', 'Tradition'...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_corpus['includes_lgbt'] = 0\n",
    "coca_corpus['text'] = coca_corpus['text'].str.lower()\n",
    "coca_corpus['includes_lgbt'] = coca_corpus['text'].str.find('queer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_corpus['includes_gay'] = coca_corpus['text'].str.find('gay') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>includes_lgbt</th>\n",
       "      <th>includes_gay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005075 life  the t.v ' . s on , it 's blari...</td>\n",
       "      <td>['Life', 'The', 'T.V', 's', 'on', 'it', \"'s\", ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005076 shelly and the great purple hairstre...</td>\n",
       "      <td>['Shelly', 'and', 'the', 'Great', 'Purple', 'H...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005101 manny dubinsky had been 50 years in ...</td>\n",
       "      <td>['MANNY', 'DUBINSKY', 'had', 'been', '50', 'ye...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005102 no man can resist the charms of stun...</td>\n",
       "      <td>['No', 'man', 'can', 'resist', 'the', 'charms'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005103 interweaving health with tradition  ...</td>\n",
       "      <td>['Interweaving', 'Health', 'With', 'Tradition'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21875</td>\n",
       "      <td>21875</td>\n",
       "      <td>2013</td>\n",
       "      <td>fic</td>\n",
       "      <td>4163137 n april , on the island of terzoza , t...</td>\n",
       "      <td>['n', 'April', 'on', 'the', 'island', 'of', 'T...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21876</td>\n",
       "      <td>21876</td>\n",
       "      <td>2013</td>\n",
       "      <td>fic</td>\n",
       "      <td>4163138 e should google it -- roses of the unb...</td>\n",
       "      <td>['e', 'should', 'Google', 'it', 'roses', 'of',...</td>\n",
       "      <td>1</td>\n",
       "      <td>69008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21877</td>\n",
       "      <td>21877</td>\n",
       "      <td>2013</td>\n",
       "      <td>fic</td>\n",
       "      <td>4163139 he figure she came up with wasn't stag...</td>\n",
       "      <td>['he', 'figure', 'she', 'came', 'up', 'with', ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21878</td>\n",
       "      <td>21878</td>\n",
       "      <td>2013</td>\n",
       "      <td>fic</td>\n",
       "      <td>4163140 he days came and went and mary kept ge...</td>\n",
       "      <td>['he', 'days', 'came', 'and', 'went', 'and', '...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21879</td>\n",
       "      <td>21879</td>\n",
       "      <td>2013</td>\n",
       "      <td>fic</td>\n",
       "      <td>4163476 \" yes . \" kate , his mother , attached...</td>\n",
       "      <td>['Yes', 'Kate', 'his', 'mother', 'attached', '...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21880 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  year genre  \\\n",
       "0               0  1998   fic   \n",
       "1               1  1998   fic   \n",
       "2               2  1998   fic   \n",
       "3               3  1998   fic   \n",
       "4               4  1998   fic   \n",
       "...           ...   ...   ...   \n",
       "21875       21875  2013   fic   \n",
       "21876       21876  2013   fic   \n",
       "21877       21877  2013   fic   \n",
       "21878       21878  2013   fic   \n",
       "21879       21879  2013   fic   \n",
       "\n",
       "                                                    text  \\\n",
       "0      ##1005075 life  the t.v ' . s on , it 's blari...   \n",
       "1      ##1005076 shelly and the great purple hairstre...   \n",
       "2      ##1005101 manny dubinsky had been 50 years in ...   \n",
       "3      ##1005102 no man can resist the charms of stun...   \n",
       "4      ##1005103 interweaving health with tradition  ...   \n",
       "...                                                  ...   \n",
       "21875  4163137 n april , on the island of terzoza , t...   \n",
       "21876  4163138 e should google it -- roses of the unb...   \n",
       "21877  4163139 he figure she came up with wasn't stag...   \n",
       "21878  4163140 he days came and went and mary kept ge...   \n",
       "21879  4163476 \" yes . \" kate , his mother , attached...   \n",
       "\n",
       "                                          tokenized_text  includes_lgbt  \\\n",
       "0      ['Life', 'The', 'T.V', 's', 'on', 'it', \"'s\", ...             -1   \n",
       "1      ['Shelly', 'and', 'the', 'Great', 'Purple', 'H...             -1   \n",
       "2      ['MANNY', 'DUBINSKY', 'had', 'been', '50', 'ye...             -1   \n",
       "3      ['No', 'man', 'can', 'resist', 'the', 'charms'...             -1   \n",
       "4      ['Interweaving', 'Health', 'With', 'Tradition'...             -1   \n",
       "...                                                  ...            ...   \n",
       "21875  ['n', 'April', 'on', 'the', 'island', 'of', 'T...             -1   \n",
       "21876  ['e', 'should', 'Google', 'it', 'roses', 'of',...              1   \n",
       "21877  ['he', 'figure', 'she', 'came', 'up', 'with', ...             -1   \n",
       "21878  ['he', 'days', 'came', 'and', 'went', 'and', '...             -1   \n",
       "21879  ['Yes', 'Kate', 'his', 'mother', 'attached', '...             -1   \n",
       "\n",
       "       includes_gay  \n",
       "0                -1  \n",
       "1                -1  \n",
       "2                -1  \n",
       "3                -1  \n",
       "4                -1  \n",
       "...             ...  \n",
       "21875            -1  \n",
       "21876         69008  \n",
       "21877            -1  \n",
       "21878            -1  \n",
       "21879            -1  \n",
       "\n",
       "[21880 rows x 7 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_corpus.loc[coca_corpus['includes_lgbt'] > -1, 'includes_lgbt'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_corpus['includes_gay'] = coca_corpus['text'].str.find('gay') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_corpus.loc[coca_corpus['includes_gay'] > -1, 'includes_gay'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "queer_sentences = coca_corpus.loc[coca_corpus['includes_lgbt'] ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "gay_sentences = coca_corpus.loc[coca_corpus['includes_gay'] ==1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-b8715fad6b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgay_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sents'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgay_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlucem_illud_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlucem_illud_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgay_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normalized_sents'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgay_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlucem_illud_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizeTokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4040\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4042\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-b8715fad6b45>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgay_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sents'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgay_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlucem_illud_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlucem_illud_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgay_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normalized_sents'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgay_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlucem_illud_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizeTokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/lucem_illud_2020/proccessing.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(word_list, model)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/maxout.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X__bi, drop)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mdrop\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__bi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gay_sentences['tokenized_sents'] = gay_sentences['text'].apply(lambda x: [lucem_illud_2020.word_tokenize(s) for s in lucem_illud_2020.sent_tokenize(x)])\n",
    "gay_sentences['normalized_sents'] = gay_sentences['tokenized_sents'].apply(lambda x: [lucem_illud_2020.normalizeTokens(s, lemma=False) for s in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "queer_sentences['tokenized_sents'] = queer_sentences['text'].apply(lambda x: [lucem_illud_2020.word_tokenize(s) for s in lucem_illud_2020.sent_tokenize(x)])\n",
    "queer_sentences['normalized_sents'] = queer_sentences['tokenized_sents'].apply(lambda x: [lucem_illud_2020.normalizeTokens(s, lemma=False) for s in x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that generate a BERT-powered chatbot tuned on text related to your final project. What is interesting about this model, and how to does it compare to an untrained model? What does it reveal about the social game involved with your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation using BERT\n",
    "\n",
    "The last method which we will explore is text generation. While some may regard it as a parlour trick due to unpredictability, recent dramatic improvements in text generation suggest that these kind of models can find themselves being used in more serious social scientific applications, such as in survey design and construction, idiomatic translation, and the normalization of phrase and sentence meanings.\n",
    "\n",
    "These models can be quite impressive, even uncanny in how human like they sound. Check out this [cool website](https://transformer.huggingface.co), which allows you to write with a transformer. The website is built by the folks who wrote the package we are using. The code underneath the website can be found in their examples: [run_generation.py](https://github.com/huggingface/transformers/blob/master/examples/run_generation.py).\n",
    "\n",
    "We will be using the built in generate function, but the example file has more detailed code which allows you to set the seed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1ed47a18cf47bb8173bdbc1def6cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=224, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c8e33e11b7456c96e6237e46f96918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1042301, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce4edc4a9e14f82a12b45258510fb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=456318, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a71f137007d42c885e6f7fcfe8d79f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=548118077, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model_gpt = AutoModelWithLMHead.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing that we like to do more than analyse data all day long and then try to figure out what's going on.\n",
      "\n",
      "\"We're not going to be able to do that. We're not going to be able to do that.!\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Nothing that we like to do more than analyse data all day long and\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. A little creepy, and as we can see, far from perfect: GPT doesn't alwats work out flawlessly, but it sometimes can, and we will try and see if fine-tuning helps. We are going to tune the model on a complete dataset of Trump tweets, as they have a set of distinctive, highly identifiable qualities.\n",
    "\n",
    "### Creating a domain-specific language model\n",
    "\n",
    "One of the most exciting things about BERT and GPT is being able to retune them the way we want to. We will be training models to perform two tasks - one is to create a BERT with an \"accent\", by traning a model with english news data from the UK, from the US, and from India. We will also train a language generation model with a bunch of Trump tweets. \n",
    "\n",
    "We can train models specifically over a certain domain to make its language generation similar to that domain. \n",
    "[run_language modelling.py](https://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py), followed by [run_generation.py](https://github.com/huggingface/transformers/blob/master/examples/run_generation.py). I've downloaded these files and added them to this directory so we can run them through the notebook. You are encouraged to look at these files to get a rough idea of what is going on.\n",
    "\n",
    "### Loading Data \n",
    "\n",
    "We want to now get our Trump tweets and our English news datasets ready. The data the scripts expect is just a text file with relevant data. We load the Trump tweets and then write them to disk as train and test files with only data. I leave the original dataframes in case you would like to use it for your own purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_corpus = pd.read_csv('../week-6/1990_2011_coca_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a reasonably sized random sample of my corpus to run this\n",
    "text_df = coca_corpus.sample(n=5000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13598</td>\n",
       "      <td>13598</td>\n",
       "      <td>2007</td>\n",
       "      <td>spok</td>\n",
       "      <td>##244801 !PAULA-ZAHN-CNN-AN : Good evening , e...</td>\n",
       "      <td>['PAULA', 'ZAHN', 'CNN', 'AN', 'Good', 'evenin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1006010 At the Baby Shower  Three good witch...</td>\n",
       "      <td>['At', 'the', 'Baby', 'Shower', 'Three', 'good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11683</td>\n",
       "      <td>11683</td>\n",
       "      <td>1999</td>\n",
       "      <td>news</td>\n",
       "      <td>##3043155  U.S. Ambassador James Sasser emerge...</td>\n",
       "      <td>['U.S.', 'Ambassador', 'James', 'Sasser', 'eme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>1998</td>\n",
       "      <td>fic</td>\n",
       "      <td>##1005357 My teacher told me to be really crea...</td>\n",
       "      <td>['My', 'teacher', 'told', 'me', 'to', 'be', 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14619</td>\n",
       "      <td>14619</td>\n",
       "      <td>2007</td>\n",
       "      <td>spok</td>\n",
       "      <td>##249349 JOE WITTE , announcer : MAKE YOUR LIF...</td>\n",
       "      <td>['JOE', 'WITTE', 'announcer', 'MAKE', 'YOUR', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>2390</td>\n",
       "      <td>2012</td>\n",
       "      <td>mag</td>\n",
       "      <td>4155309 editor 's note # If the readers and ed...</td>\n",
       "      <td>['editor', \"'s\", 'note', 'If', 'the', 'readers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12122</td>\n",
       "      <td>12122</td>\n",
       "      <td>1999</td>\n",
       "      <td>news</td>\n",
       "      <td>##3049739  Move over , Neil Armstrong . Space ...</td>\n",
       "      <td>['Move', 'over', 'Neil', 'Armstrong', 'Space',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5036</td>\n",
       "      <td>5036</td>\n",
       "      <td>2002</td>\n",
       "      <td>acad</td>\n",
       "      <td>##4002437 Results from three national surveys ...</td>\n",
       "      <td>['Results', 'from', 'three', 'national', 'surv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19399</td>\n",
       "      <td>19399</td>\n",
       "      <td>1994</td>\n",
       "      <td>mag</td>\n",
       "      <td>##2014084 Soil seems like passive stuff when I...</td>\n",
       "      <td>['Soil', 'seems', 'like', 'passive', 'stuff', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10780</td>\n",
       "      <td>10780</td>\n",
       "      <td>1999</td>\n",
       "      <td>news</td>\n",
       "      <td>##3010112  As much as they hate hearing about ...</td>\n",
       "      <td>['As', 'much', 'as', 'they', 'hate', 'hearing'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  year genre  \\\n",
       "13598       13598  2007  spok   \n",
       "484           484  1998   fic   \n",
       "11683       11683  1999  news   \n",
       "168           168  1998   fic   \n",
       "14619       14619  2007  spok   \n",
       "...           ...   ...   ...   \n",
       "2390         2390  2012   mag   \n",
       "12122       12122  1999  news   \n",
       "5036         5036  2002  acad   \n",
       "19399       19399  1994   mag   \n",
       "10780       10780  1999  news   \n",
       "\n",
       "                                                    text  \\\n",
       "13598  ##244801 !PAULA-ZAHN-CNN-AN : Good evening , e...   \n",
       "484    ##1006010 At the Baby Shower  Three good witch...   \n",
       "11683  ##3043155  U.S. Ambassador James Sasser emerge...   \n",
       "168    ##1005357 My teacher told me to be really crea...   \n",
       "14619  ##249349 JOE WITTE , announcer : MAKE YOUR LIF...   \n",
       "...                                                  ...   \n",
       "2390   4155309 editor 's note # If the readers and ed...   \n",
       "12122  ##3049739  Move over , Neil Armstrong . Space ...   \n",
       "5036   ##4002437 Results from three national surveys ...   \n",
       "19399  ##2014084 Soil seems like passive stuff when I...   \n",
       "10780  ##3010112  As much as they hate hearing about ...   \n",
       "\n",
       "                                          tokenized_text  \n",
       "13598  ['PAULA', 'ZAHN', 'CNN', 'AN', 'Good', 'evenin...  \n",
       "484    ['At', 'the', 'Baby', 'Shower', 'Three', 'good...  \n",
       "11683  ['U.S.', 'Ambassador', 'James', 'Sasser', 'eme...  \n",
       "168    ['My', 'teacher', 'told', 'me', 'to', 'be', 'r...  \n",
       "14619  ['JOE', 'WITTE', 'announcer', 'MAKE', 'YOUR', ...  \n",
       "...                                                  ...  \n",
       "2390   ['editor', \"'s\", 'note', 'If', 'the', 'readers...  \n",
       "12122  ['Move', 'over', 'Neil', 'Armstrong', 'Space',...  \n",
       "5036   ['Results', 'from', 'three', 'national', 'surv...  \n",
       "19399  ['Soil', 'seems', 'like', 'passive', 'stuff', ...  \n",
       "10780  ['As', 'much', 'as', 'they', 'hate', 'hearing'...  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text = train_test_split(text_df['text'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5632     ##4015984 Section : ORIGINAL ARTICLE Abstract ...\n",
       "3366     ##1050683 **69;0;TOOLONG Birthday Girl ( 2001 ...\n",
       "15971    ##4111845 STORY ONE  Some mammal populations f...\n",
       "7268     ##78298 9:00-10:00 PM , It 's NPR 's ALL THING...\n",
       "13431    ##238035 It 's MORNING EDITION from NPR News ....\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text.to_frame().to_csv(r'train_text_coca', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.to_frame().to_csv(r'test_text_coca', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text.to_frame().to_csv(r'train_text_trump', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.to_frame().to_csv(r'test_text_trump', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now used the Google Colab GPUs to train the Trump tweet models. We'll be doing the same for our blog posts too.\n",
    "\n",
    "### GloWBe dataset\n",
    "\n",
    "We'll now load up the GloWbe (Corpus of Global Web-Based English) dataset which have different texts from different countries. We'll try and draw out texts from only the US, UK and India. We'll then save these to disk. Note that this is a Davies Corpora dataset: the full download can be done with the Dropbox link I sent in an announcement a few weeks ago. The whole download is about 3.5 GB but we only need two files, which are anout 250 MB each. The other files might be useful for your research purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucem_illud_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = \"/Users/bhargavvader/Downloads/Academics_tech/corpora/GloWbE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the exact name of the files\n",
    "us = \"/text_us_blog_jfy.zip\"\n",
    "gb = \"/text_gb_blog_akq.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_texts = lucem_illud_2020.loadDavies(address, corpus_style=\"us_blog\", num_files=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_texts = lucem_illud_2020.loadDavies(address, corpus_style=\"gb_blog\", num_files=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dictionary with document ids mapping to text. Since we don't need any information but the text, we can just save these to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(list(us_texts.values())[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_texts(texts, file_name):\n",
    "    text = []\n",
    "    for doc in list(texts.values()):\n",
    "        text.append(' '.join(doc).replace(\"< h >\", \"\").replace(\"< p >\", \"\"))\n",
    "    train_text, test_text = train_test_split(text, test_size=0.2)\n",
    "    with open(file_name + \"_train\", 'w') as f:\n",
    "        for item in train_text:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    \n",
    "    with open(file_name + \"_test\", 'w') as f:\n",
    "        for item in test_text:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_texts(us_texts, \"us_blog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_texts(gb_texts, \"gb_blog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the training and testing files for both US and GB blogs in English. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING - SHIFT TO GOOGLE COLAB\n",
    "\n",
    "The [Google Colab file](https://colab.research.google.com/drive/1_G6iGqiXb-zPBTurRxd7cgGrXyNaKGsA) walks you through the process of fine-tuning models, as we did before for the classification task. Move now to the colab file to fine tune your models. Once you downloaded all the models and their information, place those files in the directory of the HW to use them as demonstrated below. \n",
    "\n",
    "\n",
    "\n",
    "### Running Scripts\n",
    "\n",
    "We use the scripts to do language modelling and text generation. The following cells run the code as if you would have run it in a terminal. I trained all of these models using the Googlr Colab file, and then saved the models to disk.\n",
    "\n",
    "#### Trump GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python run_language_modelling.py --output_dir=output_gpt_trump --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=train_text_trump --do_eval --eval_data_file=test_text_trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python run_language_modeling.py --output_dir=output_roberta_US --model_type=roberta --model_name_or_path=roberta-base --do_train --train_data_file=$TRAIN_FILE --do_eval --eval_data_file=$TEST_FILE --mlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python run_language_modeling.py --output_dir=output_roberta_UK --model_type=roberta --model_name_or_path=roberta-base --do_train --train_data_file=$TRAIN_FILE --do_eval --eval_data_file=$TEST_FILE --mlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and using models\n",
    "\n",
    "Let us now load the four models we have and see how we can use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now - let us see what our Trump Tweet Bot looks like!\n",
    "You can generate text via command line using the command below. You can also load a model once it is saved - I trained my model using Google Colab, downloaded the model, and am loading it again via the command below. Note that you have to download all the files in your folder of the fine-tuned model to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python run_generation.py --model_type=gpt2 --model_name_or_path=output_trump_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_trump = AutoTokenizer.from_pretrained(\"output_trump_gpt\")\n",
    "model_trump = AutoModelWithLMHead.from_pretrained(\"output_trump_gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"Obama is going to\"\n",
    "\n",
    "input = tokenizer_trump.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_trump.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_trump.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow - our Trump bot is nasty, so we know our model trained well. What happens if we try the same sentence for our non-fine tuned model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"Obama is going to\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite the contrast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check out our UK and GB embeddings - how do you think the two models will differ? Maybe in the way different words relate to each other in the same sentence? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_us_model_embedding = RobertaModel.from_pretrained('roberta_us')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RobertaTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-810bcd5004e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroberta_us_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta_us'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'RobertaTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "roberta_us_tokenizer = RobertaTokenizer.from_pretrained('roberta_us')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to visualise how words in a sentence or different or similar to each other. We will try to construct sentences where words might mean different things in different countries - in the US, people might eat chips with salsa, but in the UK, chips are what Americans call french fries, and might eat it fried fish instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Do you have your chips with fish or with salsa?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"He went out in just his undershirt and pants.\" #pants are underwear in Britain; maybe closer to an undershirt\n",
    "text2 = \"His braces completed the outfit.\" #braces are suspenders (in Britain); maybe closer to an outfit\n",
    "text3 = \"Does your pencil have a rubber on it?\" #rubber is an eraser in Britain); maybe closer to a pencil\n",
    "text4 = \"Was the bog closer to the forest or the house?\" #bog is a toilen in Britain); maybe closer to a house\n",
    "text5 = \"Are you taking the trolley or the train to the grocery market\" #trolley is a food carriage; possibly closer to a market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_diffs(text, model, tokenizer):\n",
    "    word_vecs = []\n",
    "    for i in range(0, len(text.split())):\n",
    "        word_vecs.append(word_vector(text, i, model, tokenizer))\n",
    "    L = []\n",
    "    for p in word_vecs:\n",
    "        l = []\n",
    "        for q in word_vecs:\n",
    "            l.append(1 - cosine(p, q))\n",
    "        L.append(l)\n",
    "    M = np.array(L)\n",
    "    fig = plt.figure()\n",
    "    div = pd.DataFrame(M, columns = list(text.split()), index = list(text.split()))\n",
    "    ax = sns.heatmap(div)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_diffs(text, roberta_us_model_embedding, roberta_us_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_gb_model_embedding = RobertaModel.from_pretrained('roberta_gb')\n",
    "roberta_gb_tokenizer = RobertaTokenizer.from_pretrained('roberta_gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_diffs(text, roberta_gb_model_embedding, roberta_gb_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see regarding the relations with chips and sala/fish? What about the other sentences? How about comparing sentence embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that tune BERT to at least two different textual samples. These could be from different corpora, distinct time periods, separate authors, alternative publishing outlets, etc. Then compare the meaning of words, phrases and sentences to each other across the separate models. What do they reveal about the social worlds inscribed by the distinctive samples?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
